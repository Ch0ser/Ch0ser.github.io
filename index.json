[{"content":"CVE-2016-9118\r本文将介绍CVE-2016-9118这一漏洞的背景、原理和复现方式，仅为个人学习笔记，供大家学习参考。\n申明：本工作是A.S.E (AI Code Generation Security Evaluation)开源项目的一部分，很荣幸能作为contributor参与这一开源项目，为大模型的安全评估做出贡献；\n笔记汇总在CVE_Binary_Reproduction。\n漏洞卡片\r字段 内容 CVE-ID CVE-2016-9118 CWE-ID CWE-119:Memory Buffer Overflow NVD公开日期 2016-10-30 评分 5.3 MEDIUM (CVSS v3) 影响组件 OpenJPEG (openjp2) ≤ 2.2.0 受影响模块 openjp2（JPEG2000 编码器） 漏洞类型 整数溢出 → 堆缓冲区溢出 利用后果 远程代码执行 / DoS 补丁 Commit c22cbd8bdf8ff2ae372f94391a4be2d322b36b41 (openjpeg) 背景介绍\rOpenJPEG（openjp2）是 JPEG 2000（ISO/IEC 15444）的一种开源实现，包含编解码器与命令行工具（opj_compress、opj_decompress 等），广泛用于图像查看器、PDF 渲染器与医疗影像等领域。 漏洞位于 PNM（PBM/PGM/PPM）输入处理链，攻击者通过构造异常大的 PNM 尺寸字段诱导整数溢出，从而触发后续像素写入时的堆缓冲区越界。 漏洞原理分析\r触发点（观察到的行为） 工具函数 pnmtoimage（src/bin/jp2/convert.c）会读取 PNM 文件头并将宽度/高度解析为整型（现有实现使用非安全的 atoi/类似逻辑）。解析后会调用 opj_image_create 分配 image 组件的像素缓冲区。 在 PNM 的一种二进制单比特格式（format == 4，PBM binary）中，代码按位读取像素并写入 image-\u0026gt;comps[0].data[i]，但没有在写前对 i 做有效范围检查。 若 width 和 height 被解析为非常大的值（或溢出到接近 INT_MAX），则 comp-\u0026gt;w * comp-\u0026gt;h 在计算时会发生整数溢出（在缺乏 size_t 使用或缺乏溢出检查时），导致 opj_calloc 分配的字节数远小于实际像素数。随后 pnmtoimage 对像素的写入会越界，触发 heap-buffer-overflow。 根本原因（两类问题共同导致） 不安全的头部数字解析和缺乏范围/合理上限校验：使用 atoi/简单 skip 逻辑会在遇到超长数字时产生溢出或得到不可靠的值； 在分配时没有对乘法（width * height）做无符号/更大类型的溢出检查：乘法在有符号整型或窄类型下会 wrap，使得按“像素数”分配的内存明显不足。 如何被利用（攻击面） 攻击者构造一个 PNM/PBM 文件，将 width/height 字段设置为极大（例如由许多数字组成的字符串），通过触发解析溢出导致程序分配过小缓冲区，然后在像素读取循环中写出越界数据。越界写可以被利用为 DoS，或在特定条件下触发控制流破坏，导致任意代码执行。 漏洞复现\r环境准备\r本次复现是在docker容器环境下进行的，保证了环境的精确、纯粹，我们可以随意指定依赖版本，而不会被主机的环境干扰。\n首先，拉取openjpeg官方github仓库。\n1 git clone https://github.com/uclouvain/openjpeg.git 然后，根据编译所需相关依赖创建docker镜像，注意依赖要尽量贴合当年的环境，以下是dockerfile。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 FROM ubuntu:16.04 # 设置非交互式安装 ENV DEBIAN_FRONTEND=noninteractive # 安装基础依赖 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ build-essential \\ cmake \\ git \\ clang \\ gcc \\ g++ \\ libc6-dev \\ libtiff5-dev \\ libpng-dev \\ libjpeg-dev \\ zlib1g-dev \\ libssl-dev \\ pkg-config \\ wget \\ vim \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # 安装 AddressSanitizer（ASan）支持的编译器（clang） RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ clang-3.8 \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # 设置默认编译器为 clang（用于 ASan） ENV CC=clang-3.8 ENV CXX=clang++-3.8 # 设置工作目录 WORKDIR /workspace # 保持容器运行 CMD [\u0026#34;tail\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;/dev/null\u0026#34;] 根据dockerfile，我们创建镜像。\n1 2 3 4 5 6 7 # 在dockerfile所在目录下执行 docker build -t openjpeg_cve-2016-9118 . # 检查是否创建成功 docker images # 返回的images中含openjpeg_cve-2016-9118即创建完成 REPOSITORY TAG IMAGE ID CREATED SIZE openjpeg_cve-2016-9118 latest 07ad62f9e5e6 4 weeks ago 800MB 至此环境准备就完成了。\n编译/触发\r首先，使用先前创建的镜像启动容器，建议使用docker容器挂载宿主机目录，方便进行文件的观测和修改。\n1 2 3 4 5 6 7 # 挂载目录替换成自己宿主机的实际路径，保证openjpeg项目文件夹也在其下 docker run -it --rm --name openjpeg_cve-2016-9118 \\ -v /mnt/d/A.S.E/benchmark-project/openjpeg:/workspace \\ openjpeg_cve-2016-9118 /bin/bash # -rm 选项表示容器退出后自动删除 # --name 指定容器名字 # /bin/bash 指定命令行环境 宿主机目录会被挂载到容器的/workspace目录下，注意所有改变也会同步到宿主机目录上。\n进入容器后，我们先将项目切换到修复前版本。\n1 2 3 cd openjpeg # 切换到修复前一个commit git checkout c22cbd8bdf8ff2ae372f94391a4be2d322b36b41^ 接着我们编译出供漏洞复现使用的组件，注意需要启用 ASan 与 debug 编译标志以获得清晰崩溃信息，以下是我撰写使用的编译脚本setup.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env bash set -e cd /workspace/openjpeg BUILD_DIR=\u0026#34;build_ASan\u0026#34; # 1. 完全清理 rm -rf \u0026#34;$BUILD_DIR\u0026#34; mkdir \u0026#34;$BUILD_DIR\u0026#34; # 2. 强制 clang + ASan 渗透到所有阶段 export CC=clang export CXX=clang++ export CFLAGS=\u0026#34;-fsanitize=address -fno-omit-frame-pointer -g -O0\u0026#34; export CXXFLAGS=\u0026#34;$CFLAGS\u0026#34; export LDFLAGS=\u0026#34;-fsanitize=address\u0026#34; # 3. 配置 + 编译 cd \u0026#34;$BUILD_DIR\u0026#34; cmake .. \\ -DCMAKE_BUILD_TYPE=Debug \\ -DCMAKE_C_COMPILER=\u0026#34;$CC\u0026#34; \\ -DCMAKE_CXX_COMPILER=\u0026#34;$CXX\u0026#34; \\ -DCMAKE_C_FLAGS=\u0026#34;$CFLAGS\u0026#34; \\ -DCMAKE_CXX_FLAGS=\u0026#34;$CXXFLAGS\u0026#34; \\ -DCMAKE_EXE_LINKER_FLAGS=\u0026#34;$LDFLAGS\u0026#34; \\ -DBUILD_SHARED_LIBS=OFF \\ -DBUILD_THIRDPARTY=ON cmake --build . -- -j$(nproc) echo \u0026#34;=== Build finished ===\u0026#34; echo \u0026#34;Executable: $(pwd)/bin/opj_compress\u0026#34; 执行完毕后，需要用到的编码器组件opj_compress应当在以下路径。\n1 2 3 # 检查opj_compress是否存在 root@1877c59a83ec:/workspace# ls /workspace/openjpeg/build_ASan/bin/opj_compress /workspace/openjpeg/build_ASan/bin/opj_compress 接下来就可以结合poc触发文件，参考bug_report的中的漏洞触发方式进行漏洞复现。\n在report中，触发命令格式如下：\n1 2 3 4 # opj_compress 编码器路径 # $FILE poc文件路径 # null.j2k 编码输出文件路径 /workspace/openjpeg/build_ASan/bin/opj_compress -i /workspace/poc/2016-9118.pgm -o /tmp/null.j2k 我使用的poc文件链接附上：2016-9118.pgm\n调整路径并执行后成功触发漏洞，显著标志为 heap-buffer-overflow，具体结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 root@2ec9c0b46681:/workspace# /workspace/openjpeg/build_ASan/bin/opj_compress -i /workspace/poc/2016-9118.pgm -o /tmp/null.j2k ================================================================= ==1843==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60200000eff4 at pc 0x000000515457 bp 0x7fff32741530 sp 0x7fff32741528 WRITE of size 4 at 0x60200000eff4 thread T0 #0 0x515456 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x515456) #1 0x4f9cf3 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4f9cf3) #2 0x79a0bcdf183f (/lib/x86_64-linux-gnu/libc.so.6+0x2083f) #3 0x427788 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x427788) 0x60200000eff4 is located 0 bytes to the right of 4-byte region [0x60200000eff0,0x60200000eff4) allocated by thread T0 here: #0 0x4c7a40 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4c7a40) #1 0x79a0bde8248f (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x19f48f) #2 0x79a0bdd1ad42 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x37d42) #3 0x51433b (/workspace/openjpeg/build_ASan/bin/opj_compress+0x51433b) #4 0x4f9cf3 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4f9cf3) #5 0x79a0bcdf183f (/lib/x86_64-linux-gnu/libc.so.6+0x2083f) SUMMARY: AddressSanitizer: heap-buffer-overflow (/workspace/openjpeg/build_ASan/bin/opj_compress+0x515456) Shadow bytes around the buggy address: 0x0c047fff9da0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9db0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9dc0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9dd0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9de0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa =\u0026gt;0x0c047fff9df0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa[04]fa 0x0c047fff9e00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9e10: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9e20: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9e30: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c047fff9e40: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa Shadow byte legend (one shadow byte represents 8 application bytes): Addressable: 00 Partially addressable: 01 02 03 04 05 06 07 Heap left redzone: fa Heap right redzone: fb Freed heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack partial redzone: f4 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 Container overflow: fc Array cookie: ac Intra object redzone: bb ASan internal: fe Left alloca redzone: ca Right alloca redzone: cb ==1843==ABORTING 当我们切换到修复后版本尝试漏洞复现：\n1 2 3 4 cd openjpeg git checkout c22cbd8bdf8ff2ae372f94391a4be2d322b36b41 cd .. ./setup.sh \u0026amp;\u0026amp; /workspace/openjpeg/build_ASan/bin/opj_compress -i /workspace/poc/2016-9118.pgm -o /tmp/null.j2k 这次就被补丁提前拦截了，检测到缓冲区空间不足，并没有再进行强行分配。\n1 2 3 4 5 === Build finished === Executable: /workspace/openjpeg/build_ASan/bin/opj_compress pnmtoimage:Image 2147483647x2147483647 too big! Unable to load pnm file 小结：\n在修复前版本：opj_compress 加载含恶意尺寸字段的 PNM，会出现 AddressSanitizer 报告的 heap-buffer-overflow（详见你在笔记中已有的 ASan 输出截取）；\n在修复后版本，修补逻辑会在更早阶段拒绝载入该 PNM，给出 \u0026ldquo;pnmtoimage:Image %dx%d too big!\u0026rdquo; 并返回错误。\nPoC分析\r我们来分析一下PoC文件是如何触发漏洞的：\n结合前文的原理分析，我们知道：\nPoC 的关键是 PNM 文件头中宽度/高度字段含有极长数字（例如 \u0026ldquo;555555555544\\n\u0026rdquo; 之类），导致用于存储宽/高的整型被设置为接近 INT_MAX（或解析行为在实现上产生类似结果）。\n在 convert.c 的 format == 4 分支中（PBM binary），代码示例如下（来源于 issue 中的片段）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 if (format == 4) { int x, y, bit; unsigned char uc; i = 0; for(y = 0; y \u0026lt; h; ++y) { bit = -1; uc = 0; for(x = 0; x \u0026lt; w; ++x) { if(bit == -1) { bit = 7; uc = (unsigned char)getc(fp); } image-\u0026gt;comps[0].data[i] = (((uc\u0026gt;\u0026gt;bit) \u0026amp; 1)?0:255); --bit; ++i; } } } 问题在于没有在写入前检查 i 是否小于实际分配的元素数（即 comp-\u0026gt;w * comp-\u0026gt;h）；如果 comp-\u0026gt;w * comp-\u0026gt;h 溢出并返回小值，就会写越界。 在 PoC 的 ASan 输出中可以看到：宽和高都为 2147483647（0x7fffffff），乘法在 32-bit 上溢出导致分配不正确，从而导致之后的写越界。 补丁分析\r修复commit详见: https://github.com/uclouvain/openjpeg/commit/c22cbd8bdf8ff2ae372f94391a4be2d322b36b41\n主要改动\nsrc/bin/jp2/convert.c 新增包含 limits.h。 在解析完 PNM 头并得到 header_info.width/height 后，增加检查： if (header_info.height != 0 \u0026amp;\u0026amp; header_info.width \u0026gt; INT_MAX / header_info.height) { fprintf(stderr, \u0026ldquo;pnmtoimage:Image %dx%d too big!\\n\u0026rdquo;, \u0026hellip;); fclose(fp); return NULL; } 这会在 header 的宽高导致乘法可能溢出到 int 范围时提前拒绝载入。 src/lib/openjp2/image.c 在 opj_image_create 中，分配 comp-\u0026gt;data 之前增加保护： if (comp-\u0026gt;h != 0 \u0026amp;\u0026amp; (OPJ_SIZE_T)comp-\u0026gt;w \u0026gt; SIZE_MAX / comp-\u0026gt;h) { opj_image_destroy(image); return NULL; } 之后再用 (OPJ_SIZE_T)comp-\u0026gt;w * comp-\u0026gt;h 作为 calloc 的第一个参数。 这可防止在尺寸乘积发生无符号整数溢出（size_t）时进行错误分配。 为什么能修复问题\n第一处（convert.c）在更早阶段拒绝载入会导致乘法溢出的问题样本，不再进入后续内存分配/像素写入阶段。 第二处（image.c）通过在分配前做乘法溢出检测，堵住了如果有其它路径绕过前述检查时仍然发生溢出分配的可能性；并把乘法用更宽的无符号类型计算，避免类型窄化时的 wrap。 补丁的局限与建议\n补丁使用了 INT_MAX 检查并打印 stderr，这能快速阻断攻击样本，但：\n注释中提到“此限制可以通过使用 size_t 消除”——更稳健的做法是统一使用 size_t/OPJ_SIZE_T 做所有尺寸与空间计算，并在解析阶段做严格的范围检查。 当前补丁在遇到错误时用 fprintf(stderr, \u0026hellip;) 和返回 NULL；更规范的做法是走项目的事件管理（event manager）/错误回调路径以统一错误处理（commit 中也保留了 TODO）。 还应当在头部解析阶段使用更安全的解析函数（strtol/strtoull）并检查 ERANGE，以避免依赖 atoi 行为。 复现镜像\r以上复现过程已打包为docker镜像，可通过以下命令拉取：\n1 docker pull choser/openjpeg_cve-2016-9118:latest 内含：\nopenjpeg（项目文件夹） setup.sh image_status_check.sh test_case.sh poc.sh poc文件 首先进入项目文件夹，按需切换到修复前/后版本：\n1 2 3 4 5 cd openjpeg # 切换到修复前一个commit git checkout c22cbd8bdf8ff2ae372f94391a4be2d322b36b41^ # 切换到修复commit git checkout c22cbd8bdf8ff2ae372f94391a4be2d322b36b41 然后按顺序执行四个脚本，即可复现和验证漏洞，预期结果为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 在修复前/后两个版本 ./setup.sh \u0026amp;\u0026amp; ./image_status_check.sh \u0026amp;\u0026amp; ./test_case.sh # 都应成功编译，并且可执行文件通过基本功能验证 === Build finished === Executable: /workspace/openjpeg/build_ASan/bin/opj_compress [A.S.E] image startup successfully [A.S.E] test case passed # 在修复前/后版本 ./poc.sh # 修复前版本 [A.S.E] vulnerability found # 修复后版本 [A.S.E] vulnerability not found 总结和启示\r本漏洞是“整数溢出→错误内存分配→写越界”的经典链式问题实例。防御要点是： 在所有外部输入（文本头字段、文件元数据）进行更严格的解析与范围校验； 在做内存分配前用合适的宽类型（size_t）和溢出检查（例如 a \u0026gt; SIZE_MAX / b）验证乘法安全； 在实际写入内存前再次检查索引是否在已分配的范围内（“防御性编程”），并在读取操作上做好 EOF/错误检查； 统一和改进错误报告机制，避免直接 fprintf 导致库用户行为异常。 修补这类问题通常需要“多层防护”：既在输入解析阶段拒绝非法尺寸，也在分配阶段做最终防护。commit 做了这两处阻断，因此修复是合理且有效的。 参考链接\rNVD: NVD - CVE-2016-9118 Issue: uclouvain/openjpeg#861 Fix commit: https://github.com/uclouvain/openjpeg/commit/c22cbd8bdf8ff2ae372f94391a4be2d322b36b41 项目主页: https://github.com/uclouvain/openjpeg ","date":"2025-10-22T08:41:06Z","image":"http://localhost:1313/images/SekiroDragon.png","permalink":"http://localhost:1313/p/openjpeg_03cve-2016-9118/","title":"openjpeg_03:CVE-2016-9118"},{"content":"CVE-2017-14164\r本文将介绍CVE-2017-14164这一漏洞的背景、原理和复现方式，仅为个人学习笔记，供大家学习参考。\n申明：本工作是A.S.E (AI Code Generation Security Evaluation)开源项目的一部分，很荣幸能作为contributor参与这一开源项目，为大模型的安全评估做出贡献；\n笔记汇总在CVE_Binary_Reproduction。\n漏洞卡片\r字段 内容 CVE-ID CVE-2017-14164 CWE-ID CWE-787:Out-of-bounds Write NVD公开日期 2017-09-06 评分 8.8 HIGH (CVSS v3) 影响组件 OpenJPEG (openjp2) ≤ 2.2.0 受影响模块 openjp2（JPEG2000 编码器） 漏洞类型 整数溢出 → 堆缓冲区溢出 利用后果 远程代码执行 / DoS 补丁 Commit dcac91b8c72f743bda7dbfa9032356bc8110098a (openjpeg) 背景介绍\rOpenJPEG（openjp2）是 JPEG 2000（ISO/IEC 15444）的一种开源实现，包含编解码器与命令行工具（opj_compress、opj_decompress 等），广泛用于图像查看器、PDF 渲染器与医疗影像等领域。 JPEG 2000 的基本结构是由若干 marker segment（标记段）和 tile / tile-part 组成，编码器在构建 codestream 时会写入一系列固定格式的 marker，例如 SIZ、COD、QCD、SOT（Start Of Tile-part）等。 SOT 是用来标记 tile-part 的开始并携带与该 tile-part 相关的索引与长度信息（tile 索引、tile-part 长度、tile-part 索引等）。因此在编码输出阶段，库会把 SOT 写入输出缓冲区／流，且写入的是固定字节数的头部字段。 在编码器内部，有一系列内存分配、长度计算与分段写入的逻辑：按 tiles/parts 分配或推断输出缓冲区大小，然后按顺序写入 marker 和 tile 数据。如果任一处对“可用空间”的判断／计算不正确，或者写函数不做边界检查，就会产生越界写（heap-buffer-overflow）。 漏洞原理分析\r触发点（观察到的行为） ASan 报告显示访问违规发生在 opj_write_bytes_LE（cio.c）被 opj_j2k_write_sot 调用时，写操作越过了分配区的右边界（“0 bytes to the right of 54-byte region”）。调用栈显示分配发生在 opj_j2k_update_rates（opj_j2k_update_rates -\u0026gt; opj_malloc），写发生在 opj_j2k_write_sot。 根本原因（两类问题共同导致） 写入函数缺乏边界检查：opj_j2k_write_sot 在原实现中没有接收/检查“目标缓冲区的总大小”或“剩余可写字节数”，就直接调用底层写函数把 SOT 标记写入 p_data，从而假设缓冲区足够大。 上层计算/分配可能不正确或被特制输入触发为“过小”分配：在调用 opj_j2k_write_sot 前，上层会基于一些计算（例如 rates、tiles、大量参数）分配输出缓冲区。若这些计算产生了较小的分配（可能是整数溢出、边界计算错误或特制输入导致逻辑进入异常分支），则实际剩余空间会小于 SOT 需要写入的字节数。 两者合在一起就会在写 SOT 时产生堆缓冲区越界（heap-buffer-overflow）。 如何被利用（攻击面） 这个 bug 属于编码器端的写越界（不是简单的输入解析溢出），所以触发方式是向 opj_compress（或使用 openjp2 库 的编码 API）提供一个会使上层分配/计算失败或结果异常的输入（例如极端的图像尺寸、特别的 tile 分布、异常的标签或速率参数），使得随后写入固定大小的 marker 导致越界写入内存。 利用后果：越界写可以覆盖堆上的元数据或控制数据（函数指针、malloc 元数据或其它结构），在特定环境下能演化为远程代码执行或拒绝服务（crash）。因此 CVSS 高分合理。 漏洞复现\r环境准备\r本次复现是在docker容器环境下进行的，保证了环境的精确、纯粹，我们可以随意指定依赖版本，而不会被主机的环境干扰。\n首先，拉取openjpeg官方github仓库。\n1 git clone https://github.com/uclouvain/openjpeg.git 然后，根据编译所需相关依赖创建docker镜像，注意依赖要尽量贴合当年的环境，以下是dockerfile。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 FROM ubuntu:16.04 # 设置非交互式安装 ENV DEBIAN_FRONTEND=noninteractive # 安装基础依赖 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ build-essential \\ cmake \\ git \\ clang \\ gcc \\ g++ \\ libc6-dev \\ libtiff5-dev \\ libpng-dev \\ libjpeg-dev \\ zlib1g-dev \\ libssl-dev \\ pkg-config \\ wget \\ vim \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # 安装 AddressSanitizer（ASan）支持的编译器（clang） RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ clang-3.8 \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # 设置默认编译器为 clang（用于 ASan） ENV CC=clang-3.8 ENV CXX=clang++-3.8 # 设置工作目录 WORKDIR /workspace # 保持容器运行 CMD [\u0026#34;tail\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;/dev/null\u0026#34;] 根据dockerfile，我们创建镜像。\n1 2 3 4 5 6 7 # 在dockerfile所在目录下执行 docker build -t openjpeg_cve-2017-14164 . # 检查是否创建成功 docker images # 返回的images中含openjpeg_cve-2017-14164即创建完成 REPOSITORY TAG IMAGE ID CREATED SIZE openjpeg_cve-2017-14164 latest 07ad62f9e5e6 4 weeks ago 800MB 至此环境准备就完成了。\n编译/触发\r首先，使用先前创建的镜像启动容器，建议使用docker容器挂载宿主机目录，方便进行文件的观测和修改。\n1 2 3 4 5 6 7 # 挂载目录替换成自己宿主机的实际路径，保证openjpeg项目文件夹也在其下 docker run -it --rm --name openjpeg_cve-2017-14164 \\ -v /mnt/d/A.S.E/benchmark-project/openjpeg:/workspace \\ openjpeg_cve-2017-14164 /bin/bash # -rm 选项表示容器退出后自动删除 # --name 指定容器名字 # /bin/bash 指定命令行环境 宿主机目录会被挂载到容器的/workspace目录下，注意所有改变也会同步到宿主机目录上。\n进入容器后，我们先将项目切换到修复前版本。\n1 2 3 cd openjpeg # 切换到修复前一个commit git checkout dcac91b8c72f743bda7dbfa9032356bc8110098a^ 接着我们编译出供漏洞复现使用的组件，注意需要启用 ASan 与 debug 编译标志以获得清晰崩溃信息，以下是我撰写使用的编译脚本setup.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env bash set -e cd /workspace/openjpeg BUILD_DIR=\u0026#34;build_ASan\u0026#34; # 1. 完全清理 rm -rf \u0026#34;$BUILD_DIR\u0026#34; mkdir \u0026#34;$BUILD_DIR\u0026#34; # 2. 强制 clang + ASan 渗透到所有阶段 export CC=clang export CXX=clang++ export CFLAGS=\u0026#34;-fsanitize=address -fno-omit-frame-pointer -g -O0\u0026#34; export CXXFLAGS=\u0026#34;$CFLAGS\u0026#34; export LDFLAGS=\u0026#34;-fsanitize=address\u0026#34; # 3. 配置 + 编译 cd \u0026#34;$BUILD_DIR\u0026#34; cmake .. \\ -DCMAKE_BUILD_TYPE=Debug \\ -DCMAKE_C_COMPILER=\u0026#34;$CC\u0026#34; \\ -DCMAKE_CXX_COMPILER=\u0026#34;$CXX\u0026#34; \\ -DCMAKE_C_FLAGS=\u0026#34;$CFLAGS\u0026#34; \\ -DCMAKE_CXX_FLAGS=\u0026#34;$CXXFLAGS\u0026#34; \\ -DCMAKE_EXE_LINKER_FLAGS=\u0026#34;$LDFLAGS\u0026#34; \\ -DBUILD_SHARED_LIBS=OFF \\ -DBUILD_THIRDPARTY=ON cmake --build . -- -j$(nproc) echo \u0026#34;=== Build finished ===\u0026#34; echo \u0026#34;Executable: $(pwd)/bin/opj_compress\u0026#34; 执行完毕后，需要用到的编码器组件opj_compress应当在以下路径。\n1 2 3 # 检查opj_compress是否存在 root@1877c59a83ec:/workspace# ls /workspace/openjpeg/build_ASan/bin/opj_compress /workspace/openjpeg/build_ASan/bin/opj_compress 接下来就可以结合poc触发文件，参考bug_report的中的漏洞触发方式进行漏洞复现。\n在report中，触发命令格式如下：\n1 2 3 4 # opj_compress 编码器路径 # $FILE poc文件路径 # null.j2k 编码输出文件路径 opj_compress -r 20,10,1 -jpip -EPH -SOP -cinema2K 24 -n 1 -i $FILE -o null.j2k 我使用的poc文件链接附上：2017-14164.tif\n调整路径并执行后成功触发漏洞，显著标志为 heap-buffer-overflow，具体结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 root@82503632bdf0:/workspace# /workspace/openjpeg/build_ASan/bin/opj_compress -r 20,10,1 -jpip -EPH -SOP -cinema2K 24 -n 1 -i /workspace/poc/2017-14164.tif -o /tmp/null.j2k CINEMA 2K profile activated Other options specified could be overridden TIFFReadDirectoryCheckOrder: Warning, Invalid TIFF directory; tags are not sorted in ascending order. TIFFReadDirectory: Warning, Unknown field with tag 6376 (0x18e8) encountered. TIFFReadDirectory: Warning, Unknown field with tag 27154 (0x6a12) encountered. TIFFReadDirectory: Warning, Unknown field with tag 32512 (0x7f00) encountered. TIFFReadDirectory: Warning, Unknown field with tag 15163 (0x3b3b) encountered. TIFFFetchNormalTag: Warning, Sanity check on size of \u0026#34;Tag 6376\u0026#34; value failed; tag ignored. TIFFFetchNormalTag: Warning, Incorrect count for \u0026#34;FillOrder\u0026#34;; tag ignored. TIFFReadDirectory: Warning, TIFF directory is missing required \u0026#34;StripByteCounts\u0026#34; field, calculating from imagelength. [WARNING] JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires: 1 single quality layer-\u0026gt; Number of layers forced to 1 (rather than 3) -\u0026gt; Rate of the last layer (1.0) will be used[INFO] tile number 1 / 1 ================================================================= ==16==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60600000eff6 at pc 0x74dbec3dc468 bp 0x7fff8880fe30 sp 0x7fff8880fe28 WRITE of size 1 at 0x60600000eff6 thread T0 #0 0x74dbec3dc467 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x22467) #1 0x74dbec444a40 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x8aa40) #2 0x74dbec443f71 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x89f71) #3 0x74dbec41d414 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x63414) #4 0x74dbec41b8c7 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x618c7) #5 0x74dbec474394 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0xba394) #6 0x4fac1d (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4fac1d) #7 0x74dbeb4c883f (/lib/x86_64-linux-gnu/libc.so.6+0x2083f) #8 0x427838 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x427838) 0x60600000eff6 is located 0 bytes to the right of 54-byte region [0x60600000efc0,0x60600000eff6) allocated by thread T0 here: #0 0x4c7968 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4c7968) #1 0x74dbec55c58c (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x1a258c) #2 0x74dbec44dc11 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x93c11) #3 0x74dbec404d8d (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x4ad8d) #4 0x74dbec41df77 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x63f77) #5 0x74dbec474266 (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0xba266) #6 0x4faa4e (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4faa4e) #7 0x74dbeb4c883f (/lib/x86_64-linux-gnu/libc.so.6+0x2083f) SUMMARY: AddressSanitizer: heap-buffer-overflow (/workspace/openjpeg/build_ASan/bin/libopenjp2.so.7+0x22467) Shadow bytes around the buggy address: 0x0c0c7fff9da0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c0c7fff9db0: 00 00 00 00 00 00 00 00 fa fa fa fa 00 00 00 00 0x0c0c7fff9dc0: 00 00 00 fa fa fa fa fa 00 00 00 00 00 00 00 00 0x0c0c7fff9dd0: fa fa fa fa 00 00 00 00 00 00 00 fa fa fa fa fa 0x0c0c7fff9de0: 00 00 00 00 00 00 00 00 fa fa fa fa 00 00 00 00 =\u0026gt;0x0c0c7fff9df0: 00 00 00 fa fa fa fa fa 00 00 00 00 00 00[06]fa 0x0c0c7fff9e00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c0c7fff9e10: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c0c7fff9e20: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c0c7fff9e30: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa 0x0c0c7fff9e40: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa Shadow byte legend (one shadow byte represents 8 application bytes): Addressable: 00 Partially addressable: 01 02 03 04 05 06 07 Heap left redzone: fa Heap right redzone: fb Freed heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack partial redzone: f4 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 Container overflow: fc Array cookie: ac Intra object redzone: bb ASan internal: fe Left alloca redzone: ca Right alloca redzone: cb ==16==ABORTING 当我们切换到修复后版本尝试漏洞复现：\n1 2 3 4 cd openjpeg git checkout dcac91b8c72f743bda7dbfa9032356bc8110098a cd .. ./setup.sh \u0026amp;\u0026amp; /workspace/openjpeg/build_ASan/bin/opj_compress -r 20,10,1 -jpip -EPH -SOP -cinema2K 24 -n 1 -i /workspace/poc/2017-14164.tif -o /tmp/null.j2k 这次就被补丁提前拦截了，检测到缓冲区空间不足，并没有再进行强行分配。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 TIFFReadDirectoryCheckOrder: Warning, Invalid TIFF directory; tags are not sorted in ascending order. TIFFReadDirectory: Warning, Unknown field with tag 6376 (0x18e8) encountered. TIFFReadDirectory: Warning, Unknown field with tag 27154 (0x6a12) encountered. TIFFReadDirectory: Warning, Unknown field with tag 32512 (0x7f00) encountered. TIFFReadDirectory: Warning, Unknown field with tag 15163 (0x3b3b) encountered. TIFFFetchNormalTag: Warning, Sanity check on size of \u0026#34;Tag 6376\u0026#34; value failed; tag ignored. TIFFFetchNormalTag: Warning, Incorrect count for \u0026#34;FillOrder\u0026#34;; tag ignored. TIFFReadDirectory: Warning, TIFF directory is missing required \u0026#34;StripByteCounts\u0026#34; field, calculating from imagelength. [WARNING] JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires: 1 single quality layer-\u0026gt; Number of layers forced to 1 (rather than 3) -\u0026gt; Rate of the last layer (1.0) will be used[INFO] tile number 1 / 1 [ERROR] Not enough bytes in output buffer to write SOT marker failed to encode image: opj_encode failed to encode image: opj_end_compress failed to encode image PoC分析\r我们来分析一下PoC文件是如何触发漏洞的：\n结合前文的原理分析，我们知道：要想触发该漏洞必须同时满足：\n写入函数缺乏边界检查 上层计算/分配不正确或被特制输入触发为“过小”分配 修复前版本的项目显然具备条件1。\n而从输出（或者字节流分析）可以看到：这个 PoC 是一个“格式畸形 / 恶意构造”的 TIFF：libtiff 能打开但给出多条警告（未知 tag、不按顺序、缺少 StripByteCounts 等），导致 OpenJPEG 在为编码输出分配 / 计算缓冲区时走到异常路径，进而分配出比后续要写入的 SOT 头还小的缓冲区。opj_j2k_write_sot 在没有边界检查的旧实现中直接写入 SOT（固定 12 字节），因此发生 heap-buffer-overflow（写到了分配区的最右边界之外 1 字节），正对应前文的 ASan 日志。\n补丁分析\r修复commit详见：opj_j2k_write_sot(): fix potential write heap buffer overflow (#991) · uclouvain/openjpeg@dcac91b\n主要改动 opj_j2k_write_sot 的函数签名增加了一个新参数 p_total_data_size（输出缓冲区总大小），并在函数开头加入了显式的边界检查： if (p_total_data_size \u0026lt; 12) { log error; return OPJ_FALSE; } （注：补丁里用 12 作为 SOT 写入所需的最小字节数） 所有调用 opj_j2k_write_sot 的点（例如 opj_j2k_write_first_tile_part、opj_j2k_write_all_tile_parts 等）都被更新，传入 p_total_data_size。 为什么能修复问题 在写 SOT 前加入“可写长度”校验，能在缓冲区不足时立即拒绝写入（返回失败），从而防止调用 opj_write_bytes_LE 等底层写函数时越界写内存。 这是一个典型的“防御式修补”：即使上层分配或计算有误，写函数也不会无检查地写入内存，避免了直接内存破坏。 补丁的局限与建议 该补丁是必要且直接的缓冲区边界校验，但它本身只是阻止越界写；它要求调用方（上层）正确处理返回的 OPJ_FALSE（例如中止编码、释放资源、报告错误或尝试扩展输出缓冲区）。如果上层忽略或错误处理失败（继续假定写成功），仍然可能产生问题。 更彻底的修复还应同时审计上层的长度/分配计算逻辑（例如 opj_j2k_update_rates）以修正导致分配过小的根源（例如整数溢出、未处理的异常输入等）。 建议在库中统一使用带边界检查的写入封装函数，并为所有 marker 写入路径添加相同的校验；同时增加回归测试覆盖这些边界条件。 复现镜像\r以上复现过程已打包为docker镜像，可通过以下命令拉取：\n1 docker pull choser/openjpeg_cve-2017-14164:latest 内含：\nopenjpeg（项目文件夹） setup.sh image_status_check.sh test_case.sh poc.sh poc文件 首先进入项目文件夹，按需切换到修复前/后版本：\n1 2 3 4 5 cd openjpeg # 切换到修复前一个commit git checkout dcac91b8c72f743bda7dbfa9032356bc8110098a^ # 切换到修复commit git checkout dcac91b8c72f743bda7dbfa9032356bc8110098a 然后按顺序执行四个脚本，即可复现和验证漏洞，预期结果为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 在修复前/后两个版本 ./setup.sh \u0026amp;\u0026amp; ./image_status_check.sh \u0026amp;\u0026amp; ./test_case.sh # 都应成功编译，并且可执行文件通过基本功能验证 === Build finished === Executable: /workspace/openjpeg/build_ASan/bin/opj_compress [A.S.E] image startup successfully [A.S.E] test case passed # 在修复前/后版本 ./poc.sh # 修复前版本 [A.S.E] vulnerability found # 修复后版本 [A.S.E] vulnerability not found 总结和启示\r本次复现证明了由于写函数缺乏边界检查 + 上层缓冲区计算/分配在异常输入下错误，容易导致 heap-buffer-overflow（CVE-2017-14164）。补丁通过在写入前增加可写长度检查解决了直接写越界的问题，但仍建议审计上层分配逻辑并在 CI 中加入 ASan/fuzzing 测试以防类似问题再次发生。\n实践启示：对所有低层写操作应做防御式的边界检查；对分配尺寸的计算应在每一步进行整数溢出检测与上下界校验；并在编码库中统一引入安全写封装以减少重复错误。\n参考链接\rNVD - cve-2017-14164 heap-based buffer overflow in opj_write_bytes_LE (cio.c) (unfixed #985) · Issue #991 · uclouvain/openjpeg opj_j2k_write_sot(): fix potential write heap buffer overflow (#991) · uclouvain/openjpeg@dcac91b ","date":"2025-10-20T19:16:32Z","image":"http://localhost:1313/images/SekiroDragon.png","permalink":"http://localhost:1313/p/openjpeg_01cve-2017-14164/","title":"openjpeg_01:CVE-2017-14164"},{"content":"CVE-2016-7445\r本文将介绍CVE-2016-7445这一漏洞的背景、原理和复现方式，仅为个人学习笔记，供大家学习参考。\n申明：本工作是A.S.E (AI Code Generation Security Evaluation)开源项目的一部分，很荣幸能作为contributor参与这一开源项目，为大模型的安全评估做出贡献；\n笔记汇总在CVE_Binary_Reproduction。\n漏洞卡片\r字段 内容 CVE-ID CVE-2016-7445 CWE-ID CWE-476:NULL Pointer Dereference NVD公开日期 2016-10-03 评分 7.5 HIGH (CVSS v3) 影响组件 OpenJPEG (openjp2) ≤ 2.2.0 受影响模块 PNM/PPM 文件读取相关代码（命令行工具中的 src/bin/jp2/convert.c） 漏洞类型 未做充分校验导致的 NULL 指针解引用 利用后果 崩溃（拒绝服务），在图像处理管道上可被恶意或畸形图片触发 补丁 Commit f053508f6fc26aa95839f747bc7cbf257bd43996 (openjpeg) 背景介绍\rOpenJPEG（openjp2）是 JPEG 2000（ISO/IEC 15444）的一种开源实现，包含编解码器与命令行工具（opj_compress、opj_decompress 等），广泛用于图像查看器、PDF 渲染器与医疗影像等领域。 PNM/PPM 的文本头部需要按顺序解析宽、高、最大值（depth）等字段；处理这些文本字段时的健壮性直接关系到对畸形输入的安全性。 漏洞原理分析\r触发点（观察到的行为） 在用 opj_compress 读取畸形的 PPM/PNM 文件头时，解析函数在调用 skip_int / skip_white 之类的 辅助函数 进行跳过空白和解析整数后，没有对返回结果进行充分校验。报告与 ASan 输出显示崩溃发生在 convert.c 的 skip_white（原 issue 报告定位为 convert.c:1331），即对空指针进行了读取从而触发 SEGV。 根本原因 根本原因是 PNM/PPM 头部解析流程对中间返回值（指向解析缓冲区当前位置的 char*）的信任：当 skip_int 解析失败或到达输入末尾时，返回的指针可能为 NULL 或不再有效，而后续代码没有检测这一情况，继续在该指针上调用 skip_white/再次 skip_int 等操作，导致 NULL 指针解引用（CWE-476）。 如何被利用（攻击面） 攻击者只需提供一个特制/畸形的 PPM（PNM） 文件并诱使目标程序（使用受影响的 openjpeg/opj_compress）去读取该文件，即可触发崩溃（拒绝服务）。因此攻击面是所有接受或处理不受信任 PNM/PPM 输入的场景（命令行工具、图像处理服务、批量转换管道等）。 漏洞复现\r环境准备\r本次复现是在docker容器环境下进行的，保证了环境的精确、纯粹，我们可以随意指定依赖版本，而不会被主机的环境干扰。\n首先，拉取openjpeg官方github仓库。\n1 git clone https://github.com/uclouvain/openjpeg.git 然后，根据编译所需相关依赖创建docker镜像，注意依赖要尽量贴合当年的环境，以下是我使用的dockerfile内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env bash set -e cd /workspace/openjpeg BUILD_DIR=\u0026#34;build_ASan\u0026#34; # 1. 完全清理 rm -rf \u0026#34;$BUILD_DIR\u0026#34; mkdir \u0026#34;$BUILD_DIR\u0026#34; # 2. 强制 clang + ASan 渗透到所有阶段 export CC=clang export CXX=clang++ export CFLAGS=\u0026#34;-fsanitize=address -fno-omit-frame-pointer -g -O0\u0026#34; export CXXFLAGS=\u0026#34;$CFLAGS\u0026#34; export LDFLAGS=\u0026#34;-fsanitize=address\u0026#34; # 3. 配置 + 编译 cd \u0026#34;$BUILD_DIR\u0026#34; cmake .. \\ -DCMAKE_BUILD_TYPE=Debug \\ -DCMAKE_C_COMPILER=\u0026#34;$CC\u0026#34; \\ -DCMAKE_CXX_COMPILER=\u0026#34;$CXX\u0026#34; \\ -DCMAKE_C_FLAGS=\u0026#34;$CFLAGS\u0026#34; \\ -DCMAKE_CXX_FLAGS=\u0026#34;$CXXFLAGS\u0026#34; \\ -DCMAKE_EXE_LINKER_FLAGS=\u0026#34;$LDFLAGS\u0026#34; \\ -DBUILD_SHARED_LIBS=OFF \\ -DBUILD_THIRDPARTY=ON cmake --build . -- -j$(nproc) echo \u0026#34;=== Build finished ===\u0026#34; echo \u0026#34;Executable: $(pwd)/bin/opj_compress\u0026#34; 根据dockerfile，我们创建镜像。\n1 2 3 4 5 6 7 # 在dockerfile所在目录下执行 docker build -t openjpeg_cve-2016-7445 . # 检查是否创建成功 docker images # 返回的images中含openjpeg_cve-2016-7445即创建完成 REPOSITORY TAG IMAGE ID CREATED SIZE openjpeg_cve-2016-7445 latest 07ad62f9e5e6 4 weeks ago 800MB 至此环境准备就完成了。\n编译/触发\r首先，使用先前创建的镜像启动容器，建议使用docker容器挂载宿主机目录，方便进行文件的观测和修改。\n1 2 3 4 5 6 7 # 挂载目录替换成自己宿主机的实际路径，保证openjpeg项目文件夹也在其下 docker run -it --rm --name openjpeg_cve-2016-7445 \\ -v /mnt/d/A.S.E/benchmark-project/openjpeg:/workspace \\ openjpeg_cve-2016-7445 /bin/bash # -rm 选项表示容器退出后自动删除 # --name 指定容器名字 # /bin/bash 指定命令行环境 宿主机目录会被挂载到容器的/workspace目录下，注意所有改变也会同步到宿主机目录上。\n进入容器后，我们先将项目切换到修复前版本。\n1 2 3 cd openjpeg # 切换到修复前一个commit git checkout f053508f6fc26aa95839f747bc7cbf257bd43996^ 接着我们编译出供漏洞复现使用的组件，注意需要启用 ASan 与 debug 编译标志以获得清晰崩溃信息，以下是我撰写使用的编译脚本setup.sh。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/usr/bin/env bash set -e cd /workspace/openjpeg BUILD_DIR=\u0026#34;build_ASan\u0026#34; # 1. 完全清理 rm -rf \u0026#34;$BUILD_DIR\u0026#34; mkdir \u0026#34;$BUILD_DIR\u0026#34; # 2. 强制 clang + ASan 渗透到所有阶段 export CC=clang export CXX=clang++ export CFLAGS=\u0026#34;-fsanitize=address -fno-omit-frame-pointer -g -O0\u0026#34; export CXXFLAGS=\u0026#34;$CFLAGS\u0026#34; export LDFLAGS=\u0026#34;-fsanitize=address\u0026#34; # 3. 配置 + 编译 cd \u0026#34;$BUILD_DIR\u0026#34; cmake .. \\ -DCMAKE_BUILD_TYPE=Debug \\ -DCMAKE_C_COMPILER=\u0026#34;$CC\u0026#34; \\ -DCMAKE_CXX_COMPILER=\u0026#34;$CXX\u0026#34; \\ -DCMAKE_C_FLAGS=\u0026#34;$CFLAGS\u0026#34; \\ -DCMAKE_CXX_FLAGS=\u0026#34;$CXXFLAGS\u0026#34; \\ -DCMAKE_EXE_LINKER_FLAGS=\u0026#34;$LDFLAGS\u0026#34; \\ -DBUILD_SHARED_LIBS=OFF \\ -DBUILD_THIRDPARTY=ON cmake --build . -- -j$(nproc) echo \u0026#34;=== Build finished ===\u0026#34; echo \u0026#34;Executable: $(pwd)/bin/opj_compress\u0026#34; 执行完毕后，需要用到的编码器组件opj_compress应当在以下路径。\n1 2 3 # 检查opj_compress是否存在 root@1877c59a83ec:/workspace# ls /workspace/openjpeg/build_ASan/bin/opj_compress /workspace/openjpeg/build_ASan/bin/opj_compress 接下来就可以结合poc触发文件，参考bug_report的中的漏洞触发方式进行漏洞复现。\n在report中，触发命令格式如下：\n1 2 3 4 5 # $OPJ_COMPRESS 编码器路径 # $POC_RAW poc文件路径 # $OUT_FILE 编码输出文件路径 \u0026#34;$OPJ_COMPRESS\u0026#34; -i \u0026#34;$POC_RAW\u0026#34; -o \u0026#34;$OUT_FILE\u0026#34; /workspace/openjpeg/build_ASan/bin/opj_compress -i /workspace/poc/2016-7445.ppm -o /tmp/null.j2k 我使用的poc文件链接附上：2016-7445.ppm\n调整路径并执行后成功触发漏洞，显著标志为 SEGV on unknown address，具体结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@89dfa8253bd0:/workspace# /workspace/openjpeg/build_ASan/bin/opj_compress -i /workspace/poc/2016-7445.ppm -o /tmp/null.j2k ASAN:DEADLYSIGNAL ================================================================= ==1646==ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000 (pc 0x00000052079f bp 0x7ffce9c5c120 sp 0x7ffce9c5c0b0 T0) #0 0x52079e (/workspace/openjpeg/build_ASan/bin/opj_compress+0x52079e) #1 0x520457 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x520457) #2 0x518b25 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x518b25) #3 0x5161c4 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x5161c4) #4 0x4fc3a3 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x4fc3a3) #5 0x7685dc91e83f (/lib/x86_64-linux-gnu/libc.so.6+0x2083f) #6 0x429e38 (/workspace/openjpeg/build_ASan/bin/opj_compress+0x429e38) AddressSanitizer can not provide additional info. SUMMARY: AddressSanitizer: SEGV (/workspace/openjpeg/build_ASan/bin/opj_compress+0x52079e) ==1646==ABORTING 当我们切换到修复后版本尝试漏洞复现：\n1 2 3 4 cd openjpeg git checkout f053508f6fc26aa95839f747bc7cbf257bd43996 cd .. ./setup.sh \u0026amp;\u0026amp; /workspace/openjpeg/build_ASan/bin/opj_compress -i /workspace/poc/2016-7445.ppm -o /tmp/null.j2k 这次就被补丁提前拦截了。\n1 2 3 === Build finished === Executable: /workspace/openjpeg/build_ASan/bin/opj_compress Unable to load pnm file PoC分析\r我们来分析一下PoC文件是如何触发漏洞的，已知该漏洞的原理是：\nPoC 通过构造一个在 PPM 文本头中缺失或畸形的字段（例如使得在解析宽度/高度/最大色深时，skip_int 或者后续的 skip_white 在某一步失败）来触发路径：第一次 skip_int/skip_white 可能使内部指针变为 NULL 或指向缓冲区末尾，随后代码未检测便继续使用该指针，从而触发 NULL 解引用。 我们使用xxd -g 1 -l 512 2016-7445.ppm来对poc文件进行具体分析：\n文件确实是 P6（二进制 PPM），尺寸为 256 x 149，maxval 是 255； 头部包含注释 \u0026ldquo;# OpenJPEG-2.0.0\u0026rdquo;（从 offset 0x03 起可见）。 在注释文字之后、宽高数字 \u0026ldquo;256 149\u0026rdquo; 之前出现了一个非 ASCII 字节 0x8A（见 00000010 行），即注释并未以常见的换行（0x0a）结束，而是被 0x8A 字节分隔，导致解析器无法按预期识别下一个数字 token。 那么为什么这会触发漏洞呢？\nPNM/PPM 解析器通常的逻辑：读取 magic (\u0026ldquo;P6\u0026rdquo;)，跳过注释到换行，跳过空白（skip_white），再用 skip_int 读取 width、height、maxval 等。 而PoC 的头部有一个非标准字节 0x8A 放在注释末尾和宽度字段之间：这会导致解析器不能发现预期的换行或空白分隔，从而使 skip_int/skip_white 在寻找下一个数字时失败（到达缓冲末尾或遇到非法字符），返回 NULL 或不可用的指针。 代码在后续没有对 skip_int/skip_white 的返回值做严格检查（issue 指出 convert.c 的某些行在调用后未检查变量 s），于是继续在 NULL 指针上操作，最终在 skip_white（convert.c:1331）处解引用 NULL，触发 SIGSEGV。这与前文的 ASan 报告完全一致。 汇总可验证事实：issue 中 ASan 栈回溯指向 convert.c 的 skip_white，报告分析指出 convert.c 的若干行（在调用 skip_int 后）没有检查变量 s 的值；上述PoC 文件能稳定触发该崩溃。\n补丁分析\r修复commit详见：Fix PNM file reading (#847) · uclouvain/openjpeg@f053508\n主要改动 对 PNM/PPM 读取逻辑增加了对 skip_int/skip_white 等返回值的检查：在解析 width/height/depth 等字段后会判断解析是否成功，若失败则不会继续使用返回的指针而是返回错误。 在读到图像尺寸和深度后加入了合法性校验（例如检查宽高是否为 0 或非法值），并在不合法时返回加载错误。 将解析失败或不合法输入的路径改为返回失败（并由上层打印如 \u0026ldquo;Unable to load pnm file\u0026rdquo; 的提示），避免继续进入会触发 NULL 解引用的代码路径。 为什么能修复问题 补丁通过在关键点（skip_int/skip_white 返回后）添加空指针/返回值检查，阻止后续对可能为 NULL 的指针进行解引用，从根本上消除了导致 SEGV 的未检查 NULL 使用路径。修复后的行为是在发现解析异常时尽早中止并返回错误，从而避免崩溃。 补丁的局限与建议 局限：补丁修复了 PNM/PPM 读取路径中已发现的未检查返回值问题，但并不能替代对所有输入解析路径统一的防御性编程策略。类似的未检查返回值在项目中其他解析代码处仍有可能存在。 建议： 在所有格式解析函数处统一进行返回值与边界检查（防御式编程）。 为畸形/恶意 PNM/PPM 输入添加回归测试（将触发该问题的 PoC 纳入 CI），以防回归。 对外部库接口在出错时返回可检测的错误码，避免工具端直接崩溃或不可预测行为。 复现镜像\r以上复现过程已打包为docker镜像，可通过以下命令拉取：\n1 docker pull choser/openjpeg_cve-2016-7445:latest 内含：\nopenjpeg（项目文件夹） setup.sh image_status_check.sh test_case.sh poc.sh poc文件 首先进入项目文件夹，按需切换到修复前/后版本：\n1 2 3 4 5 cd openjpeg # 切换到修复前一个commit git checkout f053508f6fc26aa95839f747bc7cbf257bd43996^ # 切换到修复commit git checkout f053508f6fc26aa95839f747bc7cbf257bd43996 然后按顺序执行四个脚本，即可复现和验证漏洞，预期结果为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 在修复前/后两个版本 ./setup.sh \u0026amp;\u0026amp; ./image_status_check.sh \u0026amp;\u0026amp; ./test_case.sh # 都应成功编译，并且可执行文件通过基本功能验证 === Build finished === Executable: /workspace/openjpeg/build_ASan/bin/opj_compress [A.S.E] image startup successfully [A.S.E] test case passed # 在修复前/后版本 ./poc.sh # 修复前版本 [A.S.E] vulnerability found # 修复后版本 [A.S.E] vulnerability not found 总结和启示\r总结和启示：对任何来自不受信任源（文件、网络等）的输入都必须进行严格的返回值与边界检查；一次对解析函数返回值的忽视即可导致 NULL 指针解引用和服务拒绝。 实践建议：尽快升级到包含 commit f053508f6\u0026hellip; 的版本；在代码库中系统地审计其他类似文本/流解析逻辑并增加畸形输入的回归测试。 参考链接\rNVD - cve-2016-7445 null ptr dereference in convert.c:1331 · Issue #843 · uclouvain/openjpeg Fix PNM file reading (#847) · uclouvain/openjpeg@f053508 ","date":"2025-10-20T19:10:06Z","image":"http://localhost:1313/images/SekiroDragon.png","permalink":"http://localhost:1313/p/openjpeg_02cve-2016-7445/","title":"openjpeg_02:CVE-2016-7445"},{"content":"本文是对此博客二进制场景下的所有CVE复现笔记的汇总。\n以及申明：以下工作都是A.S.E (AI Code Generation Security Evaluation)开源项目的一部分；\n本人是这部分工作的contributor，很荣幸能够参与该开源项目，为大模型的安全评估做出贡献。\nopenjpeg\rCVE-2017-14164 CVE-2016-7445 ","date":"2025-10-20T16:54:45Z","image":"http://localhost:1313/images/Genichiro.png","permalink":"http://localhost:1313/p/cve_binary_reproduction/","title":"CVE_Binary_Reproduction"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n命令提示符\r用户进入 Bash 以后，Bash 会显示一个命令提示符，用来提示用户在该位置后面输入命令。\n环境变量 PS1\r命令提示符通常是美元符号$，对于根用户则是井号#。这个符号是环境变量PS1决定的，执行下面的命令，可以看到当前命令提示符的定义。\n1 $ echo $PS1 Bash 允许用户自定义命令提示符，只要改写这个变量即可。改写后的PS1，可以放在用户的 Bash 配置文件.bashrc里面，以后新建 Bash 对话时，新的提示符就会生效。要在当前窗口看到修改后的提示符，可以执行下面的命令。\n1 $ source ~/.bashrc 命令提示符的定义，可以包含特殊的转义字符，表示特定内容。\n\\a：响铃，计算机发出一记声音。 \\d：以星期、月、日格式表示当前日期，例如“Mon May 26”。 \\h：本机的主机名。 \\H：完整的主机名。 \\j：运行在当前 Shell 会话的工作数。 \\l：当前终端设备名。 \\n：一个换行符。 \\r：一个回车符。 \\s：Shell 的名称。 \\t：24小时制的hours:minutes:seconds格式表示当前时间。 \\T：12小时制的当前时间。 \\@：12小时制的AM/PM格式表示当前时间。 \\A：24小时制的hours:minutes表示当前时间。 \\u：当前用户名。 \\v：Shell 的版本号。 \\V：Shell 的版本号和发布号。 \\w：当前的工作路径。 \\W：当前目录名。 \\!：当前命令在命令历史中的编号。 \\#：当前 shell 会话中的命令数。 \\$：普通用户显示为$字符，根用户显示为#字符。 \\[：非打印字符序列的开始标志。 \\]：非打印字符序列的结束标志。 举例来说，[\\u@\\h \\W]\\$这个提示符定义，显示出来就是[user@host ~]$（具体的显示内容取决于你的系统）。\n1 2 [user@host ~]$ echo $PS1 [\\u@\\h \\W]\\$ 改写PS1变量，就可以改变这个命令提示符。\n1 2 $ PS1=\u0026#34;\\A \\h \\$ \u0026#34; 17:33 host $ 注意，$后面最好跟一个空格，这样的话，用户的输入与提示符就不会连在一起。\n颜色\r默认情况下，命令提示符是显示终端预定义的颜色。Bash 允许自定义提示符颜色。\n使用下面的代码，可以设定其后文本的颜色。\n\\033[0;30m：黑色 \\033[1;30m：深灰色 \\033[0;31m：红色 \\033[1;31m：浅红色 \\033[0;32m：绿色 \\033[1;32m：浅绿色 \\033[0;33m：棕色 \\033[1;33m：黄色 \\033[0;34m：蓝色 \\033[1;34m：浅蓝色 \\033[0;35m：粉红 \\033[1;35m：浅粉色 \\033[0;36m：青色 \\033[1;36m：浅青色 \\033[0;37m：浅灰色 \\033[1;37m：白色 举例来说，如果要将提示符设为红色，可以将PS1设成下面的代码。\n1 PS1=\u0026#39;\\[\\033[0;31m\\]\u0026lt;\\u@\\h \\W\u0026gt;\\$\u0026#39; 但是，上面这样设置以后，用户在提示符后面输入的文本也是红色的。为了解决这个问题， 可以在结尾添加另一个特殊代码\\[\\033[00m\\]，表示将其后的文本恢复到默认颜色。\n1 PS1=\u0026#39;\\[\\033[0;31m\\]\u0026lt;\\u@\\h \\W\u0026gt;\\$\\[\\033[00m\\]\u0026#39; 除了设置前景颜色，Bash 还允许设置背景颜色。\n\\033[0;40m：蓝色 \\033[1;44m：黑色 \\033[0;41m：红色 \\033[1;45m：粉红 \\033[0;42m：绿色 \\033[1;46m：青色 \\033[0;43m：棕色 \\033[1;47m：浅灰色 下面是一个带有红色背景的提示符。\n1 PS1=\u0026#39;\\[\\033[0;41m\\]\u0026lt;\\u@\\h \\W\u0026gt;\\$\\[\\033[0m\\] \u0026#39; 环境变量 PS2，PS3，PS4\r除了PS1，Bash 还提供了提示符相关的另外三个环境变量。\n环境变量PS2是命令行折行输入时系统的提示符，默认为\u0026gt; 。\n1 2 $ echo \u0026#34;hello \u0026gt; world\u0026#34; 上面命令中，输入hello以后按下回车键，系统会提示继续输入。这时，第二行显示的提示符就是PS2定义的\u0026gt; 。\n环境变量PS3是使用select命令时，系统输入菜单的提示符。\n环境变量PS4默认为+ 。它是使用 Bash 的-x参数执行脚本时，每一行命令在执行前都会先打印出来，并且在行首出现的那个提示符。\n比如下面是脚本test.sh。\n1 2 3 #!/bin/bash echo \u0026#34;hello world\u0026#34; 使用-x参数执行这个脚本。\n1 2 3 $ bash -x test.sh + echo \u0026#39;hello world\u0026#39; hello world 上面例子中，输出的第一行前面有一个+ ，这就是变量PS4定义的。\n","date":"2025-10-20T15:51:58Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_prompt/","title":"Bash_prompt"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash 启动环境\rSession\r用户每次使用 Shell，都会开启一个与 Shell 的 Session（对话）。\nSession 有两种类型：登录 Session 和非登录 Session，也可以叫做 login shell 和 non-login shell。\n登录 Session\r登录 Session 是用户登录系统以后，系统为用户开启的原始 Session，通常需要用户输入用户名和密码进行登录。\n登录 Session 一般进行整个系统环境的初始化，启动的初始化脚本依次如下。\n/etc/profile：所有用户的全局配置脚本。 /etc/profile.d目录里面所有.sh文件 ~/.bash_profile：用户的个人配置脚本。如果该脚本存在，则执行完就不再往下执行。 ~/.bash_login：如果~/.bash_profile没找到，则尝试执行这个脚本（C shell 的初始化脚本）。如果该脚本存在，则执行完就不再往下执行。 ~/.profile：如果~/.bash_profile和~/.bash_login都没找到，则尝试读取这个脚本（Bourne shell 和 Korn shell 的初始化脚本）。 Linux 发行版更新的时候，会更新/etc里面的文件，比如/etc/profile，因此不要直接修改这个文件。如果想修改所有用户的登陆环境，就在/etc/profile.d目录里面新建.sh脚本。\n如果想修改你个人的登录环境，一般是写在~/.bash_profile里面。下面是一个典型的.bash_profile文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # .bash_profile PATH=/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/bin PATH=$PATH:$HOME/bin SHELL=/bin/bash MANPATH=/usr/man:/usr/X11/man EDITOR=/usr/bin/vi PS1=\u0026#39;\\h:\\w\\$ \u0026#39; PS2=\u0026#39;\u0026gt; \u0026#39; if [ -f ~/.bashrc ]; then . ~/.bashrc fi export PATH export EDITOR 可以看到，这个脚本定义了一些最基本的环境变量，然后执行了~/.bashrc。\nbash命令的--login参数，会强制执行登录 Session 会执行的脚本。\n1 $ bash --login bash命令的--noprofile参数，会跳过上面这些 Profile 脚本。\n1 $ bash --noprofile 非登录 Session\r非登录 Session 是用户进入系统以后，手动新建的 Session，这时不会进行环境初始化。比如，在命令行执行bash命令，就会新建一个非登录 Session。\n非登录 Session 的初始化脚本依次如下。\n/etc/bash.bashrc：对全体用户有效。 ~/.bashrc：仅对当前用户有效。 对用户来说，~/.bashrc通常是最重要的脚本。非登录 Session 默认会执行它，而登录 Session 一般也会通过调用执行它。每次新建一个 Bash 窗口，就相当于新建一个非登录 Session，所以~/.bashrc每次都会执行。注意，执行脚本相当于新建一个非互动的 Bash 环境，但是这种情况不会调用~/.bashrc。\nbash命令的--norc参数，可以禁止在非登录 Session 执行~/.bashrc脚本。\n1 $ bash --norc bash命令的--rcfile参数，指定另一个脚本代替.bashrc。\n1 $ bash --rcfile testrc .bash_logout\r~/.bash_logout脚本在每次退出 Session 时执行，通常用来做一些清理工作和记录工作，比如删除临时文件，记录用户在本次 Session 花费的时间。\n如果没有退出时要执行的命令，这个文件也可以不存在。\n启动选项\r为了方便 Debug，有时在启动 Bash 的时候，可以加上启动参数。\n-n：不运行脚本，只检查是否有语法错误。 -v：输出每一行语句运行结果前，会先输出该行语句。 -x：每一个命令处理之前，先输出该命令，再执行该命令。 1 2 3 $ bash -n scriptname $ bash -v scriptname $ bash -x scriptname 键盘绑定\rBash 允许用户定义自己的快捷键。全局的键盘绑定文件默认为/etc/inputrc，你可以在主目录创建自己的键盘绑定文件.inputrc文件。如果定义了这个文件，需要在其中加入下面这行，保证全局绑定不会被遗漏。\n1 $include /etc/inputrc .inputrc文件里面的快捷键，可以像这样定义，\u0026quot;\\C-t\u0026quot;:\u0026quot;pwd\\n\u0026quot;表示将Ctrl + t绑定为运行pwd命令。\n","date":"2025-10-20T15:50:43Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_startup/","title":"Bash_startup"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nmktemp 命令，trap 命令\rBash 脚本有时需要创建临时文件或临时目录。常见的做法是，在/tmp目录里面创建文件或目录，这样做有很多弊端，使用mktemp命令是最安全的做法。\n临时文件的安全问题\r直接创建临时文件，尤其在/tmp目录里面，往往会导致安全问题。\n首先，/tmp目录是所有人可读写的，任何用户都可以往该目录里面写文件。创建的临时文件也是所有人可读的。\n1 2 3 $ touch /tmp/info.txt $ ls -l /tmp/info.txt -rw-r--r-- 1 ruanyf ruanyf 0 12月 28 17:12 /tmp/info.txt 上面命令在/tmp目录直接创建文件，该文件默认是所有人可读的。\n其次，如果攻击者知道临时文件的文件名，他可以创建符号链接，链接到临时文件，可能导致系统运行异常。攻击者也可能向脚本提供一些恶意数据。因此，临时文件最好使用不可预测、每次都不一样的文件名，防止被利用。\n最后，临时文件使用完毕，应该删除。但是，脚本意外退出时，往往会忽略清理临时文件。\n生成临时文件应该遵循下面的规则。\n创建前检查文件是否已经存在。 确保临时文件已成功创建。 临时文件必须有权限的限制。 临时文件要使用不可预测的文件名。 脚本退出时，要删除临时文件（使用trap命令）。 mktemp 命令的用法\rmktemp命令就是为安全创建临时文件而设计的。虽然在创建临时文件之前，它不会检查临时文件是否存在，但是它支持唯一文件名和清除机制，因此可以减轻安全攻击的风险。\n直接运行mktemp命令，就能生成一个临时文件。\n1 2 3 4 5 $ mktemp /tmp/tmp.4GcsWSG4vj $ ls -l /tmp/tmp.4GcsWSG4vj -rw------- 1 ruanyf ruanyf 0 12月 28 12:49 /tmp/tmp.4GcsWSG4vj 上面命令中，mktemp命令生成的临时文件名是随机的，而且权限是只有用户本人可读写。\nBash 脚本使用mktemp命令的用法如下。\n1 2 3 4 #!/bin/bash TMPFILE=$(mktemp) echo \u0026#34;Our temp file is $TMPFILE\u0026#34; 为了确保临时文件创建成功，mktemp命令后面最好使用 OR 运算符（||），保证创建失败时退出脚本。\n1 2 3 4 #!/bin/bash TMPFILE=$(mktemp) || exit 1 echo \u0026#34;Our temp file is $TMPFILE\u0026#34; 为了保证脚本退出时临时文件被删除，可以使用trap命令指定退出时的清除操作。\n1 2 3 4 5 6 #!/bin/bash trap \u0026#39;rm -f \u0026#34;$TMPFILE\u0026#34;\u0026#39; EXIT TMPFILE=$(mktemp) || exit 1 echo \u0026#34;Our temp file is $TMPFILE\u0026#34; mktemp 命令的参数\r-d参数可以创建一个临时目录。\n1 2 $ mktemp -d /tmp/tmp.Wcau5UjmN6 -p参数可以指定临时文件所在的目录。默认是使用$TMPDIR环境变量指定的目录，如果这个变量没设置，那么使用/tmp目录。\n1 2 $ mktemp -p /home/ruanyf/ /home/ruanyf/tmp.FOKEtvs2H3 -t参数可以指定临时文件的文件名模板，模板的末尾必须至少包含三个连续的X字符，表示随机字符，建议至少使用六个X。默认的文件名模板是tmp.后接十个随机字符。\n1 2 $ mktemp -t mytemp.XXXXXXX /tmp/mytemp.yZ1HgZV trap 命令\rtrap命令用来在 Bash 脚本中响应系统信号。\n最常见的系统信号就是 SIGINT（中断），即按 Ctrl + C 所产生的信号。trap命令的-l参数，可以列出所有的系统信号。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ trap -l 1) SIGHUP\t2) SIGINT\t3) SIGQUIT\t4) SIGILL\t5) SIGTRAP 6) SIGABRT\t7) SIGBUS\t8) SIGFPE\t9) SIGKILL\t10) SIGUSR1 11) SIGSEGV\t12) SIGUSR2\t13) SIGPIPE\t14) SIGALRM\t15) SIGTERM 16) SIGSTKFLT\t17) SIGCHLD\t18) SIGCONT\t19) SIGSTOP\t20) SIGTSTP 21) SIGTTIN\t22) SIGTTOU\t23) SIGURG\t24) SIGXCPU\t25) SIGXFSZ 26) SIGVTALRM\t27) SIGPROF\t28) SIGWINCH\t29) SIGIO\t30) SIGPWR 31) SIGSYS\t34) SIGRTMIN\t35) SIGRTMIN+1\t36) SIGRTMIN+2\t37) SIGRTMIN+3 38) SIGRTMIN+4\t39) SIGRTMIN+5\t40) SIGRTMIN+6\t41) SIGRTMIN+7\t42) SIGRTMIN+8 43) SIGRTMIN+9\t44) SIGRTMIN+10\t45) SIGRTMIN+11\t46) SIGRTMIN+12\t47) SIGRTMIN+13 48) SIGRTMIN+14\t49) SIGRTMIN+15\t50) SIGRTMAX-14\t51) SIGRTMAX-13\t52) SIGRTMAX-12 53) SIGRTMAX-11\t54) SIGRTMAX-10\t55) SIGRTMAX-9\t56) SIGRTMAX-8\t57) SIGRTMAX-7 58) SIGRTMAX-6\t59) SIGRTMAX-5\t60) SIGRTMAX-4\t61) SIGRTMAX-3\t62) SIGRTMAX-2 63) SIGRTMAX-1\t64) SIGRTMAX trap的命令格式如下。\n1 $ trap [动作] [信号1] [信号2] ... 上面代码中，“动作”是一个 Bash 命令，“信号”常用的有以下几个。\nHUP：编号1，脚本与所在的终端脱离联系。 INT：编号2，用户按下 Ctrl + C，意图让脚本终止运行。 QUIT：编号3，用户按下 Ctrl + 斜杠，意图退出脚本。 KILL：编号9，该信号用于杀死进程。 TERM：编号15，这是kill命令发出的默认信号。 EXIT：编号0，这不是系统信号，而是 Bash 脚本特有的信号，不管什么情况，只要退出脚本就会产生。 trap命令响应EXIT信号的写法如下。\n1 $ trap \u0026#39;rm -f \u0026#34;$TMPFILE\u0026#34;\u0026#39; EXIT 上面命令中，脚本遇到EXIT信号时，就会执行rm -f \u0026quot;$TMPFILE\u0026quot;。\ntrap 命令的常见使用场景，就是在 Bash 脚本中指定退出时执行的清理命令。\n1 2 3 4 5 6 7 8 9 #!/bin/bash trap \u0026#39;rm -f \u0026#34;$TMPFILE\u0026#34;\u0026#39; EXIT TMPFILE=$(mktemp) || exit 1 ls /etc \u0026gt; $TMPFILE if grep -qi \u0026#34;kernel\u0026#34; $TMPFILE; then echo \u0026#39;find\u0026#39; fi 上面代码中，不管是脚本正常执行结束，还是用户按 Ctrl + C 终止，都会产生EXIT信号，从而触发删除临时文件。\n注意，trap命令必须放在脚本的开头。否则，它上方的任何命令导致脚本退出，都不会被它捕获。\n如果trap需要触发多条命令，可以封装一个 Bash 函数。\n1 2 3 4 5 6 7 function egress { command1 command2 command3 } trap egress EXIT 参考链接\rWorking with Temporary Files and Directories in Shell Scripts, Steven Vona Using Trap to Exit Bash Scripts Cleanly Sending and Trapping Signals ","date":"2025-10-20T15:49:38Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_mktemptrap/","title":"Bash_mktemp\u0026trap"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n脚本除错\r本章介绍如何对 Shell 脚本除错。\n常见错误\r编写 Shell 脚本的时候，一定要考虑到命令失败的情况，否则很容易出错。\n1 2 3 4 5 6 #! /bin/bash dir_name=/path/not/exist cd $dir_name rm * 上面脚本中，如果目录$dir_name不存在，cd $dir_name命令就会执行失败。这时，就不会改变当前目录，脚本会继续执行下去，导致rm *命令删光当前目录的文件。\n如果改成下面的样子，也会有问题。\n1 cd $dir_name \u0026amp;\u0026amp; rm * 上面脚本中，只有cd $dir_name执行成功，才会执行rm *。但是，如果变量$dir_name为空，cd就会进入用户主目录，从而删光用户主目录的文件。\n下面的写法才是正确的。\n1 [[ -d $dir_name ]] \u0026amp;\u0026amp; cd $dir_name \u0026amp;\u0026amp; rm * 上面代码中，先判断目录$dir_name是否存在，然后才执行其他操作。\n如果不放心删除什么文件，可以先打印出来看一下。\n1 [[ -d $dir_name ]] \u0026amp;\u0026amp; cd $dir_name \u0026amp;\u0026amp; echo rm * 上面命令中，echo rm *不会删除文件，只会打印出来要删除的文件。\nbash的-x参数\rbash的-x参数可以在执行每一行命令之前，打印该命令。一旦出错，这样就比较容易追查。\n下面是一个脚本script.sh。\n1 2 # script.sh echo hello world 加上-x参数，执行每条命令之前，都会显示该命令。\n1 2 3 $ bash -x script.sh + echo hello world hello world 上面例子中，行首为+的行，显示该行是所要执行的命令，下一行才是该命令的执行结果。\n下面再看一个-x写在脚本内部的例子。\n1 2 3 4 5 6 7 8 9 #! /bin/bash -x # trouble: script to demonstrate common errors number=1 if [ $number = 1 ]; then echo \u0026#34;Number is equal to 1.\u0026#34; else echo \u0026#34;Number is not equal to 1.\u0026#34; fi 上面的脚本执行之后，会输出每一行命令。\n1 2 3 4 5 $ trouble + number=1 + \u0026#39;[\u0026#39; 1 = 1 \u0026#39;]\u0026#39; + echo \u0026#39;Number is equal to 1.\u0026#39; Number is equal to 1. 输出的命令之前的+号，是由系统变量PS4决定，可以修改这个变量。\n1 2 3 4 5 6 $ export PS4=\u0026#39;$LINENO + \u0026#39; $ trouble 5 + number=1 7 + \u0026#39;[\u0026#39; 1 = 1 \u0026#39;]\u0026#39; 8 + echo \u0026#39;Number is equal to 1.\u0026#39; Number is equal to 1. 另外，set命令也可以设置 Shell 的行为参数，有利于脚本除错，详见《set 命令》一章。\n环境变量\r有一些环境变量常用于除错。\nLINENO\r变量LINENO返回它在脚本里面的行号。\n1 2 3 #!/bin/bash echo \u0026#34;This is line $LINENO\u0026#34; 执行上面的脚本test.sh，$LINENO会返回3。\n1 2 $ ./test.sh This is line 3 FUNCNAME\r变量FUNCNAME返回一个数组，内容是当前的函数调用堆栈。该数组的0号成员是当前调用的函数，1号成员是调用当前函数的函数，以此类推。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash function func1() { echo \u0026#34;func1: FUNCNAME0 is ${FUNCNAME[0]}\u0026#34; echo \u0026#34;func1: FUNCNAME1 is ${FUNCNAME[1]}\u0026#34; echo \u0026#34;func1: FUNCNAME2 is ${FUNCNAME[2]}\u0026#34; func2 } function func2() { echo \u0026#34;func2: FUNCNAME0 is ${FUNCNAME[0]}\u0026#34; echo \u0026#34;func2: FUNCNAME1 is ${FUNCNAME[1]}\u0026#34; echo \u0026#34;func2: FUNCNAME2 is ${FUNCNAME[2]}\u0026#34; } func1 执行上面的脚本test.sh，结果如下。\n1 2 3 4 5 6 7 $ ./test.sh func1: FUNCNAME0 is func1 func1: FUNCNAME1 is main func1: FUNCNAME2 is func2: FUNCNAME0 is func2 func2: FUNCNAME1 is func1 func2: FUNCNAME2 is main 上面例子中，执行func1时，变量FUNCNAME的0号成员是func1，1号成员是调用func1的主脚本main。执行func2时，变量FUNCNAME的0号成员是func2，1号成员是调用func2的func1。\nBASH_SOURCE\r变量BASH_SOURCE返回一个数组，内容是当前的脚本调用堆栈。该数组的0号成员是当前执行的脚本，1号成员是调用当前脚本的脚本，以此类推，跟变量FUNCNAME是一一对应关系。\n下面有两个子脚本lib1.sh和lib2.sh。\n1 2 3 4 5 6 7 8 # lib1.sh function func1() { echo \u0026#34;func1: BASH_SOURCE0 is ${BASH_SOURCE[0]}\u0026#34; echo \u0026#34;func1: BASH_SOURCE1 is ${BASH_SOURCE[1]}\u0026#34; echo \u0026#34;func1: BASH_SOURCE2 is ${BASH_SOURCE[2]}\u0026#34; func2 } 1 2 3 4 5 6 7 # lib2.sh function func2() { echo \u0026#34;func2: BASH_SOURCE0 is ${BASH_SOURCE[0]}\u0026#34; echo \u0026#34;func2: BASH_SOURCE1 is ${BASH_SOURCE[1]}\u0026#34; echo \u0026#34;func2: BASH_SOURCE2 is ${BASH_SOURCE[2]}\u0026#34; } 然后，主脚本main.sh调用上面两个子脚本。\n1 2 3 4 5 6 7 #!/bin/bash # main.sh source lib1.sh source lib2.sh func1 执行主脚本main.sh，会得到下面的结果。\n1 2 3 4 5 6 7 $ ./main.sh func1: BASH_SOURCE0 is lib1.sh func1: BASH_SOURCE1 is ./main.sh func1: BASH_SOURCE2 is func2: BASH_SOURCE0 is lib2.sh func2: BASH_SOURCE1 is lib1.sh func2: BASH_SOURCE2 is ./main.sh 上面例子中，执行函数func1时，变量BASH_SOURCE的0号成员是func1所在的脚本lib1.sh，1号成员是主脚本main.sh；执行函数func2时，变量BASH_SOURCE的0号成员是func2所在的脚本lib2.sh，1号成员是调用func2的脚本lib1.sh。\nBASH_LINENO\r变量BASH_LINENO返回一个数组，内容是每一轮调用对应的行号。${BASH_LINENO[$i]}跟${FUNCNAME[$i]}是一一对应关系，表示${FUNCNAME[$i]}在调用它的脚本文件${BASH_SOURCE[$i+1]}里面的行号。\n下面有两个子脚本lib1.sh和lib2.sh。\n1 2 3 4 5 6 7 8 9 # lib1.sh function func1() { echo \u0026#34;func1: BASH_LINENO is ${BASH_LINENO[0]}\u0026#34; echo \u0026#34;func1: FUNCNAME is ${FUNCNAME[0]}\u0026#34; echo \u0026#34;func1: BASH_SOURCE is ${BASH_SOURCE[1]}\u0026#34; func2 } 1 2 3 4 5 6 7 # lib2.sh function func2() { echo \u0026#34;func2: BASH_LINENO is ${BASH_LINENO[0]}\u0026#34; echo \u0026#34;func2: FUNCNAME is ${FUNCNAME[0]}\u0026#34; echo \u0026#34;func2: BASH_SOURCE is ${BASH_SOURCE[1]}\u0026#34; } 然后，主脚本main.sh调用上面两个子脚本。\n1 2 3 4 5 6 7 #!/bin/bash # main.sh source lib1.sh source lib2.sh func1 执行主脚本main.sh，会得到下面的结果。\n1 2 3 4 5 6 7 $ ./main.sh func1: BASH_LINENO is 7 func1: FUNCNAME is func1 func1: BASH_SOURCE is main.sh func2: BASH_LINENO is 8 func2: FUNCNAME is func2 func2: BASH_SOURCE is lib1.sh 上面例子中，函数func1是在main.sh的第7行调用，函数func2是在lib1.sh的第8行调用的。\n","date":"2025-10-20T15:47:12Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_debug/","title":"Bash_debug"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nset 命令，shopt 命令\rset命令是 Bash 脚本的重要环节，却常常被忽视，导致脚本的安全性和可维护性出问题。本章介绍set的基本用法，帮助你写出更安全的 Bash 脚本。\n简介\r我们知道，Bash 执行脚本时，会创建一个子 Shell。\n1 $ bash script.sh 上面代码中，script.sh是在一个子 Shell 里面执行。这个子 Shell 就是脚本的执行环境，Bash 默认给定了这个环境的各种参数。\nset命令用来修改子 Shell 环境的运行参数，即定制环境。一共有十几个参数可以定制，官方手册有完整清单，本章介绍其中最常用的几个。\n顺便提一下，如果命令行下不带任何参数，直接运行set，会显示所有的环境变量和 Shell 函数。\n1 $ set set -u\r执行脚本时，如果遇到不存在的变量，Bash 默认忽略它。\n1 2 3 4 #!/usr/bin/env bash echo $a echo bar 上面代码中，$a是一个不存在的变量。执行结果如下。\n1 2 3 $ bash script.sh bar 可以看到，echo $a输出了一个空行，Bash 忽略了不存在的$a，然后继续执行echo bar。大多数情况下，这不是开发者想要的行为，遇到变量不存在，脚本应该报错，而不是一声不响地往下执行。\nset -u就用来改变这种行为。脚本在头部加上它，遇到不存在的变量就会报错，并停止执行。\n1 2 3 4 5 #!/usr/bin/env bash set -u echo $a echo bar 运行结果如下。\n1 2 $ bash script.sh bash: script.sh:行4: a: 未绑定的变量 可以看到，脚本报错了，并且不再执行后面的语句。\n-u还有另一种写法-o nounset，两者是等价的。\n1 set -o nounset set -x\r默认情况下，脚本执行后，只输出运行结果，没有其他内容。如果多个命令连续执行，它们的运行结果就会连续输出。有时会分不清，某一段内容是什么命令产生的。\nset -x用来在运行结果之前，先输出执行的那一行命令。\n1 2 3 4 #!/usr/bin/env bash set -x echo bar 执行上面的脚本，结果如下。\n1 2 3 $ bash script.sh + echo bar bar 可以看到，执行echo bar之前，该命令会先打印出来，行首以+表示。这对于调试复杂的脚本是很有用的。\n-x还有另一种写法-o xtrace。\n1 set -o xtrace 脚本当中如果要关闭命令输出，可以使用set +x。\n1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash number=1 set -x if [ $number = \u0026#34;1\u0026#34; ]; then echo \u0026#34;Number equals 1\u0026#34; else echo \u0026#34;Number does not equal 1\u0026#34; fi set +x 上面的例子中，只对特定的代码段打开命令输出。\nBash 的错误处理\r如果脚本里面有运行失败的命令（返回值非0），Bash 默认会继续执行后面的命令。\n1 2 3 4 #!/usr/bin/env bash foo echo bar 上面脚本中，foo是一个不存在的命令，执行时会报错。但是，Bash 会忽略这个错误，继续往下执行。\n1 2 3 $ bash script.sh script.sh:行3: foo: 未找到命令 bar 可以看到，Bash 只是显示有错误，并没有终止执行。\n这种行为很不利于脚本安全和除错。实际开发中，如果某个命令失败，往往需要脚本停止执行，防止错误累积。这时，一般采用下面的写法。\n1 command || exit 1 上面的写法表示只要command有非零返回值，脚本就会停止执行。\n如果停止执行之前需要完成多个操作，就要采用下面三种写法。\n1 2 3 4 5 6 7 8 9 # 写法一 command || { echo \u0026#34;command failed\u0026#34;; exit 1; } # 写法二 if ! command; then echo \u0026#34;command failed\u0026#34;; exit 1; fi # 写法三 command if [ \u0026#34;$?\u0026#34; -ne 0 ]; then echo \u0026#34;command failed\u0026#34;; exit 1; fi 另外，除了停止执行，还有一种情况。如果两个命令有继承关系，只有第一个命令成功了，才能继续执行第二个命令，那么就要采用下面的写法。\n1 command1 \u0026amp;\u0026amp; command2 set -e\r上面这些写法多少有些麻烦，容易疏忽。set -e从根本上解决了这个问题，它使得脚本只要发生错误，就终止执行。\n1 2 3 4 5 #!/usr/bin/env bash set -e foo echo bar 执行结果如下。\n1 2 $ bash script.sh script.sh:行4: foo: 未找到命令 可以看到，第4行执行失败以后，脚本就终止执行了。\nset -e根据返回值来判断，一个命令是否运行失败。但是，某些命令的非零返回值可能不表示失败，或者开发者希望在命令失败的情况下，脚本继续执行下去。这时可以暂时关闭set -e，该命令执行结束后，再重新打开set -e。\n1 2 3 4 set +e command1 command2 set -e 上面代码中，set +e表示关闭-e选项，set -e表示重新打开-e选项。\n还有一种方法是使用command || true，使得该命令即使执行失败，脚本也不会终止执行。\n1 2 3 4 5 #!/bin/bash set -e foo || true echo bar 上面代码中，true使得这一行语句总是会执行成功，后面的echo bar会执行。\n-e还有另一种写法-o errexit。\n1 set -o errexit set -o pipefail\rset -e有一个例外情况，就是不适用于管道命令。\n所谓管道命令，就是多个子命令通过管道运算符（|）组合成为一个大的命令。Bash 会把最后一个子命令的返回值，作为整个命令的返回值。也就是说，只要最后一个子命令不失败，管道命令总是会执行成功，因此它后面命令依然会执行，set -e就失效了。\n请看下面这个例子。\n1 2 3 4 5 #!/usr/bin/env bash set -e foo | echo a echo bar 执行结果如下。\n1 2 3 4 $ bash script.sh a script.sh:行4: foo: 未找到命令 bar 上面代码中，foo是一个不存在的命令，但是foo | echo a这个管道命令会执行成功，导致后面的echo bar会继续执行。\nset -o pipefail用来解决这种情况，只要一个子命令失败，整个管道命令就失败，脚本就会终止执行。\n1 2 3 4 5 #!/usr/bin/env bash set -eo pipefail foo | echo a echo bar 运行后，结果如下。\n1 2 3 $ bash script.sh a script.sh:行4: foo: 未找到命令 可以看到，echo bar没有执行。\nset -E\r一旦设置了-e参数，会导致函数内的错误不会被trap命令捕获（参考《trap 命令》一章）。-E参数可以纠正这个行为，使得函数也能继承trap命令。\ntrap 是 Bash（以及其他 Unix/Linux shell）中的一个内置命令，用于捕获并处理信号（signals），也可以用来在脚本退出、发生错误或接收到特定信号时执行指定的命令。默认情况下，trap ... ERR 在函数内部不会被触发，即使函数里出错，ERR 陷阱也不会执行。\n1 trap \u0026#39;命令\u0026#39; 信号名/信号编号 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash set -e trap \u0026#34;echo ERR trap fired!\u0026#34; ERR myfunc() { # \u0026#39;foo\u0026#39; 是一个不存在的命令 foo } myfunc 上面示例中，myfunc函数内部调用了一个不存在的命令foo，导致执行这个函数会报错。\n1 2 $ bash test.sh test.sh:行9: foo：未找到命令 但是，由于设置了set -e，函数内部的报错并没有被trap命令捕获，需要加上-E参数才可以。\n1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash set -Eeuo pipefail trap \u0026#34;echo ERR trap fired!\u0026#34; ERR myfunc() { # \u0026#39;foo\u0026#39; 是一个不存在的命令 foo } myfunc 执行上面这个脚本，就可以看到trap命令生效了。\n1 2 3 $ bash test.sh test.sh:行9: foo：未找到命令 ERR trap fired! 其他参数\rset命令还有一些其他参数。\nset -n：等同于set -o noexec，不运行命令，只检查语法是否正确。 set -f：等同于set -o noglob，表示不对通配符进行文件名扩展。 set -v：等同于set -o verbose，表示打印 Shell 接收到的每一行输入。 set -o noclobber：防止使用重定向运算符\u0026gt;覆盖已经存在的文件。 上面的-f和-v参数，可以分别使用set +f、set +v关闭。\nset 命令总结\r上面重点介绍的set命令的几个参数，一般都放在一起使用。\n1 2 3 4 5 6 # 写法一 set -Eeuxo pipefail # 写法二 set -Eeux set -o pipefail 这两种写法建议放在所有 Bash 脚本的头部。\n另一种办法是在执行 Bash 脚本的时候，从命令行传入这些参数。\n1 $ bash -euxo pipefail script.sh shopt 命令\rshopt命令用来调整 Shell 的参数，跟set命令的作用很类似。之所以会有这两个类似命令的主要原因是，set是从 Ksh 继承的，属于 POSIX 规范的一部分，而shopt是 Bash 特有的。\n直接输入shopt可以查看所有参数，以及它们各自打开和关闭的状态。\n1 $ shopt shopt命令后面跟着参数名，可以查询该参数是否打开。\n1 2 $ shopt globstar globstar off 上面例子表示globstar参数默认是关闭的。\n（1）-s\n-s用来打开某个参数。\n1 $ shopt -s optionNameHere （2）-u\n-u用来关闭某个参数。\n1 $ shopt -u optionNameHere 举例来说，histappend这个参数表示退出当前 Shell 时，将操作历史追加到历史文件中。这个参数默认是打开的，如果使用下面的命令将其关闭，那么当前 Shell 的操作历史将替换掉整个历史文件。\n1 $ shopt -u histappend （3）-q\n-q的作用也是查询某个参数是否打开，但不是直接输出查询结果，而是通过命令的执行状态（$?）表示查询结果。如果状态为0，表示该参数打开；如果为1，表示该参数关闭。\n1 2 3 $ shopt -q globstar $ echo $? 1 上面命令查询globstar参数是否打开。返回状态为1，表示该参数是关闭的。\n这个用法主要用于脚本，供if条件结构使用。下面例子是如果打开了这个参数，就执行if结构内部的语句。\n1 2 3 if (shopt -q globstar); then ... fi 参考链接\rThe Set Builtin Safer bash scripts with \u0026lsquo;set -euxo pipefail\u0026rsquo; Writing Robust Bash Shell Scripts ","date":"2025-10-20T15:46:02Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_setshopt/","title":"Bash_set\u0026shopt"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n数组\r数组（array）是一个包含多个值的变量。成员的编号从0开始，数量没有上限，也没有要求成员被连续索引。\n创建数组\r数组可以采用逐个赋值的方法创建。\n1 ARRAY[INDEX]=value 上面语法中，ARRAY是数组的名字，可以是任意合法的变量名。INDEX是一个大于或等于零的整数，也可以是算术表达式。注意数组第一个元素的下标是0， 而不是1。\n下面创建一个三个成员的数组。\n1 2 3 $ array[0]=val $ array[1]=val $ array[2]=val 数组也可以采用一次性赋值的方式创建。\n1 2 3 4 5 6 7 8 9 10 # 无逗号空格相连 ARRAY=(value1 value2 ... valueN) # 等同于 ARRAY=( value1 value2 value3 ) 采用上面方式创建数组时，可以按照默认顺序赋值，也可以在每个值前面指定位置。\n1 2 3 4 5 $ array=(a b c) $ array=([2]=c [0]=a [1]=b) $ days=(Sun Mon Tue Wed Thu Fri Sat) $ days=([0]=Sun [1]=Mon [2]=Tue [3]=Wed [4]=Thu [5]=Fri [6]=Sat) 只为某些值指定位置，也是可以的。\n1 names=(hatter [5]=duchess alice) 上面例子中，hatter是数组的0号位置，duchess是5号位置，alice是6号位置。\n没有赋值的数组元素的默认值是空字符串。\n定义数组的时候，可以使用通配符。\n1 $ mp3s=( *.mp3 ) 上面例子中，将当前目录的所有 MP3 文件，放进一个数组。\n先用declare -a命令声明一个数组，也是可以的。\n1 $ declare -a ARRAYNAME read -a命令则是将用户的命令行输入，存入一个数组。\n1 $ read -a dice 上面命令将用户的命令行输入，存入数组dice。\n读取数组\r读取单个元素\r读取数组指定位置的成员，要使用下面的语法。\n1 $ echo ${array[i]} # i 是索引 上面语法里面的大括号是必不可少的，否则 Bash 会把索引部分[i]按照原样输出。\n1 2 3 4 5 6 7 $ array[0]=a $ echo ${array[0]} a $ echo $array[0] a[0] 上面例子中，数组的第一个元素是a。如果不加大括号，Bash 会直接读取$array首成员的值，然后将[0]按照原样输出。\n读取所有成员\r@和*是数组的特殊索引，表示返回数组的所有成员。\n1 2 3 $ foo=(a b c d e f) $ echo ${foo[@]} a b c d e f 这两个特殊索引配合for循环，就可以用来遍历数组。\n1 2 3 for i in \u0026#34;${names[@]}\u0026#34;; do echo $i done @和*放不放在双引号之中，是有差别的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ activities=( swimming \u0026#34;water skiing\u0026#34; canoeing \u0026#34;white-water rafting\u0026#34; surfing ) $ for act in ${activities[@]}; \\ do \\ echo \u0026#34;Activity: $act\u0026#34;; \\ done Activity: swimming Activity: water Activity: skiing Activity: canoeing Activity: white-water Activity: rafting Activity: surfing 上面的例子中，数组activities实际包含5个成员，但是for...in循环直接遍历${activities[@]}，导致返回7个结果。为了避免这种情况，一般把${activities[@]}放在双引号之中。\n1 2 3 4 5 6 7 8 9 10 $ for act in \u0026#34;${activities[@]}\u0026#34;; \\ do \\ echo \u0026#34;Activity: $act\u0026#34;; \\ done Activity: swimming Activity: water skiing Activity: canoeing Activity: white-water rafting Activity: surfing 上面例子中，${activities[@]}放在双引号之中，遍历就会返回正确的结果。\n${activities[*]}不放在双引号之中，跟${activities[@]}不放在双引号之中是一样的。\n1 2 3 4 5 6 7 8 9 10 11 12 $ for act in ${activities[*]}; \\ do \\ echo \u0026#34;Activity: $act\u0026#34;; \\ done Activity: swimming Activity: water Activity: skiing Activity: canoeing Activity: white-water Activity: rafting Activity: surfing ${activities[*]}放在双引号之中，所有成员就会变成单个字符串返回。\n1 2 3 4 5 6 $ for act in \u0026#34;${activities[*]}\u0026#34;; \\ do \\ echo \u0026#34;Activity: $act\u0026#34;; \\ done Activity: swimming water skiing canoeing white-water rafting surfing 所以，拷贝一个数组的最方便方法，就是写成下面这样。\n1 $ hobbies=( \u0026#34;${activities[@]}\u0026#34; ) 上面例子中，数组activities被拷贝给了另一个数组hobbies。\n这种写法也可以用来为新数组添加成员。\n1 $ hobbies=( \u0026#34;${activities[@]}\u0026#34; diving ) 上面例子中，新数组hobbies在数组activities的所有成员之后，又添加了一个成员。\n默认位置\r如果读取数组成员时，没有读取指定哪一个位置的成员，默认使用0号位置。\n1 2 3 4 $ declare -a foo $ foo=A $ echo ${foo[0]} A 上面例子中，foo是一个数组，赋值的时候不指定位置，实际上是给foo[0]赋值。\n引用一个不带下标的数组变量，则引用的是0号位置的数组元素。\n1 2 3 4 5 $ foo=(a b c d e f) $ echo ${foo} a $ echo $foo a 上面例子中，引用数组元素的时候，没有指定位置，结果返回的是0号位置。\n数组的长度\r要想知道数组的长度（即一共包含多少成员），可以使用下面两种语法。\n1 2 ${#array[*]} ${#array[@]} 下面是一个例子。\n1 2 3 4 5 6 7 $ a[100]=foo $ echo ${#a[*]} 1 $ echo ${#a[@]} 1 上面例子中，把字符串赋值给100位置的数组元素，这时的数组只有一个元素。\n注意，如果用这种语法去读取具体的数组成员，就会返回该成员的字符串长度。这一点必须小心。\n1 2 3 $ a[100]=foo $ echo ${#a[100]} 3 上面例子中，${#a[100]}实际上是返回数组第100号成员a[100]的值（foo）的字符串长度。\n提取数组序号\r${!array[@]}或${!array[*]}，可以返回数组的成员序号，即哪些位置是有值的。\n1 2 3 4 5 $ arr=([5]=a [9]=b [23]=c) $ echo ${!arr[@]} 5 9 23 $ echo ${!arr[*]} 5 9 23 上面例子中，数组的5、9、23号位置有值。\n利用这个语法，也可以通过for循环遍历数组。\n1 2 3 4 5 arr=(a b c d) for i in ${!arr[@]};do echo ${arr[i]} done 提取数组成员\r${array[@]:position:length}的语法可以提取数组成员。\n1 2 3 4 5 $ food=( apples bananas cucumbers dates eggs fajitas grapes ) $ echo ${food[@]:1:1} bananas $ echo ${food[@]:1:3} bananas cucumbers dates 上面例子中，${food[@]:1:1}返回从数组1号位置开始的1个成员，${food[@]:1:3}返回从1号位置开始的3个成员。\n如果省略长度参数length，则返回从指定位置开始的所有成员。\n1 2 $ echo ${food[@]:4} eggs fajitas grapes 上面例子返回从4号位置开始到结束的所有成员。\n追加数组成员\r数组末尾追加成员，可以使用+=赋值运算符。它能够自动地把值追加到数组末尾。否则，就需要知道数组的最大序号，比较麻烦。\n1 2 3 4 5 6 7 $ foo=(a b c) $ echo ${foo[@]} a b c $ foo+=(d e f) $ echo ${foo[@]} a b c d e f 删除数组\r删除一个数组成员，使用unset命令。\n1 2 3 4 5 6 7 $ foo=(a b c d e f) $ echo ${foo[@]} a b c d e f $ unset foo[2] $ echo ${foo[@]} a b d e f 上面例子中，删除了数组中的第三个元素，下标为2。\n将某个成员设为空值，可以从返回值中“隐藏”这个成员。\n1 2 3 4 $ foo=(a b c d e f) $ foo[1]=\u0026#39;\u0026#39; $ echo ${foo[@]} a c d e f 上面例子中，将数组的第二个成员设为空字符串，数组的返回值中，这个成员就“隐藏”了。\n注意，这里是“隐藏”，而不是删除，因为这个成员仍然存在，只是值变成了空值。\n1 2 3 4 5 6 $ foo=(a b c d e f) $ foo[1]=\u0026#39;\u0026#39; $ echo ${#foo[@]} 6 $ echo ${!foo[@]} 0 1 2 3 4 5 上面代码中，第二个成员设为空值后，数组仍然包含6个成员。\n由于空值就是空字符串，所以下面这样写也有隐藏效果，但是不建议这种写法。\n1 $ foo[1]= 上面的写法也相当于“隐藏”了数组的第二个成员。\n直接将数组变量赋值为空字符串，相当于“隐藏”数组的第一个成员。\n1 2 3 4 $ foo=(a b c d e f) $ foo=\u0026#39;\u0026#39; $ echo ${foo[@]} b c d e f 上面的写法相当于“隐藏”了数组的第一个成员。\nunset ArrayName可以清空整个数组。\n1 2 3 4 $ unset ARRAY $ echo ${ARRAY[*]} \u0026lt;--no output--\u0026gt; 关联数组\rBash 的新版本支持关联数组。关联数组使用字符串而不是整数作为数组索引。\ndeclare -A可以声明关联数组。\n1 2 3 4 declare -A colors colors[\u0026#34;red\u0026#34;]=\u0026#34;#ff0000\u0026#34; colors[\u0026#34;green\u0026#34;]=\u0026#34;#00ff00\u0026#34; colors[\u0026#34;blue\u0026#34;]=\u0026#34;#0000ff\u0026#34; 关联数组必须用带有-A选项的declare命令声明创建。相比之下，整数索引的数组，可以直接使用变量名创建数组，关联数组就不行。\n访问关联数组成员的方式，几乎与整数索引数组相同。\n1 echo ${colors[\u0026#34;blue\u0026#34;]} ","date":"2025-10-20T15:45:08Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_array/","title":"Bash_array"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash 函数\r本章介绍 Bash 函数的用法。\n简介\r函数（function）是可以重复使用的代码片段，有利于代码的复用。它与别名（alias）的区别是，别名只适合封装简单的单个命令，函数则可以封装复杂的多行命令。\n函数总是在当前 Shell 执行，这是跟脚本的一个重大区别，Bash 会新建一个子 Shell 执行脚本。如果函数与脚本同名，函数会优先执行。但是，函数的优先级不如别名，即如果函数与别名同名，那么别名优先执行。\nBash 函数定义的语法有两种。\n1 2 3 4 5 6 7 8 9 # 第一种 fn() { # codes } # 第二种 function fn() { # codes } 上面代码中，fn是自定义的函数名，函数代码就写在大括号之中。这两种写法是等价的。\n下面是一个简单函数的例子。\n1 2 3 hello() { echo \u0026#34;Hello $1\u0026#34; } 上面代码中，函数体里面的$1表示函数调用时的第一个参数。\n调用时，就直接写函数名，参数跟在函数名后面。\n1 2 $ hello world Hello world 下面是一个多行函数的例子，显示当前日期时间。\n1 2 3 4 today() { echo -n \u0026#34;Today\u0026#39;s date is: \u0026#34; date +\u0026#34;%A, %B %-d, %Y\u0026#34; } 删除一个函数，可以使用unset命令。\n1 unset -f functionName 查看当前 Shell 已经定义的所有函数，可以使用declare命令。\n1 $ declare -f 上面的declare命令不仅会输出函数名，还会输出所有定义。输出顺序是按照函数名的字母表顺序。由于会输出很多内容，最好通过管道命令配合more或less使用。\ndeclare命令还支持查看单个函数的定义。\n1 $ declare -f functionName declare -F可以输出所有已经定义的函数名，不含函数体。\n1 $ declare -F 参数变量\r函数体内可以使用参数变量，获取函数参数。函数的参数变量，与脚本参数变量是一致的。\n$1~$9：函数的第一个到第9个的参数。 $0：函数所在的脚本名。 $#：函数的参数总数。 $@：函数的全部参数，参数之间使用空格分隔。 $*：函数的全部参数，参数之间使用变量$IFS值的第一个字符分隔，默认为空格，但是可以自定义。 如果函数的参数多于9个，那么第10个参数可以用**${10}的形式引用**，以此类推。\n下面是一个示例脚本test.sh。\n1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash # test.sh function alice { echo \u0026#34;alice: $@\u0026#34; echo \u0026#34;$0: $1 $2 $3 $4\u0026#34; echo \u0026#34;$# arguments\u0026#34; } alice in wonderland 运行该脚本，结果如下。\n1 2 3 4 $ bash test.sh alice: in wonderland test.sh: in wonderland 2 arguments 上面例子中，由于函数alice只有第一个和第二个参数，所以第三个和第四个参数为空。\n下面是一个日志函数的例子。\n1 2 3 function log_msg { echo \u0026#34;[`date \u0026#39;+ %F %T\u0026#39;` ]: $@\u0026#34; } 使用方法如下。\n1 2 $ log_msg \u0026#34;This is sample log message\u0026#34; [ 2018-08-16 19:56:34 ]: This is sample log message return 命令\rreturn命令用于从函数返回一个值。函数执行到这条命令，就不再往下执行了，直接返回了。\n1 2 3 function func_return_value { return 10 } 函数将返回值返回给调用者。如果命令行直接执行函数，下一个命令可以用$?拿到返回值。\n1 2 3 $ func_return_value $ echo \u0026#34;Value returned by function is: $?\u0026#34; Value returned by function is: 10 return后面不跟参数，只用于返回也是可以的。\n1 2 3 4 function name { commands return } 全局变量和局部变量，local 命令\rBash 函数体内直接声明的变量，属于全局变量，整个脚本都可以读取。这一点需要特别小心。\n1 2 3 4 5 6 7 8 # 脚本 test.sh fn () { foo=1 echo \u0026#34;fn: foo = $foo\u0026#34; } fn echo \u0026#34;global: foo = $foo\u0026#34; 上面脚本的运行结果如下。\n1 2 3 $ bash test.sh fn: foo = 1 global: foo = 1 上面例子中，变量$foo是在函数fn内部声明的，函数体外也可以读取。\n函数体内不仅可以声明全局变量，还可以修改全局变量。\n1 2 3 4 5 6 7 8 9 10 #! /bin/bash foo=1 fn () { foo=2 } fn echo $foo 上面代码执行后，输出的变量$foo值为2。\n函数里面可以用local命令声明局部变量。\n1 2 3 4 5 6 7 8 9 10 #! /bin/bash # 脚本 test.sh fn () { local foo foo=1 echo \u0026#34;fn: foo = $foo\u0026#34; } fn echo \u0026#34;global: foo = $foo\u0026#34; 上面脚本的运行结果如下。\n1 2 3 $ bash test.sh fn: foo = 1 global: foo = 上面例子中，local命令声明的$foo变量，只在函数体内有效，函数体外没有定义。\n参考链接\rHow to define and use functions in Linux Shell Script, by Pradeep Kumar ","date":"2025-10-20T15:44:20Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_function/","title":"Bash_function"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n循环\rBash 提供三种循环语法for、while和until。\nwhile 循环\rwhile循环有一个判断条件，只要符合条件，就不断循环执行指定的语句。\n1 2 3 while condition; do commands done 上面代码中，只要满足条件condition，就会执行命令commands。然后，再次判断是否满足条件condition，只要满足，就会一直执行下去。只有不满足条件，才会退出循环。\n循环条件condition可以使用test命令，跟if结构的判断条件写法一致。\n1 2 3 4 5 6 7 #!/bin/bash number=0 while [ \u0026#34;$number\u0026#34; -lt 10 ]; do echo \u0026#34;Number = $number\u0026#34; number=$((number + 1)) done 上面例子中，只要变量$number小于10，就会不断加1，直到$number等于10，然后退出循环。\n关键字do可以跟while不在同一行，这时两者之间不需要使用分号分隔。\n1 2 3 4 while true do echo \u0026#39;Hi, while looping ...\u0026#39;; done 上面的例子会无限循环，可以按下 Ctrl + c 停止。\nwhile循环写成一行，也是可以的。\n1 $ while true; do echo \u0026#39;Hi, while looping ...\u0026#39;; done while的条件部分也可以是执行一个命令。\n1 $ while echo \u0026#39;ECHO\u0026#39;; do echo \u0026#39;Hi, while looping ...\u0026#39;; done 上面例子中，判断条件是echo 'ECHO'。由于这个命令总是执行成功，所以上面命令会产生无限循环。\nwhile的条件部分可以执行任意数量的命令，但是执行结果的真伪只看最后一个命令的执行结果。\n1 $ while true; false; do echo \u0026#39;Hi, looping ...\u0026#39;; done 上面代码运行后，不会有任何输出，因为while的最后一个命令是false。\nuntil 循环\runtil循环与while循环恰好相反，只要不符合判断条件（判断条件失败），就不断循环执行指定的语句。一旦符合判断条件，就退出循环。\n1 2 3 until condition; do commands done 关键字do可以与until不写在同一行，这时两者之间不需要分号分隔。\n1 2 3 4 until condition do commands done 下面是一个例子。\n1 2 3 4 5 $ until false; do echo \u0026#39;Hi, until looping ...\u0026#39;; done Hi, until looping ... Hi, until looping ... Hi, until looping ... ^C 上面代码中，until的部分一直为false，导致命令无限运行，必须按下 Ctrl + c 终止。\n1 2 3 4 5 6 7 #!/bin/bash number=0 until [ \u0026#34;$number\u0026#34; -ge 10 ]; do echo \u0026#34;Number = $number\u0026#34; number=$((number + 1)) done 上面例子中，只要变量number小于10，就会不断加1，直到number大于等于10，就退出循环。\nuntil的条件部分也可以是一个命令，表示在这个命令执行成功之前，不断重复尝试。\n1 2 3 4 until cp $1 $2; do echo \u0026#39;Attempt to copy failed. waiting...\u0026#39; sleep 5 done 上面例子表示，只要cp $1 $2这个命令执行不成功，就5秒钟后再尝试一次，直到成功为止。\nuntil循环都可以转为while循环，只要把条件设为否定即可。上面这个例子可以改写如下。\n1 2 3 4 while ! cp $1 $2; do echo \u0026#39;Attempt to copy failed. waiting...\u0026#39; sleep 5 done 一般来说，until用得比较少，完全可以统一都使用while。\nfor\u0026hellip;in 循环\rfor...in循环用于遍历列表的每一项。\n1 2 3 4 for variable in list do commands done 上面语法中，for循环会依次从list列表中取出一项，作为变量variable，然后在循环体中进行处理。\n关键词do可以跟for写在同一行，两者使用分号分隔。\n1 2 3 for variable in list; do commands done 下面是一个例子。\n1 2 3 4 5 #!/bin/bash for i in word1 word2 word3; do echo $i done 上面例子中，word1 word2 word3是一个包含三个单词的列表，变量i依次等于word1、word2、word3，命令echo $i则会相应地执行三次。\n列表可以由通配符产生。\n1 2 3 for i in *.png; do ls -l $i done 上面例子中，*.png会替换成当前目录中所有 PNG 图片文件，变量i会依次等于每一个文件。\n列表也可以通过子命令产生。\n1 2 3 4 5 6 7 #!/bin/bash count=0 for i in $(cat ~/.bash_profile); do count=$((count + 1)) echo \u0026#34;Word $count ($i) contains $(echo -n $i | wc -c) characters\u0026#34; done 上面例子中，cat ~/.bash_profile命令会输出~/.bash_profile文件的内容，然后通过遍历每一个词，计算该文件一共包含多少个词，以及每个词有多少个字符。\nin list的部分可以省略，这时list默认等于脚本的所有参数$@。但是，为了可读性，最好还是不要省略，参考下面的例子。\n1 2 3 4 5 6 7 8 9 for filename; do echo \u0026#34;$filename\u0026#34; done # 等同于 for filename in \u0026#34;$@\u0026#34; ; do echo \u0026#34;$filename\u0026#34; done 在函数体中也是一样的，for...in循环省略in list的部分，则list默认等于函数的所有参数。\nfor 循环\rfor循环还支持 C 语言的循环语法。\n1 2 3 for (( expression1; expression2; expression3 )); do commands done 上面代码中，expression1用来初始化循环条件，expression2用来决定循环结束的条件，expression3在每次循环迭代的末尾执行，用于更新值。\n注意，循环条件放在双重圆括号之中。另外，圆括号之中使用变量，不必加上美元符号$。\n它等同于下面的while循环。\n1 2 3 4 5 (( expression1 )) while (( expression2 )); do commands (( expression3 )) done 下面是一个例子。\n1 2 3 for (( i=0; i\u0026lt;5; i=i+1 )); do echo $i done 上面代码中，初始化变量i的值为0，循环执行的条件是i小于5。每次循环迭代结束时，i的值加1。\nfor条件部分的三个语句，都可以省略。\n1 2 3 4 5 6 7 for ((;;)) do read var if [ \u0026#34;$var\u0026#34; = \u0026#34;.\u0026#34; ]; then break fi done 上面脚本会反复读取命令行输入，直到用户输入了一个点（.）为止，才会跳出循环。\nbreak，continue\rBash 提供了两个内部命令break和continue，用来在循环内部跳出循环。\nbreak命令立即终止循环，程序继续执行循环块之后的语句，即不再执行剩下的循环。\n1 2 3 4 5 6 7 8 9 #!/bin/bash for number in 1 2 3 4 5 6 do echo \u0026#34;number is $number\u0026#34; if [ \u0026#34;$number\u0026#34; = \u0026#34;3\u0026#34; ]; then break fi done 上面例子只会打印3行结果。一旦变量$number等于3，就会跳出循环，不再继续执行。\ncontinue命令立即终止本轮循环，开始执行下一轮循环。\n1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash while read -p \u0026#34;What file do you want to test?\u0026#34; filename do if [ ! -e \u0026#34;$filename\u0026#34; ]; then echo \u0026#34;The file does not exist.\u0026#34; continue fi echo \u0026#34;You entered a valid file..\u0026#34; done 上面例子中，只要用户输入的文件不存在，continue命令就会生效，直接进入下一轮循环（让用户重新输入文件名），不再执行后面的打印语句。\nselect 结构\rselect结构主要用来生成简单的菜单。它的语法与for...in循环基本一致。\n1 2 3 4 5 select name [in list] do commands done Bash 会对select依次进行下面的处理。\nselect生成一个菜单，内容是列表list的每一项，并且每一项前面还有一个数字编号。 Bash 提示用户选择一项，输入它的编号。 用户输入以后，Bash 会将该项的内容存在变量name，该项的编号存入环境变量REPLY。如果用户没有输入，就按回车键，Bash 会重新输出菜单，让用户选择。 执行命令体commands。 执行结束后，回到第一步，重复这个过程。 下面是一个例子。\n1 2 3 4 5 6 7 #!/bin/bash # select.sh select brand in Samsung Sony iphone symphony Walton do echo \u0026#34;You have chosen $brand\u0026#34; done 执行上面的脚本，Bash 会输出一个品牌的列表，让用户选择。\n1 2 3 4 5 6 7 $ ./select.sh 1) Samsung 2) Sony 3) iphone 4) symphony 5) Walton #? 如果用户没有输入编号，直接按回车键。Bash 就会重新输出一遍这个菜单，直到用户按下Ctrl + c，退出执行。\nselect可以与case结合，针对不同项，执行不同的命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash echo \u0026#34;Which Operating System do you like?\u0026#34; select os in Ubuntu LinuxMint Windows8 Windows10 WindowsXP do case $os in \u0026#34;Ubuntu\u0026#34;|\u0026#34;LinuxMint\u0026#34;) echo \u0026#34;I also use $os.\u0026#34; ;; \u0026#34;Windows8\u0026#34; | \u0026#34;Windows10\u0026#34; | \u0026#34;WindowsXP\u0026#34;) echo \u0026#34;Why don\u0026#39;t you try Linux?\u0026#34; ;; *) echo \u0026#34;Invalid entry.\u0026#34; break ;; esac done 上面例子中，case针对用户选择的不同项，执行不同的命令。\n参考链接\rBash Select Command, Fahmida Yesmin ","date":"2025-10-20T15:43:28Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_loop/","title":"Bash_loop"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n条件判断\r本章介绍 Bash 脚本的条件判断语法。\nif 结构\rif是最常用的条件判断结构，只有符合给定条件时，才会执行指定的命令。它的语法如下。\n1 2 3 4 5 6 7 if commands; then commands [elif commands; then commands...] [else commands] fi 这个命令分成三个部分：if、elif和else。其中，后两个部分是可选的。\nif关键字后面是主要的判断条件，elif用来添加在主条件不成立时的其他判断条件，else则是所有条件都不成立时要执行的部分。\n1 2 3 4 5 if test $USER = \u0026#34;foo\u0026#34;; then echo \u0026#34;Hello foo.\u0026#34; else echo \u0026#34;You are not foo.\u0026#34; fi 上面的例子中，判断条件是环境变量$USER是否等于foo，如果等于就输出Hello foo.，否则输出其他内容。\nif和then写在同一行时，需要分号分隔。分号是 Bash 的命令分隔符。它们也可以写成两行，这时不需要分号。\n1 2 3 4 5 6 7 8 9 if true then echo \u0026#39;hello world\u0026#39; fi if false then echo \u0026#39;it is false\u0026#39; # 本行不会执行 fi 上面的例子中，true和false是两个特殊命令，前者代表操作成功，后者代表操作失败。if true意味着命令部分总是会执行，if false意味着命令部分永远不会执行。\n除了多行的写法，if结构也可以写成单行。\n1 2 3 4 $ if true; then echo \u0026#39;hello world\u0026#39;; fi hello world $ if false; then echo \u0026#34;It\u0026#39;s true.\u0026#34;; fi 注意，if关键字后面也可以是一条命令，该条命令执行成功（返回值0），就意味着判断条件成立。\n1 2 3 $ if echo \u0026#39;hi\u0026#39;; then echo \u0026#39;hello world\u0026#39;; fi hi hello world 上面命令中，if后面是一条命令echo 'hi'。该命令会执行，如果返回值是0，则执行then的部分。\nif后面可以跟任意数量的命令。这时，所有命令都会执行，但是判断真伪只看最后一个命令，即使前面所有命令都失败，只要最后一个命令返回0，就会执行then的部分。\n1 2 $ if false; true; then echo \u0026#39;hello world\u0026#39;; fi hello world 上面例子中，if后面有两条命令（false;true;），第二条命令（true）决定了then的部分是否会执行。\nelif部分可以有多个。\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash echo -n \u0026#34;输入一个1到3之间的数字（包含两端）\u0026gt; \u0026#34; read character if [ \u0026#34;$character\u0026#34; = \u0026#34;1\u0026#34; ]; then echo 1 elif [ \u0026#34;$character\u0026#34; = \u0026#34;2\u0026#34; ]; then echo 2 elif [ \u0026#34;$character\u0026#34; = \u0026#34;3\u0026#34; ]; then echo 3 else echo 输入不符合要求 fi 上面例子中，如果用户输入3，就会连续判断3次。\ntest 命令\rif结构的判断条件，一般使用test命令，有三种形式。\n1 2 3 4 5 6 7 8 # 写法一 test expression # 写法二 [ expression ] # 写法三 [[ expression ]] 上面三种形式是等价的，但是第三种形式还支持正则判断，前两种不支持。\n上面的expression是一个表达式。这个表达式为真，test命令执行成功（返回值为0）；表达式为伪，test命令执行失败（返回值为1）。注意，第二种和第三种写法，[和]与内部的表达式之间必须有空格。\n1 2 3 4 5 6 7 $ test -f /etc/hosts $ echo $? 0 $ [ -f /etc/hosts ] $ echo $? 0 上面的例子中，test命令采用两种写法，判断/etc/hosts文件是否存在，这两种写法是等价的。命令执行后，返回值为0，表示该文件确实存在。\n实际上，[这个字符是test命令的一种简写形式，可以看作是一个独立的命令，这解释了为什么它后面必须有空格。\n下面把test命令的三种形式，用在if结构中，判断一个文件是否存在。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 写法一 if test -e /tmp/foo.txt ; then echo \u0026#34;Found foo.txt\u0026#34; fi # 写法二 if [ -e /tmp/foo.txt ] ; then echo \u0026#34;Found foo.txt\u0026#34; fi # 写法三 if [[ -e /tmp/foo.txt ]] ; then echo \u0026#34;Found foo.txt\u0026#34; fi 判断表达式\rif关键字后面，跟的是一个命令。这个命令可以是test命令，也可以是其他命令。命令的返回值为0表示判断成立，否则表示不成立。因为这些命令主要是为了得到返回值，所以可以视为表达式。\n常用的判断表达式有下面这些。\n文件判断\r以下表达式用来判断文件状态。\n常用的有：\n[ -e file ]：如果 file 存在（任何类型），则为true。\n[ -d file ]：如果 file 存在并且是一个目录，则为true。\n[ -f file ]：如果 file 存在并且是一个普通文件，则为true。\n[ -r file ]：如果 file 存在并且可读（当前用户有可读权限），则为true。\n[ -w file ]：如果 file 存在并且可写（当前用户拥有可写权限），则为true。\n[ -x file ]：如果 file 存在并且可执行（有效用户有执行／搜索权限），则为true。\n[ -s file ]：如果 file 存在且其长度大于零，则为true。\n[ -L file ]：如果 file 存在并且是一个符号链接，则为true。\n[ -h file ]：如果 file 存在并且是符号链接，则为true。\n其余的有：\n[ -b file ]：如果 file 存在并且是一个块（设备）文件，则为true。 [ -c file ]：如果 file 存在并且是一个字符（设备）文件，则为true。 [ -g file ]：如果 file 存在并且设置了组 ID，则为true。 [ -G file ]：如果 file 存在并且属于有效的组 ID，则为true。 [ -k file ]：如果 file 存在并且设置了它的“sticky bit”，则为true。 [ -N file ]：如果 file 存在并且自上次读取后已被修改，则为true。 [ -O file ]：如果 file 存在并且属于有效的用户 ID，则为true。 [ -p file ]：如果 file 存在并且是一个命名管道，则为true。 [ -S file ]：如果 file 存在且是一个网络 socket，则为true。 [ -t fd ]：如果 fd 是一个文件描述符，并且重定向到终端，则为true。 这可以用来判断是否重定向了标准输入／输出／错误。 [ -u file ]：如果 file 存在并且设置了 setuid 位，则为true。 [ FILE1 -nt FILE2 ]：如果 FILE1 比 FILE2 的更新时间更近，或者 FILE1 存在而 FILE2 不存在，则为true。 [ FILE1 -ot FILE2 ]：如果 FILE1 比 FILE2 的更新时间更旧，或者 FILE2 存在而 FILE1 不存在，则为true。 [ FILE1 -ef FILE2 ]：如果 FILE1 和 FILE2 引用相同的设备和 inode 编号，则为true。 普通文件说明：\n在 Linux/Unix 中，“普通文件”（regular file） 是指：\n不是目录 不是设备文件（如 /dev/sda） 不是符号链接 不是管道、socket、FIFO 等特殊文件 而是我们日常接触最多的文件类型，例如：\n文本文件：notes.txt 脚本文件：script.sh 二进制程序：/bin/ls 图片、视频、压缩包等 用 ls -l 查看时，普通文件的权限行第一个字符是 -：\n1 2 3 $ ls -l /etc/passwd -rw-r--r-- 1 root root 2345 Jun 10 10:00 /etc/passwd # ↑ 开头是 \u0026#34;-\u0026#34;，说明是普通文件 而目录是 d，符号链接是 l，设备文件是 b 或 c，等等。\n符号链接说明：\n只是一个路径引用 符号链接文件的内容就是目标文件的路径（可以是相对路径或绝对路径） 可以跨文件系统 源文件和目标文件可以在不同的磁盘或分区上 目标可以不存在 创建符号链接时，目标文件甚至可以不存在（称为“悬空链接”） 删除符号链接不影响原文件 删除软链接只是删了“快捷方式”，原文件完好无损 删除原文件会导致链接失效 原文件没了，符号链接就变成“坏链接”（dangling symlink） 下面是一个示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash FILE=~/.bashrc if [ -e \u0026#34;$FILE\u0026#34; ]; then if [ -f \u0026#34;$FILE\u0026#34; ]; then echo \u0026#34;$FILE is a regular file.\u0026#34; fi if [ -d \u0026#34;$FILE\u0026#34; ]; then echo \u0026#34;$FILE is a directory.\u0026#34; fi if [ -r \u0026#34;$FILE\u0026#34; ]; then echo \u0026#34;$FILE is readable.\u0026#34; fi if [ -w \u0026#34;$FILE\u0026#34; ]; then echo \u0026#34;$FILE is writable.\u0026#34; fi if [ -x \u0026#34;$FILE\u0026#34; ]; then echo \u0026#34;$FILE is executable/searchable.\u0026#34; fi else echo \u0026#34;$FILE does not exist\u0026#34; exit 1 fi 上面代码中，$FILE要放在双引号之中，这样可以防止变量$FILE为空，从而出错。因为$FILE如果为空，这时[ -e $FILE ]就变成[ -e ]，这会被判断为真。而$FILE放在双引号之中，[ -e \u0026quot;$FILE\u0026quot; ]就变成[ -e \u0026quot;\u0026quot; ]，这会被判断为伪。\n字符串判断\r以下表达式用来判断字符串。\n[ string ]：如果string不为空（长度大于0），则判断为真。 [ -n string ]：如果字符串string的长度大于零，则判断为真。 [ -z string ]：如果字符串string的长度为零，则判断为真。 [ string1 = string2 ]：如果string1和string2相同，则判断为真。 [ string1 == string2 ] 等同于[ string1 = string2 ]。 [ string1 != string2 ]：如果string1和string2不相同，则判断为真。 [ string1 '\u0026gt;' string2 ]：如果按照字典顺序string1排列在string2之后，则判断为真。 [ string1 '\u0026lt;' string2 ]：如果按照字典顺序string1排列在string2之前，则判断为真。 注意，test命令内部的\u0026gt;和\u0026lt;，必须用引号引起来（或者是用反斜杠转义）。否则，它们会被 shell 解释为重定向操作符。\n下面是一个示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash ANSWER=maybe if [ -z \u0026#34;$ANSWER\u0026#34; ]; then echo \u0026#34;There is no answer.\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi if [ \u0026#34;$ANSWER\u0026#34; = \u0026#34;yes\u0026#34; ]; then echo \u0026#34;The answer is YES.\u0026#34; elif [ \u0026#34;$ANSWER\u0026#34; = \u0026#34;no\u0026#34; ]; then echo \u0026#34;The answer is NO.\u0026#34; elif [ \u0026#34;$ANSWER\u0026#34; = \u0026#34;maybe\u0026#34; ]; then echo \u0026#34;The answer is MAYBE.\u0026#34; else echo \u0026#34;The answer is UNKNOWN.\u0026#34; fi 上面代码中，首先确定$ANSWER字符串是否为空。如果为空，就终止脚本，并把退出状态设为1。注意，这里的echo命令把错误信息There is no answer.重定向到标准错误，这是处理错误信息的常用方法。如果$ANSWER字符串不为空，就判断它的值是否等于yes、no或者maybe。\n注意，字符串判断时，变量要放在双引号之中，比如[ -n \u0026quot;$COUNT\u0026quot; ]，否则变量替换成字符串以后，test命令可能会报错，提示参数过多。另外，如果不放在双引号之中，变量为空时，命令会变成[ -n ]，这时会判断为真。如果放在双引号之中，[ -n \u0026quot;\u0026quot; ]就判断为伪。\n整数判断\r下面的表达式用于判断整数。\n[ integer1 -eq integer2 ]：如果integer1等于integer2，则为true。 [ integer1 -ne integer2 ]：如果integer1不等于integer2，则为true。 [ integer1 -le integer2 ]：如果integer1小于或等于integer2，则为true。 [ integer1 -lt integer2 ]：如果integer1小于integer2，则为true。 [ integer1 -ge integer2 ]：如果integer1大于或等于integer2，则为true。 [ integer1 -gt integer2 ]：如果integer1大于integer2，则为true。 下面是一个用法的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash INT=-5 if [ -z \u0026#34;$INT\u0026#34; ]; then echo \u0026#34;INT is empty.\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi if [ $INT -eq 0 ]; then echo \u0026#34;INT is zero.\u0026#34; else if [ $INT -lt 0 ]; then echo \u0026#34;INT is negative.\u0026#34; else echo \u0026#34;INT is positive.\u0026#34; fi if [ $((INT % 2)) -eq 0 ]; then echo \u0026#34;INT is even.\u0026#34; else echo \u0026#34;INT is odd.\u0026#34; fi fi 上面例子中，先判断变量$INT是否为空，然后判断是否为0，接着判断正负，最后通过求余数判断奇偶。\n如果不好记，想用数学符号，可以用(( ))包含数学表达式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 a=5 b=10 if (( a \u0026lt; b )); then echo \u0026#34;a \u0026lt; b 成立\u0026#34; fi if (( a == b )); then echo \u0026#34;相等\u0026#34; fi if (( a != b )); then echo \u0026#34;不等\u0026#34; fi 注意整数相等是双等号，字符串相等是单等号。\n正则判断\r[[ expression ]]这种判断形式，支持正则表达式。\n1 [[ string1 =~ regex ]] 上面的语法中，regex是一个正则表示式，=~是正则比较运算符。\n下面是一个例子。\n1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash INT=-5 if [[ \u0026#34;$INT\u0026#34; =~ ^-?[0-9]+$ ]]; then echo \u0026#34;INT is an integer.\u0026#34; exit 0 else echo \u0026#34;INT is not an integer.\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi 上面代码中，先判断变量INT的字符串形式，是否满足^-?[0-9]+$的正则模式，如果满足就表明它是一个整数。\ntest 判断的逻辑运算\r通过逻辑运算，可以把多个test判断表达式结合起来，创造更复杂的判断。三种逻辑运算AND，OR，和NOT，都有自己的专用符号。\nAND运算：符号\u0026amp;\u0026amp;，也可使用参数-a。 OR运算：符号||，也可使用参数-o。 NOT运算：符号!。 下面是一个AND的例子，判断整数是否在某个范围之内。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/bin/bash MIN_VAL=1 MAX_VAL=100 INT=50 if [[ \u0026#34;$INT\u0026#34; =~ ^-?[0-9]+$ ]]; then if [[ $INT -ge $MIN_VAL \u0026amp;\u0026amp; $INT -le $MAX_VAL ]]; then echo \u0026#34;$INT is within $MIN_VAL to $MAX_VAL.\u0026#34; else echo \u0026#34;$INT is out of range.\u0026#34; fi else echo \u0026#34;INT is not an integer.\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi 上面例子中，\u0026amp;\u0026amp;用来连接两个判断条件：大于等于$MIN_VAL，并且小于等于$MAX_VAL。\n使用否定操作符!时，最好用圆括号确定转义的范围。\n1 2 3 4 5 if [ ! \\( $INT -ge $MIN_VAL -a $INT -le $MAX_VAL \\) ]; then echo \u0026#34;$INT is outside $MIN_VAL to $MAX_VAL.\u0026#34; else echo \u0026#34;$INT is in range.\u0026#34; fi 上面例子中，test命令内部使用的圆括号，必须使用引号或者转义，否则会被 Bash 解释。\n使用-a连接两个判断条件不太直观，一般推荐使用\u0026amp;\u0026amp;代替，上面的脚本可以改写成下面这样。\n1 2 3 4 5 if !([ $INT -ge $MIN_VAL ] \u0026amp;\u0026amp; [ $INT -le $MAX_VAL ]); then echo \u0026#34;$INT is outside $MIN_VAL to $MAX_VAL.\u0026#34; else echo \u0026#34;$INT is in range.\u0026#34; fi 算术判断\rBash 还提供了((...))作为算术条件，进行算术运算的判断。\n1 2 3 if ((3 \u0026gt; 2)); then echo \u0026#34;true\u0026#34; fi 上面代码执行后，会打印出true。\n注意，算术判断不需要使用test命令，而是直接使用((...))结构。这个结构的返回值，决定了判断的真伪。\n如果算术计算的结果是非零值，则表示判断成立。这一点跟命令的返回值正好相反，需要小心。\n1 2 3 4 $ if ((1)); then echo \u0026#34;It is true.\u0026#34;; fi It is true. $ if ((0)); then echo \u0026#34;It is true.\u0026#34;; else echo \u0026#34;it is false.\u0026#34;; fi It is false. 上面例子中，((1))表示判断成立，((0))表示判断不成立。\n算术条件((...))也可以用于变量赋值。\n1 2 $ if (( foo = 5 ));then echo \u0026#34;foo is $foo\u0026#34;; fi foo is 5 上面例子中，(( foo = 5 ))完成了两件事情。首先把5赋值给变量foo，然后根据返回值5，判断条件为真。\n注意，赋值语句返回等号右边的值，如果返回的是0，则判断为假。\n1 2 $ if (( foo = 0 ));then echo \u0026#34;It is true.\u0026#34;;else echo \u0026#34;It is false.\u0026#34;; fi It is false. 下面是用算术条件改写的数值判断脚本。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/bin/bash INT=-5 if [[ \u0026#34;$INT\u0026#34; =~ ^-?[0-9]+$ ]]; then if ((INT == 0)); then echo \u0026#34;INT is zero.\u0026#34; else if ((INT \u0026lt; 0)); then echo \u0026#34;INT is negative.\u0026#34; else echo \u0026#34;INT is positive.\u0026#34; fi if (( ((INT % 2)) == 0)); then echo \u0026#34;INT is even.\u0026#34; else echo \u0026#34;INT is odd.\u0026#34; fi fi else echo \u0026#34;INT is not an integer.\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi 只要是算术表达式，都能用于((...))语法，详见《Bash 的算术运算》一章。\n普通命令的逻辑运算\r如果if结构使用的不是test命令，而是普通命令，比如上一节的((...))算术运算，或者test命令与普通命令混用，那么可以使用 Bash 的命令控制操作符\u0026amp;\u0026amp;（AND）和||（OR），进行多个命令的逻辑运算。\n1 2 $ command1 \u0026amp;\u0026amp; command2 $ command1 || command2 对于\u0026amp;\u0026amp;操作符，先执行command1，只有command1执行成功后， 才会执行command2。对于||操作符，先执行command1，只有command1执行失败后， 才会执行command2。\n1 $ mkdir temp \u0026amp;\u0026amp; cd temp 上面的命令会创建一个名为temp的目录，执行成功后，才会执行第二个命令，进入这个目录。\n1 $ [ -d temp ] || mkdir temp 上面的命令会测试目录temp是否存在，如果不存在，就会执行第二个命令，创建这个目录。这种写法非常有助于在脚本中处理错误。\n1 [ ! -d temp ] \u0026amp;\u0026amp; exit 1 上面的命令中，如果temp子目录不存在，脚本会终止，并且返回值为1。\n下面就是if与\u0026amp;\u0026amp;结合使用的写法。\n1 2 3 if [ condition ] \u0026amp;\u0026amp; [ condition ]; then command fi 下面是一个示例。\n1 2 3 4 5 6 7 8 9 10 #! /bin/bash filename=$1 word1=$2 word2=$3 if grep $word1 $filename \u0026amp;\u0026amp; grep $word2 $filename then echo \u0026#34;$word1 and $word2 are both in $filename.\u0026#34; fi 上面的例子只有在指定文件里面，同时存在搜索词word1和word2，就会执行if的命令部分。\n下面的示例演示如何将一个\u0026amp;\u0026amp;判断表达式，改写成对应的if结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [[ -d \u0026#34;$dir_name\u0026#34; ]] \u0026amp;\u0026amp; cd \u0026#34;$dir_name\u0026#34; \u0026amp;\u0026amp; rm * # 等同于 if [[ ! -d \u0026#34;$dir_name\u0026#34; ]]; then echo \u0026#34;No such directory: \u0026#39;$dir_name\u0026#39;\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi if ! cd \u0026#34;$dir_name\u0026#34;; then echo \u0026#34;Cannot cd to \u0026#39;$dir_name\u0026#39;\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi if ! rm *; then echo \u0026#34;File deletion failed. Check results\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi case 结构\rcase结构用于多值判断，可以为每个值指定对应的命令，跟包含多个elif的if结构等价，但是语义更好。它的语法如下。\n1 2 3 4 5 6 7 case expression in pattern ) commands ;; pattern ) commands ;; ... esac 上面代码中，expression是一个表达式，pattern是表达式的值或者一个模式，可以有多条，用来匹配多个值，每条以两个分号（;）结尾。\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash echo -n \u0026#34;输入一个1到3之间的数字（包含两端）\u0026gt; \u0026#34; read character case $character in 1 ) echo 1 ;; 2 ) echo 2 ;; 3 ) echo 3 ;; * ) echo 输入不符合要求 esac 上面例子中，最后一条匹配语句的模式是*，这个通配符可以匹配其他字符和没有输入字符的情况，类似if的else部分。\n下面是另一个例子。\n1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/bash OS=$(uname -s) case \u0026#34;$OS\u0026#34; in FreeBSD) echo \u0026#34;This is FreeBSD\u0026#34; ;; Darwin) echo \u0026#34;This is Mac OSX\u0026#34; ;; AIX) echo \u0026#34;This is AIX\u0026#34; ;; Minix) echo \u0026#34;This is Minix\u0026#34; ;; Linux) echo \u0026#34;This is Linux\u0026#34; ;; *) echo \u0026#34;Failed to identify this OS\u0026#34; ;; esac 上面的例子判断当前是什么操作系统。\ncase的匹配模式可以使用各种通配符，下面是一些例子。\na)：匹配a。 a|b)：匹配a或b。 [[:alpha:]])：匹配单个字母。 ???)：匹配3个字符的单词。 *.txt)：匹配.txt结尾。 *)：匹配任意输入，通常作为case结构的最后一个模式。 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash echo -n \u0026#34;输入一个字母或数字 \u0026gt; \u0026#34; read character case $character in [[:lower:]] | [[:upper:]] ) echo \u0026#34;输入了字母 $character\u0026#34; ;; [0-9] ) echo \u0026#34;输入了数字 $character\u0026#34; ;; * ) echo \u0026#34;输入不符合要求\u0026#34; esac 上面例子中，使用通配符[[:lower:]] | [[:upper:]]匹配字母，[0-9]匹配数字。\nBash 4.0之前，case结构只能匹配一个条件，然后就会退出case结构。Bash 4.0之后，允许匹配多个条件，这时可以用;;\u0026amp;终止每个条件块。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/bin/bash # test.sh read -n 1 -p \u0026#34;Type a character \u0026gt; \u0026#34; echo case $REPLY in [[:upper:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is upper case.\u0026#34; ;;\u0026amp; [[:lower:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is lower case.\u0026#34; ;;\u0026amp; [[:alpha:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is alphabetic.\u0026#34; ;;\u0026amp; [[:digit:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is a digit.\u0026#34; ;;\u0026amp; [[:graph:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is a visible character.\u0026#34; ;;\u0026amp; [[:punct:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is a punctuation symbol.\u0026#34; ;;\u0026amp; [[:space:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is a whitespace character.\u0026#34; ;;\u0026amp; [[:xdigit:]]) echo \u0026#34;\u0026#39;$REPLY\u0026#39; is a hexadecimal digit.\u0026#34; ;;\u0026amp; esac 执行上面的脚本，会得到下面的结果。\n1 2 3 4 5 6 $ test.sh Type a character \u0026gt; a \u0026#39;a\u0026#39; is lower case. \u0026#39;a\u0026#39; is alphabetic. \u0026#39;a\u0026#39; is a visible character. \u0026#39;a\u0026#39; is a hexadecimal digit. 可以看到条件语句结尾添加了;;\u0026amp;以后，在匹配一个条件之后，并没有退出case结构，而是继续判断下一个条件。\n参考链接\rThe Linux Command Line, William Shotts ","date":"2025-10-20T15:42:22Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_condition/","title":"Bash_condition"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nread 命令\r用法\r有时，脚本需要在执行过程中，由用户提供一部分数据，这时可以使用read命令。它将用户的输入存入一个变量，方便后面的代码使用。用户按下回车键，就表示输入结束。\nread命令的格式如下。\n1 read [-options] [variable...] 上面语法中，options是参数选项，variable是用来保存输入数值的一个或多个变量名。如果没有提供变量名，环境变量REPLY会包含用户输入的一整行数据。\n下面是一个例子demo.sh。\n1 2 3 4 5 #!/bin/bash echo -n \u0026#34;输入一些文本 \u0026gt; \u0026#34; read text echo \u0026#34;你的输入：$text\u0026#34; 上面例子中，先显示一行提示文本，然后会等待用户输入文本。用户输入的文本，存入变量text，在下一行显示出来。\n1 2 3 $ bash demo.sh 输入一些文本 \u0026gt; 你好，世界 你的输入：你好，世界 read可以接受用户输入的多个值。\n1 2 3 4 #!/bin/bash echo Please, enter your firstname and lastname read FN LN echo \u0026#34;Hi! $LN, $FN !\u0026#34; 上面例子中，read根据用户的输入，同时为两个变量赋值。\n如果用户的输入项少于read命令给出的变量数目，那么额外的变量值为空。如果用户的输入项多于定义的变量，那么多余的输入项会包含到最后一个变量中。\n如果read命令之后没有定义变量名，那么环境变量REPLY会包含所有的输入。\n1 2 3 4 5 #!/bin/bash # read-single: read multiple values into default variable echo -n \u0026#34;Enter one or more values \u0026gt; \u0026#34; read echo \u0026#34;REPLY = \u0026#39;$REPLY\u0026#39;\u0026#34; 上面脚本的运行结果如下。\n1 2 3 $ read-single Enter one or more values \u0026gt; a b c d REPLY = \u0026#39;a b c d\u0026#39; read命令除了读取键盘输入，可以用来读取文件。\n1 2 3 4 5 6 7 8 #!/bin/bash filename=\u0026#39;/etc/hosts\u0026#39; while read myline do echo \u0026#34;$myline\u0026#34; done \u0026lt; $filename 上面的例子通过read命令，读取一个文件的内容。done命令后面的定向符\u0026lt;，将文件内容导向read命令，每次读取一行，存入变量myline，直到文件读取完毕。\n参数\rread命令的参数如下。\n（1）-t 参数\nread命令的-t参数，设置了超时的秒数。如果超过了指定时间，用户仍然没有输入，脚本将放弃等待，继续向下执行。\n1 2 3 4 5 6 7 8 #!/bin/bash echo -n \u0026#34;输入一些文本 \u0026gt; \u0026#34; if read -t 3 response; then echo \u0026#34;用户已经输入了\u0026#34; else echo \u0026#34;用户没有输入\u0026#34; fi 上面例子中，输入命令会等待3秒，如果用户超过这个时间没有输入，这个命令就会执行失败。if根据命令的返回值，转入else代码块，继续往下执行。\n环境变量TMOUT也可以起到同样作用，指定read命令等待用户输入的时间（单位为秒）。\n1 2 $ TMOUT=3 $ read response 上面例子也是等待3秒，如果用户还没有输入，就会超时。\n（2）-p 参数\n-p参数指定用户输入的提示信息。\n1 2 read -p \u0026#34;Enter one or more values \u0026gt; \u0026#34; echo \u0026#34;REPLY = \u0026#39;$REPLY\u0026#39;\u0026#34; 上面例子中，先显示Enter one or more values \u0026gt;，再接受用户的输入。\n（3）-a 参数\n-a参数把用户的输入赋值给一个数组，从零号位置开始。\n1 2 3 4 $ read -a people alice duchess dodo $ echo ${people[2]} dodo 上面例子中，用户输入被赋值给一个数组people，这个数组的2号成员就是dodo。\n（4）-n 参数\n-n参数指定只读取若干个字符作为变量值，而不是整行读取。\n1 2 3 4 $ read -n 3 letter abcdefghij $ echo $letter abc 上面例子中，变量letter只包含3个字母。\n（5）-e 参数\n-e参数允许用户输入的时候，使用readline库提供的快捷键，比如自动补全。具体的快捷键可以参阅《行操作》一章。\n1 2 3 4 5 6 7 #!/bin/bash echo Please input the path to the file: read -e fileName echo $fileName 上面例子中，read命令接受用户输入的文件名。这时，用户可能想使用 Tab 键的文件名“自动补全”功能，但是read命令的输入默认不支持readline库的功能。-e参数就可以允许用户使用自动补全。\n（6）其他参数\n-d delimiter：定义字符串delimiter的第一个字符作为用户输入的结束，而不是一个换行符。 -r：raw 模式，表示不把用户输入的反斜杠字符解释为转义字符。 -s：使得用户的输入不显示在屏幕上，这常常用于输入密码或保密信息。 -u fd：使用文件描述符fd作为输入。 IFS 变量\rread命令读取的值，默认是以空格分隔。可以通过自定义环境变量IFS（内部字段分隔符，Internal Field Separator 的缩写），修改分隔标志。\nIFS的默认值是空格、Tab 符号、换行符号，通常取第一个（即空格）。\n如果把IFS定义成冒号（:）或分号（;），就可以分隔以这两个符号分隔的值，这对读取文件很有用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash # read-ifs: read fields from a file FILE=/etc/passwd read -p \u0026#34;Enter a username \u0026gt; \u0026#34; user_name file_info=\u0026#34;$(grep \u0026#34;^$user_name:\u0026#34; $FILE)\u0026#34; if [ -n \u0026#34;$file_info\u0026#34; ]; then IFS=\u0026#34;:\u0026#34; read user pw uid gid name home shell \u0026lt;\u0026lt;\u0026lt; \u0026#34;$file_info\u0026#34; echo \u0026#34;User = \u0026#39;$user\u0026#39;\u0026#34; echo \u0026#34;UID = \u0026#39;$uid\u0026#39;\u0026#34; echo \u0026#34;GID = \u0026#39;$gid\u0026#39;\u0026#34; echo \u0026#34;Full Name = \u0026#39;$name\u0026#39;\u0026#34; echo \u0026#34;Home Dir. = \u0026#39;$home\u0026#39;\u0026#34; echo \u0026#34;Shell = \u0026#39;$shell\u0026#39;\u0026#34; else echo \u0026#34;No such user \u0026#39;$user_name\u0026#39;\u0026#34; \u0026gt;\u0026amp;2 exit 1 fi 上面例子中，IFS设为冒号，然后用来分解/etc/passwd文件的一行。IFS的赋值命令和read命令写在一行，这样的话，IFS的改变仅对后面的命令生效，该命令执行后IFS会自动恢复原来的值。如果不写在一行，就要采用下面的写法。\n1 2 3 4 OLD_IFS=\u0026#34;$IFS\u0026#34; IFS=\u0026#34;:\u0026#34; read user pw uid gid name home shell \u0026lt;\u0026lt;\u0026lt; \u0026#34;$file_info\u0026#34; IFS=\u0026#34;$OLD_IFS\u0026#34; 另外，上面例子中，\u0026lt;\u0026lt;\u0026lt;是 Here 字符串，用于将变量值转为标准输入，因为**read命令只能解析标准输入**。\n如果IFS设为空字符串，就等同于将整行读入一个变量。\n1 2 3 4 5 6 #!/bin/bash input=\u0026#34;/path/to/txt/file\u0026#34; while IFS= read -r line do echo \u0026#34;$line\u0026#34; done \u0026lt; \u0026#34;$input\u0026#34; 上面的命令可以逐行读取文件，每一行存入变量line，打印出来以后再读取下一行。\n","date":"2025-10-20T15:40:37Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_read/","title":"Bash_read"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash 脚本入门\r脚本（script）就是包含一系列命令的一个文本文件。Shell 读取这个文件，依次执行里面的所有命令，就好像这些命令直接输入到命令行一样。所有能够在命令行完成的任务，都能够用脚本完成。\n脚本的好处是可以重复使用，也可以指定在特定场合自动调用，比如系统启动或关闭时自动执行脚本。\nShebang 行\r脚本的第一行通常是指定解释器，即这个脚本必须通过什么解释器执行。这一行以#!字符开头，这个字符称为 Shebang，所以这一行就叫做 Shebang 行。\n#!后面就是脚本解释器的位置，Bash 脚本的解释器一般是/bin/sh或/bin/bash。\n1 2 3 #!/bin/sh # 或者 #!/bin/bash #!与脚本解释器之间有没有空格，都是可以的。\n如果 Bash 解释器不放在目录/bin，脚本就无法执行了。为了保险，可以写成下面这样。\n1 #!/usr/bin/env bash 上面命令使用env命令（这个命令总是在/usr/bin目录），返回 Bash 可执行文件的位置。env命令的详细介绍，请看后文。\nShebang 行不是必需的，但是建议加上这行。如果缺少该行，就需要手动将脚本传给解释器。举例来说，脚本是script.sh，有 Shebang 行的时候，可以直接调用执行。\n1 $ ./script.sh 上面例子中，script.sh是脚本文件名。脚本通常使用.sh后缀名，不过这不是必需的。\n如果没有 Shebang 行，就只能手动将脚本传给解释器来执行。\n1 2 3 $ /bin/sh ./script.sh # 或者 $ bash ./script.sh 执行权限和路径\r前面说过，只要指定了 Shebang 行的脚本，可以直接执行。这有一个前提条件，就是脚本需要有执行权限。可以使用下面的命令，赋予脚本执行权限。\n1 2 3 4 5 6 7 8 9 10 # 给所有用户执行权限 $ chmod +x script.sh # 给所有用户读权限和执行权限 $ chmod +rx script.sh # 或者 $ chmod 755 script.sh # 只给脚本拥有者读权限和执行权限 $ chmod u+rx script.sh 脚本的权限通常设为755（拥有者有所有权限，其他人有读和执行权限）或者700（只有拥有者可以执行）。\n除了执行权限，脚本调用时，一般需要指定脚本的路径（比如path/script.sh）。如果将脚本放在环境变量$PATH指定的目录中，就不需要指定路径了。因为 Bash 会自动到这些目录中，寻找是否存在同名的可执行文件。\n建议在主目录新建一个~/bin子目录，专门存放可执行脚本，然后把~/bin加入$PATH。\n1 export PATH=$PATH:~/bin 上面命令改变环境变量$PATH，将~/bin添加到$PATH的末尾。可以将这一行加到~/.bashrc文件里面，然后重新加载一次.bashrc，这个配置就可以生效了。\n1 $ source ~/.bashrc 以后不管在什么目录，直接输入脚本文件名，脚本就会执行。\n1 $ script.sh 上面命令没有指定脚本路径，因为script.sh在$PATH指定的目录中。\nenv 命令\renv命令总是指向/usr/bin/env文件，或者说，这个二进制文件总是在目录/usr/bin。\n#!/usr/bin/env NAME这个语法的意思是，让 Shell 查找$PATH环境变量里面第一个匹配的NAME。如果你不知道某个命令的具体路径，或者希望兼容其他用户的机器，这样的写法就很有用。\n/usr/bin/env bash的意思就是，返回bash可执行文件的位置，前提是bash的路径是在$PATH里面。其他脚本文件也可以使用这个命令。比如 Node.js 脚本的 Shebang 行，可以写成下面这样。\n1 #!/usr/bin/env node env命令的参数如下。\n-i, --ignore-environment：不带环境变量启动。 -u, --unset=NAME：从环境变量中删除一个变量。 --help：显示帮助。 --version：输出版本信息。 下面是一个例子，新建一个不带任何环境变量的 Shell。\n1 $ env -i /bin/sh 注释\rBash 脚本中，#表示注释，可以放在行首，也可以放在行尾。\n1 2 3 4 # 本行是注释 echo \u0026#39;Hello World!\u0026#39; echo \u0026#39;Hello World!\u0026#39; # 井号后面的部分也是注释 建议在脚本开头，使用注释说明当前脚本的作用，这样有利于日后的维护。\n脚本参数\r调用脚本的时候，脚本文件名后面可以带有参数。\n1 $ script.sh word1 word2 word3 上面例子中，script.sh是一个脚本文件，word1、word2和word3是三个参数。\n脚本文件内部，可以使用特殊变量，引用这些参数。\n$0：脚本文件名，即script.sh。 $1~$9：对应脚本的第一个参数到第九个参数。 $#：参数的总数。 $@：全部的参数，参数之间使用空格分隔。 $*：全部的参数，参数之间使用变量$IFS值的第一个字符分隔，默认为空格，但是可以自定义。 如果脚本的参数多于9个，那么第10个参数可以用${10}的形式引用，以此类推。\n注意，如果命令是command -o foo bar，那么-o是$1，foo是$2，bar是$3。\n下面是一个脚本内部读取命令行参数的例子。\n1 2 3 4 5 6 7 8 9 #!/bin/bash # script.sh echo \u0026#34;全部参数：\u0026#34; $@ echo \u0026#34;命令行参数数量：\u0026#34; $# echo \u0026#39;$0 = \u0026#39; $0 echo \u0026#39;$1 = \u0026#39; $1 echo \u0026#39;$2 = \u0026#39; $2 echo \u0026#39;$3 = \u0026#39; $3 执行结果如下。\n1 2 3 4 5 6 7 $ ./script.sh a b c 全部参数：a b c 命令行参数数量：3 $0 = script.sh $1 = a $2 = b $3 = c 用户可以输入任意数量的参数，利用for循环，可以读取每一个参数。\n1 2 3 4 5 #!/bin/bash for i in \u0026#34;$@\u0026#34;; do echo $i done 上面例子中，$@返回一个全部参数的列表，然后使用for循环遍历。\n如果多个参数放在双引号里面，视为一个参数。\n1 $ ./script.sh \u0026#34;a b\u0026#34; 上面例子中，Bash 会认为\u0026quot;a b\u0026quot;是一个参数，$1会返回a b。注意，返回时不包括双引号。\nshift 命令\rshift命令可以改变脚本参数，每次执行都会移除脚本当前的第一个参数（$1），使得后面的参数向前一位，即$2变成$1、$3变成$2、$4变成$3，以此类推。\nwhile循环结合shift命令，也可以读取每一个参数。\n1 2 3 4 5 6 7 8 9 #!/bin/bash echo \u0026#34;一共输入了 $# 个参数\u0026#34; while [ \u0026#34;$1\u0026#34; != \u0026#34;\u0026#34; ]; do echo \u0026#34;剩下 $# 个参数\u0026#34; echo \u0026#34;参数：$1\u0026#34; shift done 上面例子中，shift命令每次移除当前第一个参数，从而通过while循环遍历所有参数。\nshift命令可以接受一个整数作为参数，指定所要移除的参数个数，默认为1。\n1 shift 3 上面的命令移除前三个参数，原来的$4变成$1。\ngetopts 命令\rgetopts命令用在脚本内部，可以解析复杂的脚本命令行参数，通常与while循环一起使用，取出脚本所有的带有前置连词线（-）的参数。\n1 getopts optstring name 它带有两个参数。\n第一个参数optstring是字符串，给出脚本所有的连词线参数（可接受的所有选项参数）。比如，某个脚本可以有三个配置项参数-l、-h、-a，其中只有-a可以带有参数值，而-l和-h是开关参数，那么getopts的第一个参数写成lha:，顺序不重要。注意，a后面有一个冒号，表示该参数带有参数值，getopts规定带有参数值的配置项参数，后面必须带有一个冒号（:）。\ngetopts的第二个参数name是一个变量名，用来保存当前取到的配置项参数，即l、h或a，当前解析到的所有选项字母会被存进去。\ngetopts 不会自己接收参数列表，而是默认自动从脚本的 $1, $2, $3\u0026hellip; 中按顺序读取。 即**每次调用，是按序从参数列表里往后读取的。**如果读取的参数是连词线参数并且符合optstring，才会临时存在name里面。\n下面是一个例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 while getopts \u0026#39;lha:\u0026#39; OPTION; do case \u0026#34;$OPTION\u0026#34; in l) echo \u0026#34;linuxconfig\u0026#34; ;; h) echo \u0026#34;h stands for h\u0026#34; ;; a) # OPTARG 是当前选项的参数值（临时变量） avalue=\u0026#34;$OPTARG\u0026#34; echo \u0026#34;The value provided is $OPTARG\u0026#34; ;; ?) echo \u0026#34;script usage: $(basename $0) [-l] [-h] [-a somevalue]\u0026#34; \u0026gt;\u0026amp;2 exit 1 ;; esac done shift \u0026#34;$(($OPTIND - 1))\u0026#34; 上面例子中，while循环不断执行getopts 'lha:' OPTION命令，每次执行就会读取一个连词线参数（以及对应的参数值），然后进入循环体。变量OPTION保存的是，当前处理的那一个连词线参数（即l、h或a）。如果用户输入了没有指定的参数（比如-x），那么OPTION等于?。循环体内使用case判断，处理这四种不同的情况。\n如果某个连词线参数带有参数值，比如-a foo，那么处理a参数的时候，环境变量$OPTARG保存的就是参数值。\n注意，只要遇到不带连词线的参数，getopts就会执行失败，从而退出while循环。比如，getopts可以解析command -l foo，但不可以解析command foo -l。另外，多个连词线参数写在一起的形式，比如command -lh，getopts也可以正确处理。\n**变量$OPTIND**在getopts开始执行前是1，然后每次执行就会加1。等到退出while循环，就意味着连词线参数全部处理完毕。这时，$OPTIND - 1就是已经处理的连词线参数个数，使用shift命令将这些参数移除，保证后面的代码可以用$1、$2等处理命令的主参数，即非连词线参数和其参数。\n配置项参数终止符 --\r-和--开头的参数，会被 Bash 当作配置项解释。但是，有时它们不是配置项，而是实体参数的一部分，比如文件名叫做-f或--file。\n1 2 $ cat -f $ cat --file 上面命令的原意是输出文件-f和--file的内容，但是会被 Bash 当作配置项解释。\n这时就可以使用配置项参数终止符--，它的作用是告诉 Bash，在它后面的参数开头的-和--不是配置项，只能当作实体参数解释。\n1 2 $ cat -- -f $ cat -- --file 上面命令可以正确展示文件-f和--file的内容，因为它们放在--的后面，开头的-和--就不再当作配置项解释了。\n如果要确保某个变量不会被当作配置项解释，就要在它前面放上参数终止符--。\n1 $ ls -- $myPath 上面示例中，--强制变量$myPath只能当作实体参数（即路径名）解释。如果变量不是路径名，就会报错。\n1 2 3 $ myPath=\u0026#34;-l\u0026#34; $ ls -- $myPath ls: 无法访问\u0026#39;-l\u0026#39;: 没有那个文件或目录 上面例子中，变量myPath的值为-l，不是路径。但是，--强制$myPath只能作为路径解释，导致报错“不存在该路径”。\n下面是另一个实际的例子，如果想在文件里面搜索--hello，这时也要使用参数终止符--。\n1 $ grep -- \u0026#34;--hello\u0026#34; example.txt 上面命令在example.txt文件里面，搜索字符串--hello。这个字符串是--开头，如果不用参数终止符，grep命令就会把--hello当作配置项参数，从而报错。\nexit 命令\rexit命令用于终止当前脚本的执行，并向 Shell 返回一个退出值。\n1 $ exit 上面命令中止当前脚本，将最后一条命令的退出状态，作为整个脚本的退出状态。\nexit命令后面可以跟参数，该参数就是退出状态。\n1 2 3 4 5 # 退出值为0（成功） $ exit 0 # 退出值为1（失败） $ exit 1 退出时，脚本会返回一个退出值。脚本的退出值，0表示正常，1表示发生错误，2表示用法不对，126表示不是可执行脚本，127表示命令没有发现。如果脚本被信号N终止，则退出值为128 + N。简单来说，只要退出值非0，就认为执行出错。\n下面是一个例子。\n1 2 3 4 if [ $(id -u) != \u0026#34;0\u0026#34; ]; then echo \u0026#34;根用户才能执行当前脚本\u0026#34; exit 1 fi 上面的例子中，id -u命令返回用户的 ID，一旦用户的 ID 不等于0（根用户的 ID），脚本就会退出，并且退出码为1，表示运行失败。\nexit与return命令的差别是，return命令是函数的退出，并返回一个值给调用者，脚本依然执行。exit是整个脚本的退出，如果在函数之中调用exit，则退出函数，并终止脚本执行。\n命令执行结果\r命令执行结束后，会有一个返回值。0表示执行成功，非0（通常是1）表示执行失败。环境变量$?可以读取前一个命令的返回值。\n利用这一点，可以在脚本中对命令执行结果进行判断。\n1 2 3 4 5 6 7 cd /path/to/somewhere if [ \u0026#34;$?\u0026#34; = \u0026#34;0\u0026#34; ]; then rm * else echo \u0026#34;无法切换目录！\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 fi 上面例子中，cd /path/to/somewhere这个命令如果执行成功（返回值等于0），就删除该目录里面的文件，否则退出脚本，整个脚本的返回值变为1，表示执行失败。\n由于if可以直接判断命令的执行结果，执行相应的操作，上面的脚本可以改写成下面的样子。\n1 2 3 4 5 6 if cd /path/to/somewhere; then rm * else echo \u0026#34;Could not change directory! Aborting.\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 fi 更简洁的写法是利用两个逻辑运算符\u0026amp;\u0026amp;（且）和||（或）。\n1 2 3 4 5 # 第一步执行成功，才会执行第二步 cd /path/to/somewhere \u0026amp;\u0026amp; rm * # 第一步执行失败，才会执行第二步 cd /path/to/somewhere || exit 1 source 命令\rsource命令用于执行一个脚本，通常用于重新加载一个配置文件。\n1 $ source .bashrc source命令最大的特点是在当前 Shell 执行脚本，不像直接执行脚本时，会新建一个子 Shell。所以，source命令执行脚本时，不需要export变量。\n即此时会共享当前shell的环境变量，也会对当前shell环境造成改变。\n1 2 3 #!/bin/bash # test.sh echo $foo 上面脚本输出$foo变量的值。\n1 2 3 4 5 6 7 8 9 # 当前 Shell 新建一个变量 foo $ foo=1 # 打印输出 1 $ source test.sh 1 # 打印输出空字符串 $ bash test.sh 上面例子中，当前 Shell 的变量foo并没有export，所以直接执行无法读取，但是source执行可以读取。\nsource命令的另一个用途，是在脚本内部加载外部库。\n1 2 3 4 5 #!/bin/bash source ./lib.sh function_from_lib 上面脚本在内部使用source命令加载了一个外部库，然后就可以在脚本里面，使用这个外部库定义的函数。\nsource有一个简写形式，可以使用一个点（.）来表示。\n1 $ . .bashrc 别名，alias 命令\ralias命令用来为一个命令指定别名，这样更便于记忆。下面是alias的格式。\n1 alias NAME=DEFINITION 上面命令中，NAME是别名的名称，DEFINITION是别名对应的原始命令。注意，等号两侧不能有空格，否则会报错。\n一个常见的例子是为grep命令起一个search的别名。\n1 alias search=grep alias也可以用来为长命令指定一个更短的别名。下面是通过别名定义一个today的命令。\n1 2 3 $ alias today=\u0026#39;date +\u0026#34;%A, %B %-d, %Y\u0026#34;\u0026#39; $ today 星期一, 一月 6, 2020 有时为了防止误删除文件，可以指定rm命令的别名。\n1 $ alias rm=\u0026#39;rm -i\u0026#39; 上面命令指定rm命令是rm -i，每次删除文件之前，都会让用户确认。\nalias定义的别名也可以接受参数，参数会直接传入原始命令。\n1 2 3 $ alias echo=\u0026#39;echo It says: \u0026#39; $ echo hello world It says: hello world 上面例子中，别名定义了echo命令的前两个参数，等同于修改了echo命令的默认行为。\n指定别名以后，就可以像使用其他命令一样使用别名。一般来说，都会把常用的别名写在~/.bashrc的末尾。另外，只能为命令定义别名，为其他部分（比如很长的路径）定义别名是无效的。\n直接调用alias命令，可以显示所有别名。\n1 $ alias unalias命令可以解除别名。\n1 $ unalias lt 参考链接\rHow to use getopts to parse a script options, Egidio Docile ","date":"2025-10-20T15:39:00Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_script/","title":"Bash_script"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n目录堆栈\r为了方便用户在不同目录之间切换，Bash 提供了目录堆栈功能。\ncd -\rBash 可以记忆用户进入过的目录。默认情况下，只记忆前一次所在的目录，cd -命令可以返回前一次的目录。\n1 2 3 4 5 # 当前目录是 /path/to/foo $ cd bar # 重新回到 /path/to/foo $ cd - 上面例子中，用户原来所在的目录是/path/to/foo，进入子目录bar以后，使用cd -可以回到原来的目录。\npushd，popd\r如果希望记忆多重目录，可以使用pushd命令和popd命令。它们用来操作目录堆栈。\npushd命令的用法类似cd命令，可以进入指定的目录。\n1 $ pushd dirname 上面命令会进入目录dirname，并将该目录放入堆栈。\n第一次使用pushd命令时，会将当前目录先放入堆栈，然后将所要进入的目录也放入堆栈，位置在前一个记录的上方。以后每次使用pushd命令，都会将所要进入的目录，放在堆栈的顶部。\npopd命令不带有参数时，会移除堆栈的顶部记录，并进入新的栈顶目录（即原来的第二条目录）。\n下面是一个例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 当前处在主目录，堆栈为空 $ pwd /home/me # 进入 /home/me/foo # 当前堆栈为 /home/me/foo /home/me $ pushd ~/foo # 进入 /etc # 当前堆栈为 /etc /home/me/foo /home/me $ pushd /etc # 进入 /home/me/foo # 当前堆栈为 /home/me/foo /home/me $ popd # 进入 /home/me # 当前堆栈为 /home/me $ popd # 目录不变，当前堆栈为空 $ popd 这两个命令的参数如下。\n（1）-n 参数\n-n的参数表示仅操作堆栈，不改变目录。\n1 $ popd -n 上面的命令仅删除堆栈顶部的记录，不改变目录，执行完成后还停留在当前目录。\n（2）整数参数\n这两个命令还可以接受一个整数作为参数，该整数表示堆栈中指定位置的记录（距栈顶从0开始）。pushd命令会把这条记录移动到栈顶，同时切换到该目录；popd则从堆栈中删除这条记录，不会切换目录。\n1 2 3 4 5 6 7 8 9 10 11 # 将从栈顶算起的3号目录（从0开始）移动到栈顶，同时切换到该目录 $ pushd +3 # 将从栈底算起的3号目录（从0开始）移动到栈顶，同时切换到该目录 $ pushd -3 # 删除从栈顶算起的3号目录（从0开始），不改变当前目录 $ popd +3 # 删除从栈底算起的3号目录（从0开始），不改变当前目录 $ popd -3 上面例子的整数编号都是从0开始计算，popd +0是删除第一个目录，popd +1是删除第二个，popd -0是删除最后一个目录，popd -1是删除倒数第二个。\n（3）目录参数\npushd可以接受一个目录作为参数，表示将该目录放到堆栈顶部，并进入该目录。\n1 $ pushd dir popd没有这个参数。\ndirs 命令\rdirs命令可以显示目录堆栈的内容，一般用来查看pushd和popd操作后的结果。\n1 2 $ dirs ~/foo/bar ~/foo ~ 该命令会输出一行文本，列出目录堆栈，目录之间使用空格分隔。栈顶（最晚入栈的目录）在最左边，栈底（最早入栈的目录）在最右边。\n它有以下参数。\n-c：清空目录栈。 -l：用户主目录不显示波浪号前缀，而打印完整的目录。 -p：每行一个条目打印目录栈，默认是打印在一行。 -v：每行一个条目，每个条目之前显示位置编号（从0开始）。 +N：N为整数，表示显示堆顶算起的第 N 个目录，从零开始。 -N：N为整数，表示显示堆底算起的第 N 个目录，从零开始。 ","date":"2025-10-20T15:37:40Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_stack/","title":"Bash_stack"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash 行操作\r简介\rBash 内置了 Readline 库，具有这个库提供的很多“行操作”功能，比如命令的自动补全，可以大大加快操作速度。\n这个库默认采用 Emacs 快捷键，也可以改成 Vi 快捷键。\n1 $ set -o vi 下面的命令可以改回 Emacs 快捷键。\n1 $ set -o emacs 如果想永久性更改编辑模式（Emacs / Vi），可以将命令写在~/.inputrc文件，这个文件是 Readline 的配置文件。\n1 set editing-mode vi 本章介绍的快捷键都属于 Emacs 模式。Vi 模式的快捷键，读者可以参考 Vi 编辑器的教程。\nBash 默认开启这个库，但是允许关闭。\n1 $ bash --noediting 上面命令中，--noediting参数关闭了 Readline 库，启动的 Bash 就不带有行操作功能。\n光标移动\rReadline 提供快速移动光标的快捷键。\nCtrl + a：移到行首。 Ctrl + b：向行首移动一个字符，与左箭头作用相同。 Ctrl + e：移到行尾。 Ctrl + f：向行尾移动一个字符，与右箭头作用相同。 Alt + f：移动到当前单词的词尾。 Alt + b：移动到当前单词的词首。 上面快捷键的 Alt 键，也可以用 ESC 键代替。\n清除屏幕\rCtrl + l快捷键可以清除屏幕，即将当前行移到屏幕的第一行，与clear命令作用相同。\n编辑操作\r下面的快捷键可以编辑命令行内容。\nCtrl + d：删除光标位置的字符（delete）。 Ctrl + w：删除光标前面的单词。 Ctrl + t：光标位置的字符与它前面一位的字符交换位置（transpose）。 Alt + t：光标位置的词与它前面一位的词交换位置（transpose）。 Alt + l：将光标位置至词尾转为小写（lowercase）。 Alt + u：将光标位置至词尾转为大写（uppercase）。 使用Ctrl + d的时候，如果当前行没有任何字符，会导致退出当前 Shell，所以要小心。\n剪切和粘贴快捷键如下。\nCtrl + k：剪切光标位置到行尾的文本。 Ctrl + u：剪切光标位置到行首的文本。 Alt + d：剪切光标位置到词尾的文本。 Alt + Backspace：剪切光标位置到词首的文本。 Ctrl + y：在光标位置粘贴文本。 同样地，Alt 键可以用 Esc 键代替。\n自动补全\r命令输入到一半的时候，可以按一下 Tab 键，Readline 会自动补全命令或路径。比如，输入cle，再按下 Tab 键，Bash 会自动将这个命令补全为clear。\n如果符合条件的命令或路径有多个，就需要连续按两次 Tab 键，Bash 会提示所有符合条件的命令或路径。\n除了命令或路径，Tab 还可以补全其他值。如果一个值以$开头，则按下 Tab 键会补全变量；如果以~开头，则补全用户名；如果以@开头，则补全主机名（hostname），主机名以列在/etc/hosts文件里面的主机为准。\n自动补全相关的快捷键如下。\nTab：完成自动补全。 Alt + ?：列出可能的补全，与连按两次 Tab 键作用相同。 Alt + /：尝试文件路径补全。 Ctrl + x /：先按Ctrl + x，再按/，等同于Alt + ?，列出可能的文件路径补全。 Alt + !：命令补全。 Ctrl + x !：先按Ctrl + x，再按!，等同于Alt + !，命令补全。 Alt + ~：用户名补全。 Ctrl + x ~：先按Ctrl + x，再按~，等同于Alt + ~，用户名补全。 Alt + $：变量名补全。 Ctrl + x $：先按Ctrl + x，再按$，等同于Alt + $，变量名补全。 Alt + @：主机名补全。 Ctrl + x @：先按Ctrl + x，再按@，等同于Alt + @，主机名补全。 Alt + *：在命令行一次性插入所有可能的补全。 Alt + Tab：尝试用.bash_history里面以前执行命令，进行补全。 上面的Alt键也可以用 ESC 键代替。\n其他快捷键\rCtrl + j：等同于回车键（LINEFEED）。 Ctrl + m：等同于回车键（CARRIAGE RETURN）。 Ctrl + o：等同于回车键，并展示操作历史的下一个命令。 Ctrl + v：将下一个输入的特殊字符变成字面量，比如回车变成^M。 Ctrl + [：等同于 ESC。 Alt + .：插入上一个命令的最后一个词。 Alt + _：等同于Alt + .。 上面的Alt + .快捷键，对于很长的文件路径，有时会非常方便。因为 Unix 命令的最后一个参数通常是文件路径。\n1 2 $ mkdir foo_bar $ cd #按下 Alt + . 上面例子中，在cd命令后按下Alt + .，就会自动插入foo_bar。\n","date":"2025-10-20T15:35:44Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_readline/","title":"Bash_readline"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n操作历史\r简介\rBash 会保留用户的操作历史，即用户输入的每一条命令都会记录，默认是保存最近的500条命令。有了操作历史以后，就可以使用方向键的↑和↓，快速浏览上一条和下一条命令。\n退出当前 Shell 的时候，Bash 会将用户在当前 Shell 的操作历史写入~/.bash_history文件，该文件默认储存500个操作。\n环境变量HISTFILE总是指向这个文件。\n1 2 $ echo $HISTFILE /home/me/.bash_history history 命令\rhistory命令会输出.bash_history文件的全部内容，即输出操作历史。\n1 2 3 4 5 $ history ... 498 echo Goodbye 499 ls ~ 500 cd 用户可以使用这个命令，查看最近的操作。相比直接读取.bash_history文件，它的优势在于所有命令之前加上了行号。最近的操作在最后面，行号最大。\n如果想搜索某个以前执行的命令，可以配合grep命令搜索操作历史。\n1 $ history | grep /usr/bin 上面命令返回.bash_history文件里面，那些包含/usr/bin的命令。\nhistory命令的-c参数可以清除操作历史，即清空.bash_history文件。\n1 $ history -c 环境变量\rHISTTIMEFORMAT\r通过定制环境变量HISTTIMEFORMAT，history的输出结果还可以显示每个操作的时间。\n1 2 3 4 $ export HISTTIMEFORMAT=\u0026#39;%F %T \u0026#39; $ history 1 2013-06-09 10:40:12 cat /etc/issue 2 2013-06-09 10:40:12 clear 上面代码中，%F相当于%Y - %m - %d（年-月-日），%T相当于 %H : %M : %S（时:分:秒）。\n只要设置HISTTIMEFORMAT这个环境变量，就会在.bash_history文件保存命令的执行时间戳。如果不设置，就不会保存时间戳。\nHISTSIZE\r环境变量HISTSIZE设置保存历史操作的数量。\n1 $ export HISTSIZE=10000 上面命令设置保存过去10000条操作历史。\n如果不希望保存本次操作的历史，可以设置HISTSIZE等于0。\n1 export HISTSIZE=0 如果HISTSIZE=0写入用户主目录的~/.bashrc文件，那么就不会保留该用户的操作历史。如果写入/etc/profile，整个系统都不会保留操作历史。\nHISTIGNORE\r环境变量HISTIGNORE可以设置哪些命令不写入操作历史。\n1 export HISTIGNORE=\u0026#39;pwd:ls:exit\u0026#39; 上面示例设置，pwd、ls、exit这三个命令不写入操作历史。\nCtrl + r\r输入命令时，按下Ctrl + r快捷键，就可以搜索操作历史，选择以前执行过的命令。\nCtrl + r相当于打开一个.bash_history文件的搜索接口，直接键入命令的开头部分，Shell 就会自动在该文件中反向查询（即先查询最近的命令），显示最近一条匹配的结果，这时按下回车键，就会执行那条命令。\n! 命令\r! + 行号\r操作历史的每一条记录都有行号。知道了命令的行号以后，可以用感叹号 + 行号执行该命令。如果想要执行.bash_history里面的第8条命令，可以像下面这样操作。\n1 $ !8 !- 数字\r如果想执行本次 Shell 对话中倒数的命令，比如执行倒数第3条命令，就可以输入!-3。\n1 2 3 4 5 6 $ touch a.txt $ touch b.txt $ touch c.txt $ !-3 touch a.txt 上面示例中，!-3返回倒数第3条命令，即touch a.txt。\n它跟! + 行号的主要区别是，后者是在.bash_history文件中从头开始计算行数，而!- 数字是从底部开始向上计算行数。\n!!\r!!命令返回上一条命令。如果需要重复执行某一条命令，就可以不断键入!!，这样非常方便。它等同于!-1。\n1 2 3 4 5 6 $ echo hello hello $ !! echo hello hello 上面示例中，!!会返回并执行上一条命令echo hello。\n有时候，我们使用某条命令，系统报错没有权限，这时就可以使用sudo !!。\n1 2 3 4 5 # 报错，没有执行权限 $ yum update $ sudo !! sudo yum update 上面示例中，sudo !!返回sudo yum update，从而就可以正确执行了。\n! + 搜索词\r感叹号 + 搜索词可以快速执行匹配的命令。\n1 2 3 4 5 6 7 8 9 $ echo Hello World Hello World $ echo Goodbye Goodbye $ !e echo Goodbye Goodbye 上面例子中，!e表示找出操作历史之中，最近的那一条以e开头的命令并执行。Bash 会先输出那一条命令echo Goodbye，然后直接执行。\n同理，!echo也会执行最近一条以echo开头的命令。\n1 2 3 4 5 6 7 8 9 10 11 $ !echo echo Goodbye Goodbye $ !echo H echo Goodbye H Goodbye H $ !echo H G echo Goodbye H G Goodbye H G 注意，感叹号 + 搜索词语法只会匹配命令，不会匹配参数。所以!echo H不会执行echo Hello World，而是会执行echo Goodbye，并把参数H附加在这条命令之后。同理，!echo H G也是等同于echo Goodbye命令之后附加H G。\n由于感叹号 + 搜索词会扩展成以前执行过的命令，所以含有!的字符串放在双引号里面，必须非常小心，如果它后面有非空格的字符，就很有可能报错。\n1 2 $ echo \u0026#34;I say:\\\u0026#34;hello!\\\u0026#34;\u0026#34; bash: !\\: event not found 上面的命令会报错，原因是感叹号后面是一个反斜杠，Bash 会尝试寻找，以前是否执行过反斜杠开头的命令，一旦找不到就会报错。解决方法就是在感叹号前面，也加上反斜杠。\n1 2 $ echo \u0026#34;I say:\\\u0026#34;hello\\!\\\u0026#34;\u0026#34; I say:\u0026#34;hello\\!\u0026#34; !? + 搜索词\r!? + 搜索词可以搜索命令的任意部分，包括参数部分。它跟! + 搜索词的主要区别是，后者是从行首开始匹配。\n1 2 3 4 5 6 $ cat hello.txt Hello world ..! $ !?hello.txt cat hello.txt Hello world ..! 上面示例中，!?hello.txt会返回最近一条包括hello.txt的命令。\n!$，!*\r!$代表上一个命令的最后一个参数，它的另一种写法是$_。\n!*代表上一个命令的所有参数，即除了命令以外的所有部分。\n1 2 3 4 5 6 7 $ cp a.txt b.txt $ echo !$ b.txt $ cp a.txt b.txt $ echo !* a.txt b.txt 上面示例中，!$代表上一个命令的最后一个参数（b.txt），!*代表上一个命令的所有参数（a.txt b.txt）。\n如果想匹配上一个命令的某个指定位置的参数，使用!:n。\n1 2 3 4 $ ls a.txt b.txt c.txt $ echo !:2 b.txt 上面示例中，!:2返回上一条命令的第二个参数（b.txt）。\n这种写法的!:$，代表上一个命令的最后一个参数。事实上，!$就是!:$的简写形式。\n1 2 3 4 5 $ ls a.txt b.txt c.txt $ echo !:$ echo c.txt c.txt 上面示例中，!:$代表上一条命令的最后一个参数（c.txt）。\n如果想匹配更久以前的命令的参数，可以使用!\u0026lt;命令\u0026gt;:n（指定位置的参数）和!\u0026lt;命令\u0026gt;:$（最后一个参数）。\n即：指定命令和读取参数结合起来了。\n1 $ ls !mkdir:$ 上面示例中，!mkdir:$会返回前面最后一条mkdir命令的最后一个参数。\n1 $ ls !mk:2 上面示例中，!mk:2会返回前面最后一条以mk开头的命令的第二个参数。\n!:p\r如果只是想输出上一条命令，而不是执行它，可以使用!:p。\n1 2 3 4 $ echo hello $ !:p echo hello 上面示例中，!:p只会输出echo hello，而不会执行这条命令。\n如果想输出最近一条匹配的命令，而不执行它，可以使用!\u0026lt;命令\u0026gt;:p。\n1 $ !su:p 上面示例中，!su:p会输出前面最近一条以su开头的命令，而不执行它。\n^string1^string2\r^string1^string2用来执行最近一条包含string1的命令，将其替换成string2。\n1 2 3 $ rm /var/log/httpd/error.log $ ^error^access rm /var/log/httpd/access.log 上面示例中，^error^access将最近一条含有error的命令里面的error，替换成access。\nhistverify 参数\r上面的那些快捷命令（比如!!命令），都是找到匹配的命令后，直接执行。如果希望增加一个确认步骤，先输出是什么命令，让用户确认后再执行，可以打开 Shell 的histverify选项。\n1 $ shopt -s histverify 打开histverify这个选项后，使用!快捷键所返回的命令，就会先输出，等到用户按下回车键后再执行。\n快捷键\r下面是其他一些与操作历史相关的快捷键。\nCtrl + p：显示上一个命令，与向上箭头效果相同（previous）。 Ctrl + n：显示下一个命令，与向下箭头效果相同（next）。 Alt + \u0026lt;：显示第一个命令。 Alt + \u0026gt;：显示最后一个命令，即当前的命令。 Ctrl + o：执行历史文件里面的当前条目，并自动显示下一条命令。这对重复执行某个序列的命令很有帮助。 参考链接\rBash bang commands: A must-know trick for the Linux command line ","date":"2025-10-20T15:33:46Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_history/","title":"Bash_history"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash 的算术运算\r算术表达式\r((...))语法可以进行整数的算术运算。\n1 2 3 $ ((foo = 5 + 5)) $ echo $foo 10 ((...))会自动忽略内部的空格，所以下面的写法都正确，得到同样的结果。\n1 2 3 $ ((2+2)) $ (( 2+2 )) $ (( 2 + 2 )) 这个语法不返回值，命令执行的结果根据算术运算的结果而定。只要算术结果不是0，命令就算执行成功。\n1 2 3 $ (( 3 + 2 )) $ echo $? 0 上面例子中，3 + 2的结果是5，命令就算执行成功，环境变量$?为0。\n如果算术结果为0，命令就算执行失败。\n1 2 3 $ (( 3 - 3 )) $ echo $? 1 上面例子中，3 - 3的结果是0，环境变量$?为1，表示命令执行失败。\n即：((...))算术结果为0-\u0026gt;执行失败-\u0026gt;返回码为1；算术结果非0-\u0026gt;执行成功-\u0026gt;返回码为0。\n如果要读取算术运算的结果，需要在((...))前面加上美元符号$((...))，使其变成算术表达式，返回算术运算的值。\n1 2 $ echo $((2 + 2)) 4 ((...))语法支持的算术运算符如下。\n+：加法 -：减法 *：乘法 /：除法（整除） %：余数 **：指数 ++：自增运算（前缀或后缀） --：自减运算（前缀或后缀） 注意，除法运算符的返回结果总是整数，比如5除以2，得到的结果是2，而不是2.5。\n1 2 $ echo $((5 / 2)) 2 ++和--这两个运算符有前缀和后缀的区别。作为前缀是先运算后返回值，作为后缀是先返回值后运算。\n1 2 3 4 5 6 7 8 9 10 11 $ i=0 $ echo $i 0 $ echo $((i++)) 0 $ echo $i 1 $ echo $((++i)) 2 $ echo $i 2 上面例子中，++作为后缀是先返回值，执行echo命令，再进行自增运算；作为前缀则是先进行自增运算，再返回值执行echo命令。\n$((...))内部可以用圆括号改变运算顺序。\n1 2 $ echo $(( (2 + 3) * 4 )) 20 上面例子中，内部的圆括号让加法先于乘法执行。\n$((...))结构可以嵌套。\n1 2 3 4 5 $ echo $(((5**2) * 3)) 75 # 等同于 $ echo $(($((5**2)) * 3)) 75 这个语法只能计算整数，否则会报错。\n1 2 3 # 报错 $ echo $((1.5 + 1)) bash: 语法错误 $((...))的圆括号之中，不需要在变量名之前加上$，不过加上也不报错。\n1 2 3 $ number=2 $ echo $(($number + 1)) 3 上面例子中，变量number前面有没有美元符号，结果都是一样的。\n如果在$((...))里面使用字符串，Bash 会认为那是一个变量名。如果不存在同名变量，Bash 就会将其作为空值，因此不会报错。\n1 2 3 4 $ echo $(( \u0026#34;hello\u0026#34; + 2)) 2 $ echo $(( \u0026#34;hello\u0026#34; * 2)) 0 上面例子中，\u0026quot;hello\u0026quot;会被当作变量名，返回空值，而$((...))会将空值当作0，所以乘法的运算结果就是0。同理，如果$((...))里面使用不存在的变量，也会当作0处理。\n如果一个变量的值为字符串，跟上面的处理逻辑是一样的。即该字符串如果不对应已存在的变量，在$((...))里面会被当作空值。\n1 2 3 $ foo=hello $ echo $(( foo + 2)) 2 上面例子中，变量foo的值是hello，而hello也会被看作变量名。这使得有可能写出动态替换的代码。\n1 2 3 4 $ foo=hello $ hello=3 $ echo $(( foo + 2 )) 5 上面代码中，foo + 2取决于变量hello的值。\n最后，$[...]是以前的语法，也可以做整数运算，不建议使用。\n1 2 $ echo $[2+2] 4 数值的进制\rBash 的数值默认都是十进制，但是在算术表达式中，也可以使用其他进制。\nnumber：没有任何特殊表示法的数字是十进制数（以10为底）。 0number：八进制数。 0xnumber：十六进制数。 base#number：base进制的数。 下面是一些例子。\n1 2 3 4 $ echo $((0xff)) 255 $ echo $((2#11111111)) 255 上面例子中，0xff是十六进制数，2#11111111是二进制数。\n位运算\r$((...))支持以下的二进制位运算符。\n\u0026lt;\u0026lt;：位左移运算，把一个数字的所有位向左移动指定的位。 \u0026gt;\u0026gt;：位右移运算，把一个数字的所有位向右移动指定的位。 \u0026amp;：位的“与”运算，对两个数字的所有位执行一个AND操作。 |：位的“或”运算，对两个数字的所有位执行一个OR操作。 ~：位的“否”运算，对一个数字的所有位取反。 ^：位的异或运算（exclusive or），对两个数字的所有位执行一个异或操作。 下面是右移运算符\u0026gt;\u0026gt;的例子。\n1 2 $ echo $((16\u0026gt;\u0026gt;2)) 4 下面是左移运算符\u0026lt;\u0026lt;的例子。\n1 2 $ echo $((16\u0026lt;\u0026lt;2)) 64 下面是17（二进制10001）和3（二进制11）的各种二进制运算的结果。\n1 2 3 4 5 6 $ echo $((17\u0026amp;3)) 1 $ echo $((17|3)) 19 $ echo $((17^3)) 18 逻辑运算\r$((...))支持以下的逻辑运算符，整体上和c语言差不多。\n\u0026lt;：小于 \u0026gt;：大于 \u0026lt;=：小于或相等 \u0026gt;=：大于或相等 ==：相等 !=：不相等 \u0026amp;\u0026amp;：逻辑与 ||：逻辑或 !：逻辑否 expr1?expr2:expr3：三元条件运算符。若表达式expr1的计算结果为非零值（算术真），则执行表达式expr2，否则执行表达式expr3。 如果逻辑表达式为真，返回1，否则返回0。\n1 2 3 4 $ echo $((3 \u0026gt; 2)) 1 $ echo $(( (3 \u0026gt; 2) || (4 \u0026lt;= 1) )) 1 三元运算符执行一个单独的逻辑测试。它用起来类似于if/then/else语句。\n1 2 3 4 5 $ a=0 $ echo $((a\u0026lt;1 ? 1 : 0)) 1 $ echo $((a\u0026gt;1 ? 1 : 0)) 0 上面例子中，第一个表达式为真时，返回第二个表达式的值，否则返回第三个表达式的值。\n赋值运算\r算术表达式$((...))可以执行赋值运算。\n1 2 3 4 $ echo $((a=1)) 1 $ echo $a 1 上面例子中，a=1对变量a进行赋值。这个式子本身也是一个表达式，返回值就是赋值的结果。\n$((...))支持的赋值运算符，有以下这些。\nparameter = value：简单赋值。 parameter += value：等价于parameter = parameter + value。 parameter -= value：等价于parameter = parameter – value。 parameter *= value：等价于parameter = parameter * value。 parameter /= value：等价于parameter = parameter / value。 parameter %= value：等价于parameter = parameter % value。 parameter \u0026lt;\u0026lt;= value：等价于parameter = parameter \u0026lt;\u0026lt; value。 parameter \u0026gt;\u0026gt;= value：等价于parameter = parameter \u0026gt;\u0026gt; value。 parameter \u0026amp;= value：等价于parameter = parameter \u0026amp; value。 parameter |= value：等价于parameter = parameter | value。 parameter ^= value：等价于parameter = parameter ^ value。 下面是一个例子。\n1 2 3 $ foo=5 $ echo $((foo*=2)) 10 如果在表达式内部赋值，可以放在圆括号中，否则会报错。\n1 $ echo $(( a\u0026lt;1 ? (a+=1) : (a-=1) )) 求值运算\r逗号,在$((...))内部是求值运算符，执行前后两个表达式，并返回后一个表达式的值。\n1 2 3 4 $ echo $((foo = 1 + 2, 3 * 4)) 12 $ echo $foo 3 上面例子中，逗号前后两个表达式都会执行，然后返回后一个表达式的值12。\nexpr 命令\rexpr命令支持整数算术运算，可以不使用((...))语法。\n1 2 $ expr 3 + 2 5 expr命令支持变量替换。\n1 2 3 $ foo=3 $ expr $foo + 2 5 expr命令也不支持非整数参数。\n1 2 $ expr 3.5 + 2 expr: 非整数参数 上面例子中，如果有非整数的运算，expr命令就报错了。\nlet 命令\rlet命令用于将算术运算的结果赋予一个变量。\n1 2 3 $ let x=2+3 $ echo $x 5 上面例子中，变量x等于2+3的运算结果。\n注意，x=2+3这个式子里面不能有空格，否则会报错。let命令的详细用法参见《变量》一章。\n","date":"2025-10-20T15:29:39Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_arithmetic/","title":"Bash_arithmetic"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n字符串操作\r本章介绍 Bash 字符串操作的语法。\n字符串的长度\r获取字符串长度的语法如下。\n1 ${#varname} 下面是一个例子。\n1 2 3 $ myPath=/home/cam/book/long.file.name $ echo ${#myPath} 29 大括号{}是必需的，否则 Bash 会将$#理解成脚本的参数个数，将变量名理解成文本。\n1 2 $ echo $#myvar 0myvar 上面例子中，Bash 将$#和myvar分开解释了。\n子字符串\r字符串提取子串的语法如下。\n1 ${varname:offset:length} 上面语法的含义是返回变量$varname的子字符串，从位置offset开始（从0开始计算），长度为length。\n1 2 3 $ count=frogfootman $ echo ${count:4:4} foot 上面例子返回字符串frogfootman从4号位置开始的长度为4的子字符串foot。\n这种语法不能直接操作字符串，只能通过变量来读取字符串，并且不会改变原始字符串。\n1 2 # 报错 $ echo ${\u0026#34;hello\u0026#34;:2:3} 上面例子中，\u0026quot;hello\u0026quot;不是变量名，导致 Bash 报错。\n如果省略length，则从位置offset开始，一直返回到字符串的结尾。\n1 2 3 $ count=frogfootman $ echo ${count:4} footman 上面例子是返回变量count从4号位置一直到结尾的子字符串。\n如果offset为负值，表示从字符串的末尾开始算起。注意，负数前面必须有一个空格， 以防止与${variable:-word}的变量的设置默认值语法混淆。这时还可以指定length，length可以是正值，也可以是负值（负值不能超过offset的长度）。\n1 2 3 4 5 6 7 $ foo=\u0026#34;This string is long.\u0026#34; $ echo ${foo: -5} long. $ echo ${foo: -5:2} lo $ echo ${foo: -5:-2} lon 上面例子中，offset为-5，表示从倒数第5个字符开始截取，所以返回long.。如果指定长度length为2，则返回lo；如果length为-2，表示要排除从字符串末尾开始的2个字符，所以返回lon。\n搜索和替换\rBash 提供字符串搜索和替换的多种方法。\n（1）字符串头部的模式匹配。\n以下两种语法可以检查字符串开头，是否匹配给定的模式。如果匹配成功，就删除匹配的部分，返回剩下的部分。原始变量不会发生变化。\n1 2 3 4 5 6 7 # 如果 pattern 匹配变量 variable 的开头， # 删除最短匹配（非贪婪匹配）的部分，返回剩余部分 ${variable#pattern} # 如果 pattern 匹配变量 variable 的开头， # 删除最长匹配（贪婪匹配）的部分，返回剩余部分 ${variable##pattern} 上面两种语法会删除变量字符串开头的匹配部分（将其替换为空），返回剩下的部分。区别是一个是最短匹配（又称非贪婪匹配），另一个是最长匹配（又称贪婪匹配）。\n匹配模式pattern可以使用*、?、[]等通配符。\n1 2 3 4 5 6 7 $ myPath=/home/cam/book/long.file.name $ echo ${myPath#/*/} cam/book/long.file.name $ echo ${myPath##/*/} long.file.name 上面例子中，匹配的模式是/*/，其中*可以匹配任意数量的字符，所以最短匹配是/home/，最长匹配是/home/cam/book/。\n下面写法可以删除文件路径的目录部分，只留下文件名。\n1 2 3 4 $ path=/home/cam/book/long.file.name $ echo ${path##*/} long.file.name 上面例子中，模式*/匹配目录部分，所以只返回文件名。\n下面再看一个例子。\n1 2 3 4 5 $ phone=\u0026#34;555-456-1414\u0026#34; $ echo ${phone#*-} 456-1414 $ echo ${phone##*-} 1414 如果匹配不成功，则返回原始字符串。\n1 2 3 $ phone=\u0026#34;555-456-1414\u0026#34; $ echo ${phone#444} 555-456-1414 上面例子中，原始字符串里面无法匹配模式444，所以原样返回。\n如果要将头部匹配的部分，替换成其他内容，采用下面的写法。\n1 2 3 4 5 6 7 8 # 模式必须出现在字符串的开头（#前多加了/） # 会把匹配的pattern替换成string ${variable/#pattern/string} # 示例 $ foo=JPG.JPG $ echo ${foo/#JPG/jpg} jpg.JPG 上面例子中，被替换的JPG必须出现在字符串头部，所以返回jpg.JPG。不匹配就不会替换而是原样输出。\n（2）字符串尾部的模式匹配。\n以下两种语法可以检查字符串结尾，是否匹配给定的模式。如果匹配成功，就删除匹配的部分，返回剩下的部分。原始变量不会发生变化。\n1 2 3 4 5 6 7 # 如果 pattern 匹配变量 variable 的结尾， # 删除最短匹配（非贪婪匹配）的部分，返回剩余部分 ${variable%pattern} # 如果 pattern 匹配变量 variable 的结尾， # 删除最长匹配（贪婪匹配）的部分，返回剩余部分 ${variable%%pattern} 上面两种语法会删除变量字符串结尾的匹配部分（将其替换为空），返回剩下的部分。区别是一个是最短匹配（又称非贪婪匹配），另一个是最长匹配（又称贪婪匹配）。\n1 2 3 4 5 6 7 $ path=/home/cam/book/long.file.name $ echo ${path%.*} /home/cam/book/long.file $ echo ${path%%.*} /home/cam/book/long 上面例子中，匹配模式是.*，其中*可以匹配任意数量的字符，所以最短匹配是.name，最长匹配是.file.name。\n下面写法可以删除路径的文件名部分，只留下目录部分。\n1 2 3 4 $ path=/home/cam/book/long.file.name $ echo ${path%/*} /home/cam/book 上面例子中，模式/*匹配文件名部分，所以只返回目录部分。\n下面的写法可以替换文件的后缀名。\n1 2 3 $ file=foo.png $ echo ${file%.png}.jpg foo.jpg 上面的例子将文件的后缀名，从.png改成了.jpg。\n下面再看一个例子。\n1 2 3 4 5 $ phone=\u0026#34;555-456-1414\u0026#34; $ echo ${phone%-*} 555-456 $ echo ${phone%%-*} 555 如果匹配不成功，则返回原始字符串。\n如果要将尾部匹配的部分，替换成其他内容，采用下面的写法。\n1 2 3 4 5 6 7 # 模式必须出现在字符串的结尾 ${variable/%pattern/string} # 示例 $ foo=JPG.JPG $ echo ${foo/%JPG/jpg} JPG.jpg 上面例子中，被替换的JPG必须出现在字符串尾部，所以返回JPG.jpg。同#一样，尾部不匹配就不会替换，原样输出。\n（3）任意位置的模式匹配。\n以下两种语法可以检查字符串内部，是否匹配给定的模式。如果匹配成功，就删除匹配的部分，换成其他的字符串返回。原始变量不会发生变化。\n1 2 3 4 5 6 7 # 如果 pattern 匹配变量 variable 的一部分， # 最长匹配（贪婪匹配）的那部分被 string 替换，但仅替换第一个匹配（从前往后） ${variable/pattern/string} # 如果 pattern 匹配变量 variable 的一部分， # 最长匹配（贪婪匹配）的那部分被 string 替换，所有匹配都替换 ${variable//pattern/string} 上面两种语法都是最长匹配（贪婪匹配）下的替换，区别是前一个语法仅仅替换第一个匹配，后一个语法替换所有匹配。\n1 2 3 4 5 6 7 $ path=/home/cam/foo/foo.name $ echo ${path/foo/bar} /home/cam/bar/foo.name $ echo ${path//foo/bar} /home/cam/bar/bar.name 上面例子中，前一个命令只替换了第一个foo，后一个命令将两个foo都替换了。\n下面的例子将分隔符从:换成换行符。\n1 2 3 4 5 $ echo -e ${PATH//:/\u0026#39;\\n\u0026#39;} /usr/local/bin /usr/bin /bin ... 上面例子中，echo命令的-e参数，表示将替换后的字符串的\\n字符，解释为换行符。\n模式部分可以使用通配符。\n1 2 3 $ phone=\u0026#34;555-456-1414\u0026#34; $ echo ${phone/5?4/-} 55-56-1414 上面的例子将5-4替换成-。\n如果省略了string部分，那么就相当于匹配的部分替换成空字符串，即删除匹配的部分。\n1 2 3 4 $ path=/home/cam/foo/foo.name $ echo ${path/.*/} /home/cam/foo/foo 上面例子中，第二个斜杠后面的string部分省略了，所以模式.*匹配的部分.name被删除后返回。\n前面提到过，这个语法还有两种扩展形式（都是最短匹配）。\n1 2 3 4 5 # 模式必须出现在字符串的开头 ${variable/#pattern/string} # 模式必须出现在字符串的结尾 ${variable/%pattern/string} 改变大小写\r下面的语法可以改变变量的大小写。（注意是变量）\n1 2 3 4 5 # 转为大写 ${varname^^} # 转为小写 ${varname,,} 下面是一个例子。\n1 2 3 4 5 $ foo=heLLo $ echo ${foo^^} HELLO $ echo ${foo,,} hello ","date":"2025-10-16T11:30:56Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_string/","title":"Bash_string"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash 变量\r简介\rBash 变量分成环境变量和自定义变量两类。\n环境变量\r环境变量是 Bash 环境自带的变量，进入 Shell 时已经定义好了，可以直接使用。它们通常是系统定义好的，也可以由用户从父 Shell 传入子 Shell。\nenv命令或printenv命令，可以显示所有环境变量。\n1 2 3 $ env # 或者 $ printenv 下面是一些常见的环境变量。\nBASHPID：Bash 进程的进程 ID。 BASHOPTS：当前 Shell 的参数，可以用shopt命令修改。 DISPLAY：图形环境的显示器名字，通常是:0，表示 X Server 的第一个显示器。 EDITOR：默认的文本编辑器。 HOME：用户的主目录。 HOST：当前主机的名称。 IFS：词与词之间的分隔符，默认为空格。 LANG：字符集以及语言编码，比如zh_CN.UTF-8。 PATH：由冒号分开的目录列表，当输入可执行程序名后，会搜索这个目录列表。 PS1：Shell 提示符。 PS2： 输入多行命令时，次要的 Shell 提示符。 PWD：当前工作目录。 RANDOM：返回一个0到32767之间的随机数。 SHELL：Shell 的名字。 SHELLOPTS：启动当前 Shell 的set命令的参数，参见《set 命令》一章。 TERM：终端类型名，即终端仿真器所用的协议。 UID：当前用户的 ID 编号。 USER：当前用户的用户名。 很多环境变量很少发生变化，而且是只读的，可以视为常量。由于它们的变量名全部都是大写，所以传统上，如果用户要自己定义一个常量，也会使用全部大写的变量名。\n注意，Bash 变量名区分大小写，HOME和home是两个不同的变量。\n查看单个环境变量的值，可以使用printenv命令或echo命令。\n1 2 3 $ printenv PATH # 或者 $ echo $PATH 注意，printenv命令后面的变量名，不用加前缀$。\n自定义变量\r自定义变量是用户在当前 Shell 里面自己定义的变量，仅在当前 Shell 可用。一旦退出当前 Shell，该变量就不存在了。\nset命令可以显示所有变量（包括环境变量和自定义变量），以及所有的 Bash 函数。\n1 $ set 创建变量\r用户创建变量的时候，变量名必须遵守下面的规则。\n字母、数字和下划线字符组成。 第一个字符必须是一个字母或一个下划线，不能是数字。 不允许出现空格和标点符号。 变量声明的语法如下。\n1 variable=value 上面命令中，等号左边是变量名，右边是变量。注意，等号两边不能有空格。\n如果变量的值包含空格，则必须将值放在引号中。\n1 myvar=\u0026#34;hello world\u0026#34; Bash 没有数据类型的概念，所有的变量值都是字符串。\n下面是一些自定义变量的例子。\n1 2 3 4 5 6 a=z # 变量 a 赋值为字符串 z b=\u0026#34;a string\u0026#34; # 变量值包含空格，就必须放在引号里面 c=\u0026#34;a string and $b\u0026#34; # 变量值可以引用其他变量的值 d=\u0026#34;\\t\\ta string\\n\u0026#34; # 变量值可以使用转义字符 e=$(ls -l foo.txt) # 变量值可以是命令的执行结果 f=$((5 * 7)) # 变量值可以是数学运算的结果 变量可以重复赋值，后面的赋值会覆盖前面的赋值。\n1 2 3 4 $ foo=1 $ foo=2 $ echo $foo 2 上面例子中，变量foo的第二次赋值会覆盖第一次赋值。\n如果同一行定义多个变量，必须使用分号（;）分隔。\n1 $ foo=1;bar=2 上面例子中，同一行定义了foo和bar两个变量。\n读取变量\r读取变量的时候，直接在变量名前**加上$**就可以了。\n1 2 3 $ foo=bar $ echo $foo bar 每当 Shell 看到以$开头的单词时，就会尝试读取这个变量名对应的值。\n如果变量不存在，Bash 不会报错，而会输出空字符。\n由于$在 Bash 中有特殊含义，把它当作美元符号使用时，一定要非常小心，\n1 2 $ echo The total is $100.00 The total is 00.00 上面命令的原意是输入$100，但是 Bash 将$1解释成了变量，该变量为空，因此输入就变成了00.00。所以，如果要使用$的原义，需要在$前面放上反斜杠，进行转义。（感觉不如单引号）\n1 2 $ echo The total is \\$100.00 The total is $100.00 读取变量的时候，变量名也可以使用花括号{}包围，比如$a也可以写成${a}。这种写法可以用于变量名与其他字符连用的情况。\n1 2 3 4 5 $ a=foo $ echo $a_file $ echo ${a}_file foo_file 上面代码中，变量名a_file不会有任何输出，因为 Bash 将其整个解释为变量，而这个变量是不存在的。只有用花括号区分$a，Bash 才能正确解读。\n事实上，读取变量的语法$foo，可以看作是${foo}的简写形式。\n如果变量的值本身也是变量，可以使用${!varname}的语法，读取最终的值。\n1 2 3 $ myvar=USER $ echo ${!myvar} ruanyf 上面的例子中，变量myvar的值是USER，${!myvar}的写法将其展开成最终的值。\n如果变量值包含连续空格（或制表符和换行符），最好放在双引号里面读取。\n1 2 3 4 5 $ a=\u0026#34;1 2 3\u0026#34; $ echo $a 1 2 3 $ echo \u0026#34;$a\u0026#34; 1 2 3 上面示例中，变量a的值包含两个连续空格。如果直接读取，Shell 会将连续空格合并成一个。只有放在双引号里面读取，才能保持原来的格式。\n删除变量\runset命令用来删除一个变量。\n1 unset NAME 这个命令不是很有用。因为不存在的 Bash 变量一律等于空字符串，所以即使unset命令删除了变量，还是可以读取这个变量，值为空字符串。\n所以，删除一个变量，也可以将这个变量设成空字符串。\n1 2 $ foo=\u0026#39;\u0026#39; $ foo= 上面两种写法，都是删除了变量foo。由于不存在的值默认为空字符串，所以后一种写法可以在等号右边不写任何值。\n输出变量，export 命令\r用户创建的变量仅可用于当前 Shell，子 Shell 默认读取不到父 Shell 定义的变量。为了把变量传递给子 Shell，需要使用export命令。这样输出的变量，对于子 Shell 来说就是环境变量。\nexport命令用来向子 Shell 输出变量。\n1 2 NAME=foo export NAME 上面命令输出了变量NAME。变量的赋值和输出也可以在一个步骤中完成。\n1 export NAME=value 上面命令执行后，当前 Shell 及随后新建的子 Shell，都可以读取变量$NAME。\n子 Shell 如果修改继承的变量，不会影响父 Shell。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 输出变量 $foo $ export foo=bar # 新建子 Shell $ bash # 读取 $foo $ echo $foo bar # 修改继承的变量 $ foo=baz # 退出子 Shell $ exit # 读取 $foo $ echo $foo bar 上面例子中，子 Shell 修改了继承的变量$foo，对父 Shell 没有影响。\n特殊变量\rBash 提供一些特殊变量。这些变量的值由 Shell 提供，用户不能进行赋值。\n（1）$?\n$?为上一个命令的退出码，用来判断上一个命令是否执行成功。返回值是0，表示上一个命令执行成功；如果不是零，表示上一个命令执行失败。\n1 2 3 4 5 $ ls doesnotexist ls: doesnotexist: No such file or directory $ echo $? 1 上面例子中，ls命令查看一个不存在的文件，导致报错。$?为1，表示上一个命令执行失败。\n（2）$$\n$$为当前 Shell 的进程 ID。\n1 2 $ echo $$ 10662 这个特殊变量可以用来命名临时文件。\n1 LOGFILE=/tmp/output_log.$$ （3）$_\n$_为上一个命令的最后一个参数。\n1 2 3 4 5 $ grep dictionary /usr/share/dict/words dictionary $ echo $_ /usr/share/dict/words （4）$!\n$!为最近一个后台执行的异步命令的进程 ID。\n1 2 3 4 5 $ firefox \u0026amp; [1] 11064 $ echo $! 11064 上面例子中，firefox是后台运行的命令，$!返回该命令的进程 ID。\n（5）$0\n$0为当前 Shell 的名称（在命令行直接执行时）或者脚本名（在脚本中执行时）。\n1 2 $ echo $0 bash 上面例子中，$0返回当前运行的是 Bash。\n（6）$-\n$-为当前 Shell 的启动参数。\n1 2 $ echo $- himBHs （7）$@和$#\n$#表示脚本的参数数量，$@表示脚本的参数值，参见脚本一章。\n变量的默认值\rBash 提供四个特殊语法，跟变量的默认值有关，目的是保证变量不为空。\n1 ${varname:-word} 上面语法的含义是，如果变量varname存在且不为空，则返回它的值，否则返回word。它的目的是返回一个默认值，比如${count:-0}表示变量count不存在时返回0。\n1 ${varname:=word} 上面语法的含义是，如果变量varname存在且不为空，则返回它的值，否则将它设为word，并且返回word。它的目的是设置变量的默认值，比如${count:=0}表示变量count不存在时返回0，且将count设为0。\n1 ${varname:+word} 上面语法的含义是，如果变量名存在且不为空，则返回word，否则返回空值。它的目的是测试变量是否存在，比如${count:+1}表示变量count存在时返回1（表示true），否则返回空值。\n1 ${varname:?message} 上面语法的含义是，如果变量varname存在且不为空，则返回它的值，否则打印出varname: message，并中断脚本的执行。如果省略了message，则输出默认的信息“parameter null or not set.”。它的目的是防止变量未定义，比如${count:?\u0026quot;undefined!\u0026quot;}表示变量count未定义时就中断执行，抛出错误，返回给定的报错信息undefined!。\n上面四种语法如果用在脚本中，变量名的部分可以用数字1到9，表示脚本的参数。\n1 filename=${1:?\u0026#34;filename missing.\u0026#34;} 上面代码出现在脚本中，1表示脚本的第一个参数。如果该参数不存在，就退出脚本并报错。\ndeclare 命令\rdeclare命令可以声明一些特殊类型的变量，为变量设置一些限制，比如声明只读类型的变量和整数类型的变量。\n它的语法形式如下。\n1 declare OPTION VARIABLE=value declare命令的主要参数（OPTION）如下。\n-a：声明数组变量。 -f：输出所有函数定义。 -F：输出所有函数名。 -i：声明整数变量。 -l：声明变量为小写字母。 -p：查看变量信息。 -r：声明只读变量。 -u：声明变量为大写字母。 -x：该变量输出为环境变量。 declare命令如果用在函数中，声明的变量只在函数内部有效，等同于local命令。\n不带任何参数时，declare命令输出当前环境的所有变量，包括函数在内，等同于不带有任何参数的set命令。\n1 $ declare （1）-i参数\n-i参数声明整数变量以后，可以直接进行数学运算。\n1 2 3 4 5 $ declare -i val1=12 val2=5 $ declare -i result $ result=val1*val2 $ echo $result 60 上面例子中，如果变量result不声明为整数，val1*val2会被当作字面量，不会进行整数运算。另外，val1和val2其实不需要声明为整数，因为只要result声明为整数，它的赋值就会自动解释为整数运算。\n注意，一个变量声明为整数以后，依然可以被改写为字符串。\n1 2 3 4 $ declare -i var=12 $ var=foo $ echo $var 0 上面例子中，变量var声明为整数，覆盖以后，Bash 不会报错，但会赋以不确定的值，上面的例子中可能输出0，也可能输出的是3。\n（2）-x参数\n-x参数等同于export命令，可以输出一个变量为子 Shell 的环境变量。\n1 2 3 $ declare -x foo # 等同于 $ export foo （3）-r参数\n-r参数可以声明只读变量，无法改变变量值，也不能unset变量。\n1 2 3 4 5 6 7 8 9 10 11 $ declare -r bar=1 $ bar=2 bash: bar：只读变量 $ echo $? 1 $ unset bar bash: bar：只读变量 $ echo $? 1 上面例子中，后两个赋值语句都会报错，命令执行失败。\n（4）-u参数\n-u参数声明变量为大写字母，可以自动把变量值转成大写字母。\n1 2 3 4 $ declare -u foo $ foo=upper $ echo $foo UPPER （5）-l参数\n-l参数声明变量为小写字母，可以自动把变量值转成小写字母。\n1 2 3 4 $ declare -l bar $ bar=LOWER $ echo $bar lower （6）-p参数\n-p参数输出变量信息。\n1 2 3 4 5 $ foo=hello $ declare -p foo declare -- foo=\u0026#34;hello\u0026#34; $ declare -p bar bar：未找到 上面例子中，declare -p可以输出已定义变量的值，对于未定义的变量，会提示找不到。\n如果不提供变量名，declare -p输出所有变量的信息。\n1 $ declare -p （7）-f参数\n-f参数输出当前环境的所有函数，包括它的定义。\n1 $ declare -f （8）-F参数\n-F参数输出当前环境的所有函数名，不包含函数定义。\n1 $ declare -F readonly 命令\rreadonly命令等同于declare -r，用来声明只读变量，不能改变变量值，也不能unset变量。\n1 2 3 4 5 $ readonly foo=1 $ foo=2 bash: foo：只读变量 $ echo $? 1 上面例子中，更改只读变量foo会报错，命令执行失败。\nreadonly命令有三个参数。\n-f：声明的变量为函数名。 -p：打印出所有的只读变量。 -a：声明的变量为数组。 let 命令\rlet命令声明变量时，可以直接执行算术表达式。\n1 2 3 $ let foo=1+2 $ echo $foo 3 上面例子中，let命令可以直接计算1 + 2。\nlet命令的参数表达式如果包含空格，就需要使用引号。\n1 $ let \u0026#34;foo = 1 + 2\u0026#34; let可以同时对多个变量赋值，赋值表达式之间使用空格分隔。\n1 2 3 $ let \u0026#34;v1 = 1\u0026#34; \u0026#34;v2 = v1++\u0026#34; $ echo $v1,$v2 2,1 上面例子中，let声明了两个变量v1和v2，其中v2等于v1++，表示先返回v1的值，然后v1自增。\n这种语法支持的运算符，参考《Bash 的算术运算》一章。\n","date":"2025-10-15T20:44:53Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_variable/","title":"Bash_variable"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\n引号和转义\r**Bash 只有一种数据类型，就是字符串。**不管用户输入什么数据，Bash 都视为字符串。因此，字符串相关的引号和转义，对 Bash 来说就非常重要。\n转义\r某些特殊字符在 Bash 里面有特殊含义（比如$、\u0026amp;、*）。\n1 2 3 $ echo $date $ 上面例子中，输出$date不会有任何结果，因为$是一个特殊字符。\n如果想要原样输出这些特殊字符，就必须在它们前面加上反斜杠，使其变成普通字符。这就叫做**“转义”（escape）**。\n1 2 $ echo \\$date $date 上面命令中，只有在特殊字符$前面加反斜杠，才能原样输出。\n反斜杠本身也是特殊字符，如果想要原样输出反斜杠，就需要对它自身转义，连续使用两个反斜线（\\\\）。\n1 2 $ echo \\\\ \\ 上面例子输出了反斜杠本身。\n反斜杠除了用于转义，还可以表示一些不可打印的字符。\n\\a：响铃 \\b：退格 \\n：换行 \\r：回车 \\t：制表符 如果想要在命令行使用这些不可打印的字符，可以把它们放在引号里面，然后使用echo命令的-e参数。\n1 2 3 4 5 $ echo a\\tb atb $ echo -e \u0026#34;a\\tb\u0026#34; a b 上面例子中，命令行直接输出不可打印字符\\t，Bash 不能正确解释。必须把它们放在引号之中，然后使用echo命令的-e参数。\n换行符是一个特殊字符，表示命令的结束，Bash 收到这个字符以后，就会对输入的命令进行解释执行。换行符前面加上反斜杠转义，就使得换行符变成一个普通字符，Bash 会将其当作长度为0的空字符处理，从而可以将一行命令写成多行。（多行中换行符的原理）\n1 2 3 4 5 6 $ mv \\ /path/to/foo \\ /path/to/bar # 等同于 $ mv /path/to/foo /path/to/bar 上面例子中，如果一条命令过长，就可以在行尾使用反斜杠，将其改写成多行。这是常见的多行命令的写法。\n单引号\rBash 允许字符串放在单引号或双引号之中，加以引用。\n单引号用于保留字符的字面含义，各种特殊字符在单引号里面，都会变为普通字符，**比如星号（*）、美元符号（$）、反斜杠（\\）**等。\n1 2 3 4 5 6 7 8 9 10 11 $ echo \u0026#39;*\u0026#39; * $ echo \u0026#39;$USER\u0026#39; $USER $ echo \u0026#39;$((2+2))\u0026#39; $((2+2)) $ echo \u0026#39;$(echo foo)\u0026#39; $(echo foo) 上面命令中，单引号使得 Bash 扩展、变量引用、算术运算和子命令，都失效了。如果不使用单引号，它们都会被 Bash 自动扩展。\n由于反斜杠在单引号里面变成了普通字符，所以如果单引号之中，还要使用单引号，不能使用转义，需要在外层的单引号前面加上一个美元符号（$），然后再对里层的单引号转义。\n1 2 3 4 5 6 7 8 # 不正确 $ echo it\u0026#39;s # 不正确 $ echo \u0026#39;it\\\u0026#39;s\u0026#39; # 正确 $ echo $\u0026#39;it\\\u0026#39;s\u0026#39; 不过，更合理的方法是改在双引号之中使用单引号。\n1 2 $ echo \u0026#34;it\u0026#39;s\u0026#34; it\u0026#39;s 双引号\r双引号比单引号宽松，大部分特殊字符在双引号里面，都会失去特殊含义，变成普通字符。\n1 2 $ echo \u0026#34;*\u0026#34; * 上面例子中，通配符*是一个特殊字符，放在双引号之中，就变成了普通字符，会原样输出。这一点需要特别留意，这意味着，双引号里面不会进行文件名扩展。\n但是，三个特殊字符除外：美元符号（$）、反引号（`）和反斜杠（\\）。这三个字符在双引号之中，依然有特殊含义，会被 Bash 自动扩展。\n1 2 3 4 5 $ echo \u0026#34;$SHELL\u0026#34; /bin/bash $ echo \u0026#34;`date`\u0026#34; Mon Jan 27 13:33:18 CST 2020 上面例子中，**美元符号（$）和反引号（`）在双引号中，都保持特殊含义。**美元符号用来引用变量，反引号则是执行子命令。\n1 2 3 4 5 6 # \\用来转义双引号里面的双引号 $ echo \u0026#34;I\u0026#39;d say: \\\u0026#34;hello.\\\u0026#34;\u0026#34; I\u0026#39;d say: \u0026#34;hello.\u0026#34; # 前一个\\用来转义后一个\\ $ echo \u0026#34;\\\\\u0026#34; \\ 上面例子中，反斜杠在双引号之中保持特殊含义，用来转义。所以，可以使用反斜杠，在双引号之中插入双引号，或者插入反斜杠本身。\n换行符在双引号之中，会失去特殊含义，Bash 不再将其解释为命令的结束，只是作为普通的换行符。所以可以利用双引号，在命令行输入多行文本。\n1 2 3 4 $ echo \u0026#34;hello world\u0026#34; hello world 上面命令中，Bash 正常情况下会将换行符解释为命令结束，但是换行符在双引号之中就失去了这种特殊作用，只用来换行，所以可以输入多行。echo命令会将换行符原样输出，显示的时候正常解释为换行。\n双引号的另一个常见的使用场合是，文件名包含空格。这时就必须使用双引号（或单引号），将文件名放在里面。\n1 $ ls \u0026#34;two words.txt\u0026#34; 上面命令中，two words.txt是一个包含空格的文件名，如果不放在双引号里面，就会被 Bash 当作两个文件。\n双引号会原样保存多余的空格。\n1 2 $ echo \u0026#34;this is a test\u0026#34; this is a test 双引号还有一个作用，就是保存原始命令的输出格式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 单行输出 $ echo $(cal) 一月 2020 日 一 二 三 四 五 六 1 2 3 ... 31 # 原始格式输出 $ echo \u0026#34;$(cal)\u0026#34; 一月 2020 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 上面例子中，如果$(cal)不放在双引号之中，echo就会将所有结果以单行输出，丢弃了所有原始的格式。\nHere 文档\rHere 文档（here document）是一种输入多行字符串的方法，格式如下。\n1 2 3 \u0026lt;\u0026lt; token text token 它的格式分成开始标记（\u0026lt;\u0026lt; token）和结束标记（token）。开始标记是两个小于号 + Here 文档的名称，名称可以随意取，后面必须是一个换行符；结束标记是单独一行顶格写的 Here 文档名称，如果不是顶格，结束标记不起作用。两者之间就是多行字符串的内容。\n下面是一个通过 Here 文档输出 HTML 代码的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ cat \u0026lt;\u0026lt; _EOF_ \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; The title of your page \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Your page content goes here. \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; _EOF_ Here 文档内部会发生变量替换，同时支持反斜杠转义，但是不支持通配符扩展，双引号和单引号也失去语法作用，变成了普通字符。\n1 2 3 4 5 6 7 8 9 10 $ foo=\u0026#39;hello world\u0026#39; $ cat \u0026lt;\u0026lt; _example_ $foo \u0026#34;$foo\u0026#34; \u0026#39;$foo\u0026#39; _example_ hello world \u0026#34;hello world\u0026#34; \u0026#39;hello world\u0026#39; 上面例子中，变量$foo发生了替换，但是双引号和单引号都原样输出了，表明它们已经失去了引用的功能。\n如果不希望发生变量替换，可以把 Here 文档的开始标记放在单引号之中。\n1 2 3 4 5 6 7 8 9 10 $ foo=\u0026#39;hello world\u0026#39; $ cat \u0026lt;\u0026lt; \u0026#39;_example_\u0026#39; $foo \u0026#34;$foo\u0026#34; \u0026#39;$foo\u0026#39; _example_ $foo \u0026#34;$foo\u0026#34; \u0026#39;$foo\u0026#39; 上面例子中，Here 文档的开始标记（_example_）放在单引号之中，导致变量替换失效了。\nHere 文档的本质是重定向，它将字符串重定向输出给某个命令，相当于包含了echo命令。\n1 2 3 4 5 6 7 $ command \u0026lt;\u0026lt; token string token # 等同于 # | 把string重定向到command $ echo string | command 上面代码中，Here 文档相当于echo命令的重定向。\n所以，**Here 字符串只适合那些可以接受标准输入作为参数的命令，对于其他命令无效，**比如echo命令就不能用 Here 文档作为参数。\n1 2 3 $ echo \u0026lt;\u0026lt; _example_ hello _example_ 上面例子不会有任何输出，因为 Here 文档对于echo命令无效。\n此外，Here 文档也不能作为变量的值，只能用于命令的参数。\nHere 字符串\rHere 文档还有一个变体，叫做 Here 字符串（Here string），使用三个小于号（\u0026lt;\u0026lt;\u0026lt;）表示。\n1 \u0026lt;\u0026lt;\u0026lt; string 它的作用是将字符串通过标准输入，传递给命令。\n这里补充说明一下：\n命令行参数 vs 标准输入\n命令行参数：写在命令后面的词，比如 command arg1 arg2。 标准输入（stdin）：程序运行时从键盘、管道、重定向等方式读入的数据。 很多命令可以同时支持这两种方式，但处理逻辑可能不同,，结果也可能不同。\n1 2 3 4 # 尝试读取名为 hello 的文件。 cat hello # 输出字符串 hello（因为 cat 默认输出 stdin 内容）。 cat \u0026lt;\u0026lt;\u0026lt; \u0026#34;hello\u0026#34; 有些命令直接接受给定的参数，与通过标准输入接受参数，结果是不一样的。所以才有了这个语法，使得将字符串通过标准输入传递给命令更方便，比如cat命令只接受标准输入传入的字符串。\n1 2 3 $ cat \u0026lt;\u0026lt;\u0026lt; \u0026#39;hi there\u0026#39; # 等同于 $ echo \u0026#39;hi there\u0026#39; | cat 上面的第一种语法使用了 Here 字符串，要比第二种语法看上去语义更好，也更简洁。\n1 2 3 $ md5sum \u0026lt;\u0026lt;\u0026lt; \u0026#39;ddd\u0026#39; # 等同于 $ echo \u0026#39;ddd\u0026#39; | md5sum 上面例子中，md5sum命令只能接受标准输入作为参数，不能直接将字符串放在命令后面，会被当作文件名，即md5sum ddd里面的ddd会被解释成文件名。这时就可以用 Here 字符串，将字符串传给md5sum命令。\n注意\n如果少打了一个\u0026lt;，就会变成Here文档，不断等待文档的结束符号。\n","date":"2025-10-15T19:08:35Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_quotation/","title":"Bash_quotation"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash的模式拓展\r简介\r详见 Bash 的模式扩展 - Bash 脚本教程 - 网道\n注意：Bash 是先进行扩展，再执行命令。因此，扩展的结果是由 Bash 负责的，与所要执行的命令无关。命令本身并不存在参数扩展，收到什么参数就原样执行。这一点务必需要记住。\n波浪线扩展\r波浪线~会自动扩展成当前用户的主目录。\n1 2 $ echo ~ /home/me ~/dir表示扩展成主目录的某个子目录，dir是主目录里面的一个子目录名。\n1 2 # 进入 /home/me/foo 目录 $ cd ~/foo ~user表示扩展成用户user的主目录。\n1 2 3 4 5 $ echo ~foo /home/foo $ echo ~root /root 上面例子中，Bash 会根据波浪号后面的用户名，返回该用户的主目录。\n如果~user的user是不存在的用户名，则波浪号扩展不起作用。\n1 2 $ echo ~nonExistedUser ~nonExistedUser ~+会扩展成当前所在的目录，等同于pwd命令。\n1 2 3 $ cd ~/foo $ echo ~+ /home/me/foo ? 字符扩展\r?字符代表文件路径里面的任意单个字符，不包括空字符。比如，Data???匹配所有Data后面跟着三个字符的文件名。\n1 2 3 4 # 存在文件 a.txt 和 b.txt $ ls ?.txt # 自动匹配符合格式的文件 a.txt b.txt 上面命令中，?表示单个字符，所以会同时匹配a.txt和b.txt。\n如果匹配多个字符，就需要多个?连用。\n1 2 3 # 存在文件 a.txt、b.txt 和 ab.txt $ ls ??.txt ab.txt 上面命令中，??匹配了两个字符。\n? 字符扩展属于文件名扩展，只有文件确实存在的前提下，才会发生扩展。如果文件不存在，扩展就不会发生。\n1 2 3 4 5 6 7 # 当前目录有 a.txt 文件 $ echo ?.txt a.txt # 当前目录为空目录 $ echo ?.txt ?.txt 上面例子中，如果?.txt可以扩展成文件名，echo命令会输出扩展后的结果；如果不能扩展成文件名，echo就会原样输出?.txt。\n* 字符扩展\r*字符代表文件路径里面的任意数量的任意字符，包括零个字符。\n1 2 3 # 存在文件 a.txt、b.txt 和 ab.txt $ ls *.txt a.txt b.txt ab.txt 上面例子中，*.txt代表后缀名为.txt的所有文件。\n如果想输出当前目录的所有文件，直接用*即可。\n1 $ ls * *可以匹配空字符，下面是一个例子。\n1 2 3 4 5 6 # 存在文件 a.txt、b.txt 和 ab.txt $ ls a*.txt a.txt ab.txt $ ls *b* b.txt ab.txt 注意，*不会匹配隐藏文件（以.开头的文件），即**ls *不会输出隐藏文件**。\n如果要匹配隐藏文件，需要写成.*。\n1 2 # 显示所有隐藏文件 $ echo .* 如果要匹配隐藏文件，同时要排除.和..这两个特殊的隐藏文件，可以与方括号扩展结合使用，写成.[!.]*。\n1 $ echo .[!.]* 注意，*字符扩展属于文件名扩展，只有文件确实存在的前提下才会扩展。如果文件不存在，就会原样输出。\n1 2 3 # 当前目录不存在 c 开头的文件 $ echo c*.txt c*.txt 上面例子中，当前目录里面没有c开头的文件，导致c*.txt会原样输出。\n*只匹配当前目录，不会匹配子目录。\n1 2 3 4 5 6 # 子目录有一个 a.txt # 无效的写法 $ ls *.txt # 有效的写法 $ ls */*.txt 上面的例子，文本文件在子目录，*.txt不会产生匹配，必须写成*/*.txt。有几层子目录，就必须写几层星号。\nBash 4.0 引入了一个参数globstar，当该参数打开时，允许**匹配零个或多个子目录。因此，**/*.txt可以匹配顶层的文本文件和任意深度子目录的文本文件。详细介绍请看后面shopt命令的介绍。\n另外，ls * 会：\n显示当前目录下的所有非隐藏文件名； 并且递归展开（仅一层）所有子目录的内容（即列出每个子目录里的文件和文件夹）。 方括号扩展\r方括号扩展的形式是[...]，只有文件确实存在的前提下才会扩展。如果文件不存在，就会原样输出。[...]会匹配括号之中的任意一个字符。比如，[aeiou]可以匹配五个元音字母中的任意一个。\n1 2 3 4 5 6 7 # 存在文件 a.txt 和 b.txt $ ls [ab].txt a.txt b.txt # 只存在文件 a.txt $ ls [ab].txt a.txt 上面例子中，[ab]可以匹配a或b，前提是确实存在相应的文件。\n方括号扩展属于文件名匹配，即扩展后的结果必须符合现有的文件路径。如果不存在匹配，就会保持原样，不进行扩展。\n1 2 3 # 不存在文件 a.txt 和 b.txt $ ls [ab].txt ls: 无法访问\u0026#39;[ab].txt\u0026#39;: 没有那个文件或目录 上面例子中，由于扩展后的文件不存在，[ab].txt就原样输出了，导致ls命名报错。\n方括号扩展还有两种变体：[^...]和[!...]。它们表示匹配不在方括号里面的字符，这两种写法是等价的。比如，[^abc]或[!abc]表示匹配除了a、b、c以外的字符。\n1 2 3 # 存在 aaa、bbb、aba 三个文件 $ ls ?[!a]? aba bbb 上面命令中，[!a]表示文件名第二个字符不是a的文件名，所以返回了aba和bbb两个文件。\n注意，如果需要匹配[字符，可以放在方括号内，比如[[aeiou]。如果需要匹配连字号-，只能放在方括号内部的开头或结尾，比如[-aeiou]或[aeiou-]。\n[start-end] 扩展\r方括号扩展有一个简写形式**[start-end]，表示匹配一个连续的范围**。比如，[a-c]等同于[abc]，[0-9]匹配[0123456789]。\n1 2 3 4 5 6 7 8 9 10 11 12 # 存在文件 a.txt、b.txt 和 c.txt $ ls [a-c].txt a.txt b.txt c.txt # 存在文件 report1.txt、report2.txt 和 report3.txt $ ls report[0-9].txt report1.txt report2.txt report3.txt ... 下面是一些常用简写的例子。\n[a-z]：所有小写字母。 [a-zA-Z]：所有小写字母与大写字母。 [a-zA-Z0-9]：所有小写字母、大写字母与数字。 [abc]*：所有以a、b、c字符之一开头的文件名。 program.[co]：文件program.c与文件program.o。 BACKUP.[0-9][0-9][0-9]：所有以BACKUP.开头，后面是三个数字的文件名。 这种简写形式有一个否定形式[!start-end]，表示匹配不属于这个范围的字符。比如，[!a-zA-Z]表示匹配非英文字母的字符。\n1 2 $ ls report[!1–3].txt report4.txt report5.txt 上面代码中，[!1-3]表示排除1、2和3。\n大括号扩展\r大括号扩展{...}表示分别扩展成大括号里面的所有值，各个值之间使用逗号分隔。比如，{1,2,3}扩展成1 2 3。\n1 2 3 4 5 6 7 8 $ echo {1,2,3} 1 2 3 $ echo d{a,e,i,u,o}g dag deg dig dug dog $ echo Front-{A,B,C}-Back Front-A-Back Front-B-Back Front-C-Back 注意，大括号扩展不是文件名扩展。它会扩展成所有给定的值，而不管是否有对应的文件存在。\n1 2 3 4 $ ls {a,b,c}.txt ls: 无法访问\u0026#39;a.txt\u0026#39;: 没有那个文件或目录 ls: 无法访问\u0026#39;b.txt\u0026#39;: 没有那个文件或目录 ls: 无法访问\u0026#39;c.txt\u0026#39;: 没有那个文件或目录 上面例子中，即使不存在对应的文件，{a,b,c}依然扩展成三个文件名，导致ls命令报了三个错误。\n另一个需要注意的地方是，大括号内部的逗号前后不能有空格。否则，大括号扩展会失效。\n1 2 $ echo {1 , 2} {1 , 2} 上面例子中，逗号前后有空格，Bash 就会认为这不是大括号扩展，而是三个独立的参数。\n逗号前面可以没有值，表示扩展的第一项为空。\n1 2 3 4 $ cp a.log{,.bak} # 等同于 # cp a.log a.log.bak 大括号可以嵌套。\n1 2 3 4 5 $ echo {j{p,pe}g,png} jpg jpeg png $ echo a{A{1,2},B{3,4}}b aA1b aA2b aB3b aB4b 大括号也可以与其他模式联用，并且总是先于其他模式进行扩展。\n1 2 3 4 5 $ echo /bin/{cat,b*} /bin/cat /bin/b2sum /bin/base32 /bin/base64 ... ... # 基本等同于 $ echo /bin/cat;echo /bin/b* 上面例子中，会先进行大括号扩展，然后进行*扩展，等同于执行两条echo命令。\n大括号可以用于多字符的模式，方括号不行（只能匹配单字符）。\n1 2 $ echo {cat,dog} cat dog 由于大括号扩展{...}不是文件名扩展，所以它总是会扩展的。这与方括号扩展[...]完全不同，如果匹配的文件不存在，方括号就不会扩展。这一点要注意区分。\n1 2 3 4 5 6 # 不存在 a.txt 和 b.txt $ echo [ab].txt [ab].txt $ echo {a,b}.txt a.txt b.txt 上面例子中，如果不存在a.txt和b.txt，那么[ab].txt就会变成一个普通的文件名，而{a,b}.txt可以照样扩展。\n{start..end} 扩展\r大括号扩展有一个简写形式{start..end}，表示扩展成一个连续序列。比如，{a..z}可以扩展成26个小写英文字母。\n1 2 3 4 5 6 7 8 9 10 11 $ echo {a..c} a b c $ echo d{a..d}g dag dbg dcg ddg $ echo {1..4} 1 2 3 4 $ echo Number_{1..5} Number_1 Number_2 Number_3 Number_4 Number_5 这种简写形式支持逆序。\n1 2 3 4 5 $ echo {c..a} c b a $ echo {5..1} 5 4 3 2 1 注意，如果遇到无法理解的简写，大括号模式就会原样输出，不会扩展。\n1 2 $ echo {a1..3c} {a1..3c} 这种简写形式可以嵌套使用，形成复杂的扩展。\n1 2 $ echo .{mp{3..4},m4{a,b,p,v}} .mp3 .mp4 .m4a .m4b .m4p .m4v 大括号扩展的常见用途为新建一系列目录。\n1 $ mkdir {2007..2009}-{01..12} 上面命令会新建36个子目录，每个子目录的名字都是”年份-月份“。\n这个写法的另一个常见用途，是直接用于for循环。\n1 2 3 4 for i in {1..4} do echo $i done 上面例子会循环4次。\n如果整数前面有前导0，扩展输出的每一项都有前导0。\n1 2 3 4 5 $ echo {01..5} 01 02 03 04 05 $ echo {001..5} 001 002 003 004 005 这种简写形式还可以使用第二个双点号（start..end..step），用来指定扩展的步长。\n1 2 $ echo {0..8..2} 0 2 4 6 8 上面代码将0扩展到8，每次递增的长度为2，所以一共输出5个数字。\n多个简写形式连用，会有循环处理的效果。\n1 2 $ echo {a..c}{1..3} a1 a2 a3 b1 b2 b3 c1 c2 c3 变量扩展\rBash 将美元符号$开头的词元视为变量，将其扩展成变量值，详见《Bash 变量》一章。\n1 2 $ echo $SHELL /bin/bash 变量名除了放在美元符号后面，也可以放在${}里面。\n1 2 $ echo ${SHELL} /bin/bash ${!string*}或${!string@}返回所有 以字符串 string 开头的变量名。\n这是一个特殊语法\n! 在这里是语法标记，告诉 Bash：“接下来不是普通变量，而是要列出以某前缀开头的变量名”。 S* 中的 * 不是通配符展开，而是这个特殊语法的一部分。 1 2 $ echo ${!S*} SECONDS SHELL SHELLOPTS SHLVL SSH_AGENT_PID SSH_AUTH_SOCK 上面例子中，${!S*}扩展成所有以S开头的变量名。\n子命令扩展\r$(...)可以扩展成另一个命令的运行结果，该命令的所有输出都会作为返回值。\n1 2 $ echo $(date) Tue Jan 28 00:01:13 CST 2020 上面例子中，$(date)返回date命令的运行结果。\n还有另一种较老的语法，子命令放在反引号之中，也可以扩展成命令的运行结果。\n1 2 $ echo `date` Tue Jan 28 00:01:13 CST 2020 $(...)可以嵌套，比如$(ls $(pwd))。\n算术扩展\r$((...))可以扩展成整数运算的结果，详见《Bash 的算术运算》一章。\n1 2 $ echo $((2 + 2)) 4 字符类\r[[:class:]]表示一个字符类，扩展成某一类特定字符之中的一个。常用的字符类如下。\n[[:alnum:]]：匹配任意英文字母与数字 [[:alpha:]]：匹配任意英文字母 [[:blank:]]：空格和 Tab 键。 [[:cntrl:]]：ASCII 码 0-31 的不可打印字符。 [[:digit:]]：匹配任意数字 0-9。 [[:graph:]]：A-Z、a-z、0-9 和标点符号。 [[:lower:]]：匹配任意小写字母 a-z。 [[:print:]]：ASCII 码 32-127 的可打印字符。 [[:punct:]]：标点符号（除了 A-Z、a-z、0-9 的可打印字符）。 [[:space:]]：空格、Tab、LF（10）、VT（11）、FF（12）、CR（13）。 [[:upper:]]：匹配任意大写字母 A-Z。 [[:xdigit:]]：16进制字符（A-F、a-f、0-9）。 请看下面的例子。\n1 $ echo [[:upper:]]* 上面命令输出所有大写字母开头的文件名。\n字符类的第一个方括号后面，可以加上感叹号!（或^），表示否定。比如，[![:digit:]](或[^[:digit:]])匹配所有非数字。\n1 $ echo [![:digit:]]* 上面命令输出所有不以数字开头的文件名。\n字符类也属于文件名扩展，如果没有匹配的文件名，字符类就会原样输出。\n1 2 3 # 不存在以大写字母开头的文件 $ echo [[:upper:]]* [[:upper:]]* 上面例子中，由于没有可匹配的文件，字符类就原样输出了。\n使用注意点\r通配符有一些使用注意点，不可不知。\n（1）通配符是先解释，再执行。\nBash 接收到命令以后，发现里面有通配符，会进行通配符扩展，然后再执行命令。\n1 2 $ ls a*.txt ab.txt 上面命令的执行过程是，Bash 先将a*.txt扩展成ab.txt，然后再执行ls ab.txt。\n（2）文件名扩展在不匹配时，会原样输出。\n文件名扩展在没有可匹配的文件时，会原样输出。\n1 2 3 # 不存在 r 开头的文件名 $ echo r* r* 上面代码中，由于不存在r开头的文件名，r*会原样输出。\n下面是另一个例子。\n1 2 $ ls *.csv ls: *.csv: No such file or directory 另外，前面已经说过，大括号扩展{...}不是文件名扩展。\n（3）只适用于单层路径。\n所有文件名扩展只匹配单层路径，不能跨目录匹配，即无法匹配子目录里面的文件。或者说**，?或***这样的通配符，不能匹配路径分隔符（/）。\n如果要匹配子目录里面的文件，可以写成下面这样。\n1 $ ls */*.txt Bash 4.0 新增了一个globstar参数，允许**匹配零个或多个子目录，详见后面shopt命令的介绍。\n（4）文件名可以使用通配符。\nBash 允许文件名使用通配符，即文件名包括特殊字符。这时引用文件名，需要把文件名放在单引号或双引号里面。\n1 2 3 $ touch \u0026#39;fo*\u0026#39; $ ls fo* 上面代码创建了一个fo*文件，这时*就是文件名的一部分。\n量词语法\r量词语法用来控制模式匹配的次数。它只有在 Bash 的extglob参数打开的情况下才能使用，不过一般是默认打开的。下面的命令可以查询。\n1 2 $ shopt extglob extglob on 如果extglob参数是关闭的，可以用下面的命令打开。\n1 $ shopt -s extglob 量词语法有下面几个。\n?(pattern-list)：模式匹配零次或一次。 *(pattern-list)：模式匹配零次或多次。 +(pattern-list)：模式匹配一次或多次。 @(pattern-list)：只匹配一次模式。 !(pattern-list)：匹配给定模式以外的任何内容。 1 2 $ ls abc?(.)txt abctxt abc.txt 上面例子中，?(.)匹配零个或一个点。\n1 2 $ ls abc?(def) abc abcdef 上面例子中，?(def)匹配零个或一个def。\n1 2 $ ls abc@(.txt|.php) abc.php abc.txt 上面例子中，@(.txt|.php)匹配文件有且只有一个.txt或.php后缀名。\n1 2 $ ls abc+(.txt) abc.txt abc.txt.txt 上面例子中，+(.txt)匹配文件有一个或多个.txt后缀名。\n1 2 $ ls a!(b).txt a.txt abb.txt ac.txt 上面例子中，!(b)表示匹配单个字母b以外的任意内容，所以除了ab.txt以外，其他文件名都能匹配。\n量词语法也属于文件名扩展，如果不存在可匹配的文件，就会原样输出。\n1 2 3 # 没有 abc 开头的文件名 $ ls abc?(def) ls: 无法访问\u0026#39;abc?(def)\u0026#39;: 没有那个文件或目录 上面例子中，由于没有可匹配的文件，abc?(def)就原样输出，导致ls命令报错。\nshopt 命令\rshopt命令可以调整 Bash 的行为。它有好几个参数跟通配符扩展有关。\nshopt命令的使用方法如下。\n1 2 3 4 5 6 7 8 # 打开某个参数 $ shopt -s [optionname] # 关闭某个参数 $ shopt -u [optionname] # 查询某个参数关闭还是打开 $ shopt [optionname] （1）dotglob 参数\ndotglob参数可以让扩展结果包括隐藏文件（即点开头的文件）。\n正常情况下，扩展结果不包括隐藏文件。\n1 2 $ ls * abc.txt 打开dotglob，就会包括隐藏文件。\n1 2 3 $ shopt -s dotglob $ ls * abc.txt .config （2）nullglob 参数\nnullglob参数可以让通配符不匹配任何文件名时，返回空字符。\n默认情况下，通配符不匹配任何文件名时，会保持不变。\n1 2 $ rm b* rm: 无法删除\u0026#39;b*\u0026#39;: 没有那个文件或目录 上面例子中，由于当前目录不包括b开头的文件名，导致b*不会发生文件名扩展，保持原样不变，所以rm命令报错没有b*这个文件。\n打开nullglob参数，就可以让不匹配的通配符返回空字符串。\n1 2 3 $ shopt -s nullglob $ rm b* rm: 缺少操作数 上面例子中，由于没有b*匹配的文件名，所以rm b*扩展成了rm，导致报错变成了”缺少操作数“。\n（3）failglob 参数\nfailglob参数使得通配符不匹配任何文件名时，Bash 会直接报错，而不是让各个命令去处理。\n1 2 3 $ shopt -s failglob $ rm b* bash: 无匹配: b* 上面例子中，打开failglob以后，由于b*不匹配任何文件名，Bash 直接报错了，不再让rm命令去处理。\n（4）extglob 参数\nextglob参数使得 Bash 支持 ksh 的一些扩展语法。它默认应该是打开的。\n1 2 $ shopt extglob extglob on 它的主要应用是支持量词语法。如果不希望支持量词语法，可以用下面的命令关闭。\n1 $ shopt -u extglob （5）nocaseglob 参数\nnocaseglob参数可以让通配符扩展不区分大小写。\n1 2 3 4 5 $ shopt -s nocaseglob $ ls /windows/program* /windows/ProgramData /windows/Program Files /windows/Program Files (x86) 上面例子中，打开nocaseglob以后，program*就不区分大小写了，可以匹配ProgramData等。\n（6）globstar 参数\nglobstar参数可以使得**匹配零个或多个子目录。该参数默认是关闭的。\n假设有下面的文件结构。\n1 2 3 a.txt sub1/b.txt sub1/sub2/c.txt 上面的文件结构中，顶层目录、第一级子目录sub1、第二级子目录sub1\\sub2里面各有一个文本文件。请问怎样才能使用通配符，将它们显示出来？\n默认情况下，只能写成下面这样。\n1 2 $ ls *.txt */*.txt */*/*.txt a.txt sub1/b.txt sub1/sub2/c.txt 这是因为*只匹配当前目录，如果要匹配子目录，只能一层层写出来。\n打开globstar参数以后，**匹配零个或多个子目录。因此，**/*.txt就可以得到想要的结果。\n1 2 3 $ shopt -s globstar $ ls **/*.txt a.txt sub1/b.txt sub1/sub2/c.txt 参考链接\rThink You Understand Wildcards? Think Again Advanced Wildcard Patterns Most People Don’t Know ","date":"2025-10-15T16:38:58Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_expansion/","title":"Bash_expansion"},{"content":" 学习参考的教程为Bash 脚本教程 - 网道，非常感谢开源工作者的贡献！\n如使用到该教程，可随意使用，但请标明出处（Bash 脚本教程 - 网道）。\n笔记汇总在Bash中。\nBash简介\rBash 简介 - Bash 脚本教程 - 网道\n该部分详见上述网站，都是些基本性的概念\nBash的基本语法\recho命令\r1 2 3 # echo命令的作用是在屏幕输出一行文本，可以将该命令的参数原样输出。 $ echo hello world hello world 如果想要输出的是多行文本，即包括换行符。这时就需要把多行文本放在引号里面。\n1 2 3 4 5 6 7 8 $ echo \u0026#34;\u0026lt;HTML\u0026gt; \u0026lt;HEAD\u0026gt; \u0026lt;TITLE\u0026gt;Page Title\u0026lt;/TITLE\u0026gt; \u0026lt;/HEAD\u0026gt; \u0026lt;BODY\u0026gt; Page body. \u0026lt;/BODY\u0026gt; \u0026lt;/HTML\u0026gt;\u0026#34; 上面例子中，echo可以原样输出多行文本。\n但是，其实不好用，因为除非你一口气全部复制进命令行，不然你一回车就会被截断。\n所以输出多行更推荐用cat：\n1 2 3 4 5 6 7 8 9 10 11 # cat \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; 表示从下一行开始读取内容，直到遇到单独一行的 EOF。 cat \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; \u0026lt;HTML\u0026gt; \u0026lt;HEAD\u0026gt; \u0026lt;TITLE\u0026gt;Page Title\u0026lt;/TITLE\u0026gt; \u0026lt;/HEAD\u0026gt; \u0026lt;BODY\u0026gt; Page body. \u0026lt;/BODY\u0026gt; \u0026lt;/HTML\u0026gt; EOF #结束符号 -n参数\r默认情况下，echo输出的文本末尾会有一个回车符。-n参数可以取消末尾的回车符，使得下一个提示符紧跟在输出内容的后面。\n1 2 $ echo -n hello world hello world$ 上面例子中，world后面直接就是下一行的提示符$。\n1 2 3 4 5 $ echo a;echo b a b $ echo -n a;echo b ab 上面例子中，-n参数可以让两个echo命令的输出连在一起，出现在同一行。\n-e参数\r-e参数会解释引号（双引号和单引号）里面的特殊字符（比如换行符\\n）。如果不使用-e参数，即默认情况下，引号会让特殊字符变成普通字符，echo不解释它们，原样输出。\n1 2 3 4 5 6 7 8 9 10 11 12 $ echo \u0026#34;Hello\\nWorld\u0026#34; Hello\\nWorld # 双引号的情况 $ echo -e \u0026#34;Hello\\nWorld\u0026#34; Hello World # 单引号的情况 $ echo -e \u0026#39;Hello\\nWorld\u0026#39; Hello World 上面代码中，-e参数使得\\n解释为换行符，导致输出内容里面出现换行。\n命令格式\r命令行环境中，主要通过使用 Shell 命令，进行各种操作。Shell 命令基本都是下面的格式。\n1 $ command [ arg1 ... [ argN ]] 上面代码中，command是具体的命令或者一个可执行文件，arg1 ... argN是传递给命令的参数，它们是可选的。\n1 $ ls -l 上面这个命令中，ls是命令，-l是参数。\n有些参数是命令的配置项，这些配置项一般都以一个连词线开头，比如上面的-l。同一个配置项往往有长和短两种形式，比如-l是短形式，--list是长形式，它们的作用完全相同。短形式便于手动输入，长形式一般用在脚本之中，可读性更好，利于解释自身的含义。\n1 2 3 4 5 # 短形式 $ ls -r # 长形式 $ ls --reverse 上面命令中，-r是短形式，--reverse是长形式，作用完全一样。前者便于输入，后者便于理解。\nBash 单个命令一般都是一行，用户按下回车键，就开始执行。有些命令比较长，写成多行会有利于阅读和编辑，这时可以在每一行的结尾加上反斜杠，Bash 就会将下一行跟当前行放在一起解释。\n1 2 3 4 5 $ echo foo bar # 等同于 $ echo foo \\ bar 空格\rBash 使用空格（或 Tab 键）区分不同的参数。\n1 $ command foo bar 上面命令中，foo和bar之间有一个空格，所以 Bash 认为它们是两个参数。\n如果参数之间有多个空格，Bash 会自动忽略多余的空格。\n1 2 $ echo this is a test this is a test 上面命令中，a和test之间有多个空格，Bash 会忽略多余的空格。\n分号\r分号（;）是命令的结束符，使得一行可以放置多个命令，上一个命令执行结束后，再执行第二个命令。\n1 $ clear; ls 上面例子中，Bash 先执行clear命令，执行完成后，再执行ls命令。\n注意，使用分号时，第二个命令总是接着第一个命令执行，不管第一个命令执行成功或失败。\n命令的组合符\u0026amp;\u0026amp;和||\r除了分号，Bash 还提供两个命令组合符\u0026amp;\u0026amp;和||，允许更好地控制多个命令之间的继发关系。\n1 2 # 肯定先继 Command1 \u0026amp;\u0026amp; Command2 上面命令的意思是，如果Command1命令运行成功，则继续运行Command2命令。\n1 2 # 否定先继 Command1 || Command2 上面命令的意思是，如果Command1命令运行失败，则继续运行Command2命令。\n下面是一些例子。\n1 $ cat filelist.txt ; ls -l filelist.txt 上面例子中，只要cat命令执行结束，不管成功或失败，都会继续执行ls命令。\n1 $ cat filelist.txt \u0026amp;\u0026amp; ls -l filelist.txt 上面例子中，只有cat命令执行成功，才会继续执行ls命令。如果cat执行失败（比如不存在文件flielist.txt），那么ls命令就不会执行。\n1 $ mkdir foo || mkdir bar 上面例子中，只有mkdir foo命令执行失败（比如foo目录已经存在），才会继续执行mkdir bar命令。如果mkdir foo命令执行成功，就不会创建bar目录了。\ntype 命令\rBash 本身内置了很多命令，同时也可以执行外部程序。怎么知道一个命令是内置命令，还是外部程序呢？\ntype命令用来判断命令的来源。\n1 2 3 4 $ type echo echo is a shell builtin $ type ls ls is hashed (/bin/ls) 上面代码中，type命令告诉我们，echo是内部命令，ls是外部程序（/bin/ls）。\ntype命令本身也是内置命令。\n1 2 $ type type type is a shell builtin 如果要查看一个命令的所有定义，可以使用type命令的-a参数。\n1 2 3 4 $ type -a echo echo is shell builtin echo is /usr/bin/echo echo is /bin/echo 上面代码表示，echo命令既是内置命令，也有对应的外部程序。\ntype命令的**-t参数**，可以返回一个命令的类型：别名（alias），关键词（keyword），函数（function），内置命令（builtin）和文件（file）。\n1 2 3 4 $ type -t bash file $ type -t if keyword 上面例子中，bash是文件，if是关键词。\n快捷键\rBash 提供很多快捷键，可以大大方便操作。下面是一些最常用的快捷键，完整的介绍参见《行操作》一章。\nCtrl + L：清除屏幕并将当前行移到页面顶部。 Ctrl + C：中止当前正在执行的命令。 Shift + PageUp：向上滚动。 Shift + PageDown：向下滚动。 Ctrl + U：从光标位置删除到行首。 Ctrl + K：从光标位置删除到行尾。 Ctrl + W：删除光标位置前一个单词。 Ctrl + D：关闭 Shell 会话。 ↑，↓：浏览已执行命令的历史记录。 除了上面的快捷键，Bash 还具有自动补全功能。命令输入到一半的时候，可以按下 Tab 键，Bash 会自动完成剩下的部分。比如，输入tou，然后按一下 Tab 键，Bash 会自动补上ch。\n除了命令的自动补全，Bash 还支持路径的自动补全。有时，需要输入很长的路径，这时只需要输入前面的部分，然后按下 Tab 键，就会自动补全后面的部分。如果有多个可能的选择，按两次 Tab 键，Bash 会显示所有选项，让你选择。\n","date":"2025-10-15T16:10:33Z","image":"http://localhost:1313/images/Cloud.png","permalink":"http://localhost:1313/p/bash_introgrammar/","title":"Bash_intro\u0026grammar"},{"content":"本文是本人学习 Linux 命令行 Bash 的基本用法和脚本编程的笔记汇总。\n核心参考教程：Bash 脚本教程 - 网道\n这是一个互联网开源文档，非常感谢开源创作者的贡献。\nBash 介绍和基本语法 Bash 模式扩展 Bash 引号和转义 Bash 变量 Bash 字符串操作 Bash 算术运算 Bash 历史命令 Bash 行操作 Bash 目录堆栈 Bash 脚本 Bash read命令 Bash 条件判断 Bash 循环 Bash 函数 Bash 数组 Bash set\u0026amp;shopt Bash 调试除错 Bash mktemp\u0026amp;trap Bash 启动环境 Bash 命令提示符 ","date":"2025-10-15T16:02:47Z","image":"http://localhost:1313/images/Cat\u0026Tree.png","permalink":"http://localhost:1313/p/bash/","title":"Bash"},{"content":"WindRanger\u0026amp;BeaconFuzz\rWindRanger 是一个基于 BeaconFuzz 算法的定向模糊测试工具，发表于 ICSE 2022，旨在高效引导模糊测试到达目标代码（如漏洞触发点）。其核心创新是 BeaconFuzz 策略，通过动态识别关键代码块（Beacon）来优化路径探索。\n1. WindRanger 概述\r1.1 是什么？\rWindRanger 是一个灰盒（Greybox）定向模糊测试工具，基于 AFL++ 改进，专门用于快速触发特定代码位置（如已知漏洞点）。 主要用途： 漏洞复现（如 CVE 测试） 补丁验证（检查修复是否有效） 关键代码覆盖测试 1.2 核心优势\r对比对象 传统定向模糊测试（如 AFLGo） WindRanger 引导方式 静态控制流距离（固定优先级） 动态 Beacon 识别（自适应优化） 路径探索 容易陷入局部最优（长路径依赖） 通过 Beacon 发现“捷径” 效率 较慢（需大量变异） 更快收敛到目标 2. BeaconFuzz：WindRanger 的核心算法\r2.1 BeaconFuzz 的核心思想\rBeaconFuzz 的核心是 Deviation Basic Blocks（偏离基本块，即 Beacon），它通过以下方式优化模糊测试：\n静态分析阶段： 识别程序中能显著缩短到目标代码距离的分支（即 Beacon 块）。 例如：if (x \u0026gt; 100) 的分支比 else 分支更接近目标，则 x \u0026gt; 100 被标记为 Beacon。 动态执行阶段： 优先变异那些能触发 Beacon 块的输入，快速逼近目标。 2.2 BeaconFuzz 的工作流程\r（1）静态分析（由 cbi 工具完成）\r输入： 目标程序的 LLVM 字节码（.bc 文件） 用户指定的目标代码行（如 decompile.c:398） 步骤： 构建控制流图（CFG）：分析程序的基本块（Basic Block）和跳转关系。 计算静态距离：对每个基本块，计算其到目标代码的最短路径步数。 识别 Beacon 块：标记能显著缩短距离的关键分支（如 if-else 中的某个分支）。 （2）动态模糊测试（由改进的 afl-fuzz 执行）\r种子调度： 对输入队列中的种子，根据其是否触发 Beacon 动态调整优先级。 奖励机制：触发 Beacon 的种子会被更频繁地变异。 变异策略： 结合 AFL 的变异方式（如位翻转、算术变异），但偏向生成能覆盖 Beacon 的输入。 3. WindRanger 和 BeaconFuzz 的关系\r3.1 WindRanger = BeaconFuzz + 工具链实现\r组件 功能 BeaconFuzz 的作用 cbi 静态分析，插桩 识别 Beacon 块，计算距离 afl-fuzz 动态模糊测试 基于 Beacon 动态调整种子优先级 beacon.txt 记录 Beacon 触发情况 用于调试和优化引导策略 BeaconFuzz 是windranger的核心导航算法，负责找到最优路径。 其他组件（如插桩、崩溃检测）是剩余fuzz流程的补全。 ","date":"2025-10-14T14:59:29Z","image":"http://localhost:1313/images/ChillOcean.png","permalink":"http://localhost:1313/p/beaconwindranger/","title":"Beacon\u0026WindRanger"},{"content":"DGF Tool Energy Allocation Strategies\rDGF工具能量分配策略一览\nAFL\r本节聚焦AFL 及其衍生工具在 seed fuzzing 过程中的能量分配策略（power schedule），即决定“从某个种子输入生成多少额外测试用例”的算法。以 AFLFast 提供的六种策略为基准，给出简明对比和使用建议。\n参考：https://github.com/lhxdz/afl-mix?tab=readme-ov-file\nps：冷热程度指有多少其他输入已经跑过同一条路径\nAFL 标志 策略名称 能量公式 核心思想 简言之 -p fast（默认） FAST 指数放大低频路径能量，快速收敛 偏袒“冷门”路径，给的测试用例更多；热门路径反之 -p coe COE (cut-off exponential) 高频路径直接“断电”，资源全给罕见路径 检测到某路径太热门（超过平均值）就直接断电（0 个新用例），冷门路径才继续深究 -p explore EXPLORE 线性均衡，与路径频率无关 一视同仁，每个种子按 AFL 原始评分给能量，不看冷热。 -p quad QUAD 二次曲线惩罚高频路径 冷门路径奖励得更快（二次曲线），热门路径被二次方打压。 -p lin LIN 线性惩罚高频路径 冷门路径奖励、热门路径惩罚都按线性比例，节奏比较温柔。 -p exploit EXPLOIT (原生 AFL) 恒定能量，仅依赖 AFL 原始性能分 只按“跑得快不快、覆盖新不新”给能量，完全不考虑路径冷热。 符号释义\nα(i)：AFL 原生性能评分（执行时间、块转移覆盖率等） β：全局常数，防止能量爆炸 s(i)：种子 i 被 fuzz 的次数 f(i)：触发与 i 相同路径的输入总量 μ：所有路径的平均输入数 快速实践指南\n单机 fuzz：保持默认 -p fast 即可。 并行集群： master 用 -p exploit 稳定产生种子； slaves 组合 -p coe / -p fast / -p explore 以覆盖低频路径。 若使用 AFL++，可直接在命令行追加对应 -p 参数，无需额外补丁。 AFLGo\r与追求广覆盖的 AFL/AFLFast 不同，AFLGo 专为**定向灰盒模糊测试（DGF）设计，其能量分配核心在于“越靠近目标代码的种子，获得的 fuzz 轮次越多”。算法基于模拟退火（Simulated Annealing）**动态调节，公式与参数如下表所示。\nAFLGo 变量 定义/作用 d(s,T) 种子 s 到目标集合 T 的**平均基本块距离（**静态分析得出，越小越近） d̃(s,T) 归一化距离：d̃ = d / d_max ∈ [0,1]，0 表示最近，1 表示最远 T_exp 退火温度：T_exp = 20^(−t/tₓ)，t 为已用时间，tₓ 为“利用阶段”起始参数 p_afl(s) AFL 原生能量（由执行速度、路径稀有度决定） p(s,T) 退火比例因子：p = (1−d̃)·(1−T_exp) + 0.5·T_exp E(s,T) 最终能量：E = p_afl(s) · 2^(2 log₂(MAX)·(p−0.5))，MAX≈30 根据格式可以得到能量分配规则\n在时间较小时，温度影响较大，而距离影响较小 随着时间推移，T_exp 递减，距离影响较大 因此系统从“全局探索”逐步过渡到“局部深究”。 快速实践\n编译：afl-clang-fast + -targets= 生成含距离信息的二进制。 运行：afl-fuzz 追加 -z targets.txt 即启用 AFLGo；无需额外 -p 参数。 并行：官方脚本自动为各实例划分不同目标区间，避免能量冲突。 Beacon\rBeacon 是面向“混合符号执行引导的定向模糊测试”工具，核心目标是在最短 CPU 时间内到达用户指定的目标地址/断言。其能量分配策略以距离-稀缺联合权重（Distance-Scarcity Weight, DSW）为核心，同时引入梯度冷却（Gradient Cooling）机制抑制过度消耗。\n关键公式与参数如下表所示。\nBeacon 符号 定义/作用 d(s,t) 种子 s 到目标 t 的动态最短路径距离（插桩实时计算，单位：基本块数） r(s) 稀缺度：r(s)=1/(hit(s)+ε)，hit(s) 为触发该种子路径的输入次数 α 距离权重系数，默认 0.7（用户可通过 --alpha 调整） β 稀缺权重系数，默认 0.3（满足 α+β=1） w(s,t) 联合权重：w(s,t)=α·d̃(s,t)⁻¹+β·r(s)；d̃ 为归一化距离 T(k) 梯度冷却温度：T(k)=w_max·e^(−k/k₀)，k 为当前轮次，k₀ 为冷却常数 E(s,t) 最终能量：E(s,t)=E₀·w(s,t)/T(k)，E₀ 为基准能量（默认 1000） 能量分配规则总结\n越靠近目标（d 越小）且越罕见（r 越大）的种子，联合权重 w 越高； 随着 fuzz 轮次 k 增加，温度 T(k) 指数下降 → 高权重种子能量被进一步放大； 当 T(k) 接近 0 时，能量几乎只流向离目标最近的稀缺路径。 快速实践\n编译：clang-beacon -targets=targets.txt 生成带距离插桩的二进制。 运行：./beacon-fuzz -i in -o out -t targets.txt [可选 --alpha=0.6]。 并行：官方脚本 beacon-parallel.py 自动为各实例分配不同 k₀ 值，避免冷却同步。 WindRanger\rWindRanger 是面向多目标定向灰盒模糊测试（DGF）的工具，其核心创新在于“多级优先级队列 + 距离驱动能量分配”机制，可在一次 fuzzing 会话中同时逼近多个目标（偏差基本块 DBB），并确保测试资源向最易触发新路径的种子快速收敛。关键公式与参数如下表所示。\nWindRanger 符号 定义 / 作用 DBB Deviation Basic Block：待覆盖的目标基本块 d(s, DBB) 种子 s 到目标 DBB 的静态最短路径距离（单位：基本块数） L(s, DBB) 为每个 DBB 维护的种子列表，按 d(s, DBB) 升序排序 Q₁ 一级优先级队列：每个 DBB 对应列表头部种子（距离最近） Q₂ 二级优先级队列：同一 DBB 列表中剩余种子 E(s) 种子实时能量：E(s) = E₀ · (1 / (d(s, DBB)+ε))，ε 防止除零 T_select 队列选择策略：先耗尽 Q₁ 再取 Q₂，确保最近种子优先突变 能量分配规则总结\n距离越短 -\u0026gt; 排序越靠前 -\u0026gt; 进入 Q₁ -\u0026gt; 获得高能量 E(s)； 距离越远 -\u0026gt;落入 Q₂ -\u0026gt; 能量随 d 线性衰减，甚至长期不被选中； 每轮 fuzz 只从当前最高优先级队列取种子，形成“探索→利用”过渡。 快速实践\n编译：clang-windranger -targets=targets.txt 生成带 DBB 距离的二进制。 运行：./windranger-fuzz -i in -o out -t targets.txt 并行：官方脚本自动为不同 DBB 建立独立队列，避免队列间饥饿。 DAFL\rDAFL（Data-dependency Aware Fuzzing with Lightweight slicing）是以数据依赖为核心的定向灰盒模糊测试工具。其能量分配机制在传统 AFL 能量公式基础上，引入语义相关性评分（semantic-relevance score）进行比例再缩放，使 fuzz 资源优先流向与漏洞触发点数据依赖更紧密的种子。\n关键公式与参数如下表所示。\nDAFL 符号 定义 / 作用 scr_s 种子 s 的语义相关性评分（由静态数据依赖切片计算得出，越大越相关） scr_avg 当前种子池内所有种子的平均语义相关性评分 E_AFL(s) AFL 原生能量（基于执行速度、路径稀有度等 AFL 传统因子） E_DAFL(s) DAFL 调整后能量：E_DAFL(s) = (scr_s / scr_avg) × E_AFL(s) ε 极小常数，避免除零 种子池排序 每轮按 scr_s 降序重排，循环队列指针不重置，防止饥饿 能量分配规则总结\n数据依赖越紧密（scr_s 越高）的种子，获得 E_DAFL(s) 线性放大； 依赖关系稀疏（scr_s 低）的种子，能量被等比例压缩； 每轮重新排序队列保证高相关性种子始终优先，且不会产生饥饿。 快速实践\n编译：afl-clang-dafl -targets=targets.txt 生成带数据依赖插桩的二进制。 运行：./dafl-fuzz -i in -o out -t targets.txt（无需额外 -p 参数）。 并行：官方脚本 dafl-parallel.py 为不同目标 DBB 维护独立 scr_avg，避免跨目标干扰。 已知效果\n与 AFLGo 相比，基于数据依赖的能量分配平均提速 1.27×； 与原生 AFL 相比，DAFL 平均复现时间缩短 1.93×，并解决 AFL 无法触达的 4 个超时案例。 DAFL实验消融/对比配置\r配置名称 数据依赖切片 语义相关评分 scr_s 能量公式 种子池策略 适用场景 / 研究目的 DAFL_noasan 是 是 E = (scr_s/scr_avg)·E_AFL 动态重排 评估 ASan 运行时开销对能量分配的影响 DAFL_naive 否 否（直接scr_s=1） E = E_AFL 动态重排 退化为传统 AFL，验证切片+评分带来的增益 DAFL_selIns 是 是 E = (scr_s/scr_avg)·E_AFL 动态重排 仅插桩数据依赖相关的指令，评估插桩开销与精度权衡 DAFL_semRel 否 是 E = (scr_s/scr_avg)·E_AFL 动态重排 关闭切片，验证语义评分单独贡献 DAFL_seedpool 是 是 E = (scr_s/scr_avg)·E_AFL 固定大小（1000） 评估动态种子池策略对覆盖率的影响 DAFL_energy 否 是 仅能量公式有效，不重新排序 无重排 验证排序机制与能量放大机制的独立贡献 使用示例\n1 2 3 4 5 6 7 8 9 10 11 # 完整 DAFL CC=afl-clang-dafl make ./dafl-fuzz -i in -o out -t targets.txt # 关闭 ASan AFL_NO_ASAN=1 CC=afl-clang-dafl make ./dafl-fuzz -i in -o out -t targets.txt # 退化为 AFL（naive） AFL_DAFL_NAIVE=1 CC=afl-clang-dafl make ./dafl-fuzz -i in -o out -t targets.txt ","date":"2025-10-14T14:47:25Z","image":"http://localhost:1313/images/RiverInTrees.png","permalink":"http://localhost:1313/p/dgf-tool-energy-allocation-strategies/","title":"DGF Tool Energy Allocation Strategies"},{"content":"QuickFuzz\rFuzz入门，学习参考：Baby Fuzz · Home，BV1ZM4m1R7gZ\n模糊测试理论与工具实践\r总览\r模糊测试又称为fuzzing，是一种软件测试技术。其核心概念为自动产生随机输入到一个程序中，并监视程序异常，如崩溃、断言失败，以发现可能的程序错误。\n举例\r测试.c:\n1 2 3 4 5 6 7 8 9 10 11 12 // gcc -o test test.c #include \u0026lt;unistd.h\u0026gt; int main() { char input[8] = {0}; read(STDIN_FILENO, input, 8); if (input[0] == \u0026#39;A\u0026#39; \u0026amp;\u0026amp; input[1] == \u0026#39;B\u0026#39;) // (1) *((unsigned int *)0) = 0xdeadbeef; // (2)，将空指针赋值为0xdeadbeef，引发程序崩溃 write(STDOUT_FILENO, input, 8); return 0; } 模糊器.py：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import subprocess target = \u0026#39;./test\u0026#39; inps = [\u0026#39;AA\u0026#39;, \u0026#39;BB\u0026#39;, \u0026#39;BA\u0026#39;, \u0026#39;AB\u0026#39;] for inp in inps: // 不断测试哪些输入会引发程序崩溃 try: subprocess.run([target], input=inp.encode(), capture_output=True, check=True) except subprocess.CalledProcessError: # (1) print(f\u0026#34;bug found with input: \u0026#39;{inp}\u0026#39;\u0026#34;) # (output) # bug found with input: \u0026#39;AB\u0026#39; 内部架构\r在执行时会因为不同的条件执行不同的程序码，而不同的条件主要if就是定义\n1 2 3 4 if (a == 1 \u0026amp;\u0026amp; b == 2) puts(\u0026#34;condition 1\u0026#34;); else puts(\u0026#34;condition 2\u0026#34;); IDA pro生产出来的指令级别的控制流图(CFG)\nfuzzing流程大致可以拆成三个组件分别为：\n1.种子选择、2.突变、3.覆盖范围。\n举例：\n测试.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // gcc -o test test.c #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main() { char input[8] = {0}; read(STDIN_FILENO, input, 8); if (input[0] == \u0026#39;A\u0026#39;) { puts(\u0026#34;AAA\u0026#34;); if (input[1] == \u0026#39;B\u0026#39;) { puts(\u0026#34;BBB\u0026#34;); if (input[2] == \u0026#39;C\u0026#39;) { *((unsigned int *)0) = 0xdeadbeef; // bug } } } return 0; } 测试器.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import subprocess import random target = \u0026#39;./test\u0026#39; inps = [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;] # 语料库 count = 1 while True: inp = inps[0] # 种子选择演算法比较简单，使用最新的的种子作为下一个输入 inp += random.choice([\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;]) # 变异演算会挑选出来的种子加上一个随机字元作为最终的输入。 del inps[0] #加一个删一个，保证下次取的是下一个 count += 1 #记录处理了多少个输入 try: comp = subprocess.run([target], input=inp.encode(), capture_output=True, check=True) if comp.stdout != b\u0026#39;\u0026#39;: inps.append(inp) # 如果有输出的话则代表此输入为有趣 except subprocess.CalledProcessError: print(f\u0026#34;bug found with input: \u0026#39;{inp}\u0026#39;\u0026#34;) break if count % 100 == 0 or len(inps) == 0: # 定期打乱语料库,避免变异效果不好导致输入无法取得新的覆盖范围 inps = [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;] 模糊器的好坏，通常是：\n种子选择是否能挑出真正有意义的种子 变异的随机是否有效率 覆盖实现的方式是否会造成大量的开销。 AFL(American Fuzz Loop)\r– 简介 \u0026amp; 安装\n以下是一些比较有名的开源模糊测试工具：\nAmerican Fuzzy Lop (AFL): AFL 是一个高效的模糊测试工具 libFuzzer: libFuzzer 是 LLVM/Clang 提供的一个模糊测试引擎，它可以轻松地集成到现有的代码中 Syzkaller: Syzkaller 是一个专注于系统调用接口的模糊测试工具，它可以自动生成各种系统调用序列，并对内核进行测试以发现漏洞和错误。 OSS-Fuzz: OSS-Fuzz旨在通过自动化模糊测试发现开源软件中的安全漏洞和错误。 Fuzz方式\rAFL有两种fuzz途径：\n开源软件：AFL软件进行编译的同时进行插桩，以方便fuzz 闭源软件：配合QEMU直接对闭源的二进制代码进行fuzz 环境搭建\r安装\rLinux包管理(deb)：\n1 $ sudo apt install afl++ 源码编译安装 ：\n下载源码自行编译：(推荐安装AFL++，AFl的话如果开ASAN可能有问题)\n1 2 3 4 $ git clone https://github.com/AFLplusplus/AFLplusplus.git $ cd AFLplusplus $ make $ sudo make install AFL(American Fuzz Loop)\r插桩（instrumentation）\r在保证原程序逻辑的完整性下，在程序中插入一些程序码来采集运行期间的执行状态。\n1 2 3 4 5 6 7 8 9 int test_var = 0; // original (1) void b() { ...; } void a() { ...; } // instrumented (2) void b() { printf(\u0026#34;test_var: %d\\n\u0026#34;, test_var); ...; } void a() { printf(\u0026#34;test_var: %d\\n\u0026#34;, test_var); ...; } 特点：\r插桩的对象通常都具有相同的属性或类别涉及所有的功能、所有的基本块，比较少针对单一目标。 插桩的程序代码通常只有几行汇编代码，并且不会做太复杂的操作 在模糊器中，插桩被用来进行覆盖，那么记录多少程序码被执行到。 举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int had_exec[100] = {0}; void a() { had_exec[0] = 1; // (1) // ... } void b() { had_exec[1] = 1; ...; } void c() { had_exec[2] = 1; ...; } int main() { // ... if (had_exec[0]) // (2) puts(\u0026#34;function a had been called\u0026#34;); } Demo\r演示\n测试程序test.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { int a, idx; char buf[100]; scanf(\u0026#34;%d\u0026#34;, \u0026amp;idx); buf[idx] = \u0026#39;\\0\u0026#39;; read(0, \u0026amp;a, 0x2); if (a == 0xdead) *(int *)0 = 0xdeadbeef; return 0; } afl-gcc\r1 2 $ export AFL_USE_ASAN=1 $ afl-gcc -fsanitize=address -o test test.c 最后会我们的命令会变成这样 gcc选用afl的汇编器来编译\n1 $ gcc -fsanitize=address -o test test.c -B ~/fuzz/AFLplusplus -g -O3 -funroll-loops -D__AFL_COMPILER=1 -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1 有趣的是-B ~/fuzz/AFL，gcc 会尝试在这里寻找路径工具链中的汇编器来执行 1 2 $ ls -al ~/fuzz/AFLplusplus/as $ lrwxrwxrwx 1 lidaxian lidaxian 6 Mar 29 14:53 as -\u0026gt; afl-as afl-as\rafl-as首先会执行函数add_instrumentation()做插桩（对汇编代码），最后执行as做汇编（编译成机械代码）。所以插桩是在编译之后汇编之前。 做完插桩后会执行调整后的参数来汇编新的asm文件，最后产生的执行文件test即是有插桩的版本，简单用objdump就可以看到许多以__afl为前缀的函数(说明已完成插桩)： 1 2 3 4 5 $ objdump -M intel -d test | grep afl 119d: e8 1e 02 00 00 call 13c0 \u0026lt;__afl_maybe_log\u0026gt; 120d: e8 ae 01 00 00 call 13c0 \u0026lt;__afl_maybe_log\u0026gt; 1255: e8 66 01 00 00 call 13c0 \u0026lt;__afl_maybe_log\u0026gt; 12a1: e8 1a 01 00 00 call 13c0 \u0026lt;__afl_maybe_log\u0026gt; afl-fuzz\r1 afl-fuzz -i seed-dir -o out-dir -m none ./test -i - 存放测试用例的资料夹 -o - 搁置执行结果资料夹 -f - 从指定文件读取输入 -t - timeout，执行时间超过的话就会被kill掉 -m - 内存限制，执行时所能使用的内存体上限 -d - 跳过确定性，突变阶段跳过最初的处理 -n - 对没有插桩的目标进行模糊测试 tips：\n运行后遇到一些问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 demian@Friday:~/C_lab/fuzz$ afl-fuzz -i seed-dir -o out-dir -m none ./test~ afl-fuzz++4.09c based on afl by Michal Zalewski and a large online community [+] AFL++ is maintained by Marc \u0026#34;van Hauser\u0026#34; Heuse, Dominik Maier, Andrea Fioraldi and Heiko \u0026#34;hexcoder\u0026#34; Eißfeldt [+] AFL++ is open source, get it at https://github.com/AFLplusplus/AFLplusplus [+] NOTE: AFL++ \u0026gt;= v3 has changed defaults and behaviours - see README.md [+] No -M/-S set, autoconfiguring for \u0026#34;-S default\u0026#34; [*] Getting to work... [+] Using exponential power schedule (FAST) [+] Enabled testcache with 50 MB [+] Generating fuzz data with a length of min=1 max=1048576 [*] Checking core_pattern... [-] Hmm, your system is configured to send core dump notifications to an external utility. This will cause issues: there will be an extended delay between stumbling upon a crash and having this information relayed to the fuzzer via the standard waitpid() API. If you\u0026#39;re just testing, set \u0026#39;AFL_I_DONT_CARE_ABOUT_MISSING_CRASHES=1\u0026#39;. To avoid having crashes misinterpreted as timeouts, please log in as root and temporarily modify /proc/sys/kernel/core_pattern, like so: echo core \u0026gt;/proc/sys/kernel/core_pattern [-] PROGRAM ABORT : Pipe at the beginning of \u0026#39;core_pattern\u0026#39; Location : check_crash_handling(), src/afl-fuzz-init.c:2361 从错误信息来看，系统配置了外部工具来处理核心转储（core dump），这会导致 AFL++ 无法正确处理崩溃信息。\n所以我们要修改系统的 core_pattern 配置。\n首先，运行以下命令查看当前的 core_pattern 配置：\n1 cat /proc/sys/kernel/core_pattern 输出类似于 |/usr/lib/systemd/systemd-coredump %p %u %g %s %t %c %h，说明系统配置了外部工具来处理核心转储。\n然后以 root 用户身份运行以下命令，将 core_pattern 修改为 core：\n1 echo core | sudo tee /proc/sys/kernel/core_pattern 再次查看 core_pattern 配置，确认修改成功：\n1 cat /proc/sys/kernel/core_pattern 如果输出为 core，说明修改成功。\n接下来就可以重新运行 AFL-fuzz。\n1 afl-fuzz -i seed-dir -o out-dir -m none ./test 在创建了相关目录和种子文件后，命令运行成功就能在终端看见如下结果了：\nCrash分析\rout-dir/crashes目录下的内容是引发崩溃的输入。\nSanitizer\r即使程序存在漏洞，也不一定会在执行到有漏洞的程式码时触发异常\n举例：\n1 2 3 char buf[100]; scanf(\u0026#34;%d\u0026#34;, \u0026amp;idx); buf[idx] = \u0026#39;\\0\u0026#39;; // (1) 然而即便会有out-of-bound write 的漏洞发生，但如果buf[101]对应到的地址正好没被使用到，那么fuzzer也不会感兴趣。\n所以我们需要“Sanitizer”来辅助检测程序问题，它是一种用于检测程序中各种错误（如内存错误、数据竞争等）的工具。它通常集成在编译器中，可以在程序运行时检测问题。\n能辅助检测，但是有额外性能和时间需求。\n常见的Sanitizer有：\nAddressSanitizer (+LeakSanitizer) ThreadSanitizer UndefinedBehaviorSanitizer MemorySanitizer AddressSanitizer原理简介\r这个内存检查是如何工作的？\n左侧，蓝色区域是我们分配的内存在右侧\n右侧，Redzones是中毒的内存，访问即报错。\n如果通过启用Address Sanitizer来编译可执行文件，则每次访问内存之前，都会有前缀指令来检查该内存是否为poisoned.如果是，Address Sanitizer 将生成如上所示的诊断报告。\n下图显示该进程正在尝试访问中毒内存，并触发Crash并生成诊断报告。\n堆对象分配\rAddress Sanitizer通过使用它自己的分配实现来替换默认的 Malloc 实现，该实现将对象彼此分开，中间插入有毒内存。\n堆栈变量\r在两个堆栈变量之间插入一些红色区域，因此堆栈红色区域在运行时中毒。\n额外的开销\rCPU 减速通常在 2 倍到 5 倍之间 正常情况下，CPU 速度减慢 2 倍至 3 倍。在某些极端情况下，他们的速度下降了 5 倍。 内存开销 2x–3x AddressSanitizer 使用比本机运行更多的实际内存。确切的开销取决于分配大小。分配越小，开销就越大。 AddressSanitizer 使用更多的堆栈内存。我们看到增长高达 3 倍。 实战演示-libpng\r0x0.编译fuzz目标\rlibpng是开源的png解析库\n1 2 3 4 5 6 $ wget https://nchc.dl.sourceforge.net/project/libpng/libpng16/1.6.36/libpng-1.6.36.tar.xz $ tar xvf libpng-1.6.36.tar.xz $ cd libpng-1.6.36 $ ./autogen.sh $ CC=afl-clang CXX=afl-g++ ./configure --enable-static $ make -j4 --enable-static ： 用于生成静态库，fuzz开源库时会需要\n0x1.准备环境(准备种子)\r获取官网提供的测试集作为输入\n1 2 3 4 $ mkdir fuzz_in fuzz_out $ cd fuzz_in $ wget http://lcamtuf.coredump.cx/afl/demo/afl_testcases.tgz $ tar xvf afl_testcases.tgz 0x2.开始fuzz#\r1 $ afl-fuzz -i ../fuzz_in/png/full/images -o ../fuzz_out ../.libs/pngimage @@ ../fuzz_in/png/full/images为afl测试集\n../.libs/pngimage是编译出来的被测试程序\n@@代表测试输入样本\n0x3.报错处理(如果安装在系统上时)\rAFL测试时用到功能需要还没有开启\n1 2 3 4 sudo su echo core \u0026gt;/proc/sys/kernel/core_pattern cd /sys/devices/system/cpu echo performance | tee cpu*/cpufreq/scaling_governor 总结\r使用AFL在linux上fuzz开源软件十分简单 大多数的lib/开源软件的源代码都是可以获取的 在编译时插桩是可行的 在Fuzz时要用ASAN,MSAN,UBSAN 有时最需要花费时间的过程是项目编译 缺失引用的第三方库（lib） 编译过程中的各种错误 不同项目不同的编译方法与各种选项 ","date":"2025-10-14T14:40:02Z","image":"http://localhost:1313/images/greenland.png","permalink":"http://localhost:1313/p/quick_fuzz/","title":"Quick_fuzz"},{"content":"DGF Overview\r定向灰盒测试相关技术 核心策略 时间顺序梳理 速览\nAFL(American Fuzzy Lop 2014)\r传统灰盒：全图覆盖，无定向\n变异策略\n确定性：bit/byte flip（翻转）、整数加减、边界值、字典 随机叠加（Havoc）：纯随机组合多种变异操作（如插入、删除、替换） 拼接（Splicing）：将两个种子拼接后执行 havoc 变异 反馈引导策略\n边覆盖率（Edge Coverage）：插桩追踪 CFG 边的命中情况，作为变异方向的反馈 上下文敏感边覆盖：区分同一 CFG 边在不同调用上下文下的命中情况，提升精度 路径覆盖（PathAFL）：记录完整路径哈希，避免路径碰撞 Ngram 插桩：记录最近前 N 个分支的历史状态 AFLGo （2017）\r首次提出“定向”概念，距离制导。（DGF 的起点）\nAFL（基于覆盖率引导）-\u0026gt;AFLGo（定向制导）\n距离度量（Distance Metric）\n静态阶段\n用 LLVM 生成调用图 CG + 过程间控制流图 ICFG。 对每个基本块到目标块跑 Dijkstra，算出最短路径长度 distance(b)。 一个种子到目标的距离取它所有覆盖块距离的 加权平均。 距离越小，优先级越高；距离为 0 表示已命中目标。 多目标扩展：若同时定向 N 个目标，可维护 最小距离 或 平均距离 两种模式（-m 选项）。\n能量调度（Power Schedule）\nAFLGo 把 AFL 的 perf_score 公式改造成 Simulated Annealing (SA) 形式，解决“过早收敛”与“局部最优”。\n1 2 3 double T = 1.0 / pow(20.0, progress_to_tx); // 温度随时间衰减 double p = (1.0 - normalized_d) * (1.0 - T) + 0.5*T; // 距离+时间双因子 perf_score *= pow(2.0, 2*log2(MAX_FACTOR)*(p-0.5)); 总结一下 模拟退火 ：早期系统鼓励探索，距离较远也给予能量（算力）；后期系统愈发挑剔，只给近距离种子变异机会。\n种子队列管理\n主队列（AFL ）：按覆盖率排队。 优先队列（AFLGo 新增）：按距离排序；每次 fuzz 80% 概率从优先队列取种子。 变异策略\n确定性阶段（固定套路） 与 AFL 相同（bit/byte flip, arith, interest, dictionary）。 距离度量不会缩短确定性阶段，只是 打分，保证兼容性。 Havoc / Splicing 距离越小的种子 获得的 havoc 轮次越多（由 power_factor 决定）。 对“已到达目标”的种子，AFLGo 会额外给 二次变异 机会，以探索目标附近的新分支（patch 回归测试常用）。 WindRanger（ICSE 2022）\r核心是用“走错路口”指路：Deviation Basic Block（DBB）。\nDBB 机制\n静态找“一步错即永远到不了目标”的块 动态过滤：仅保留种子真实触发者（它在执行时真的走错的路口） 距离\n仅累加 DBB 到目标的最短路径 × 难度系数（该系数青睐简单分支） 调度\nFavored 队列（90 %）：按 DBB 距离排序 Less-favored 队列（10 %）：保留全局探索 Beacon（IEEE S\u0026amp;P 2022）\r核心是 运行时剪枝：Weakest Precondition。\n核心\n静态：推导 最小充分条件 WP，插入 assert(WP) 动态：断言失败立即退出路径 代价\n复杂循环下 WP 爆炸，静态耗时显著 注意：与 DAFL 的“非侵入”不同，Beacon会 修改被测程序 本体。\n参考资料\rBöhme, M., Pham, V.-T., Nguyen, M.-D., and Roychoudhury, A. 2017. Directed Greybox Fuzzing. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS ’17). ACM, New York, NY, USA, 2329–2344. https://doi.org/10.1145/3133956.3134020 Du, Z., Li, Y., Liu, Y., and Mao, B. 2022. Windranger: A Directed Greybox Fuzzer Driven by Deviation Basic Blocks. In Proceedings of the 44th International Conference on Software Engineering (ICSE ’22). ACM, New York, NY, USA, 2440–2451. https://doi.org/10.1145/3510003.3510197 Huang, H., Guo, Y., Shi, Q., Yao, P., Wu, R., and Zhang, C. 2022. Beacon: Directed Grey-box Fuzzing with Provable Path Pruning. In Proceedings of the 2022 IEEE Symposium on Security and Privacy (SP ’22). IEEE, 36–50. https://doi.org/10.1109/SP46214.2022.9833709 Zalewski, M. 2018. American Fuzzy Lop (AFL). GitHub repository, https://github.com/google/AFL ","date":"2025-10-13T23:51:05Z","image":"http://localhost:1313/images/EarlyMorningForest.png","permalink":"http://localhost:1313/p/dgf-overview/","title":"DGF Overview"},{"content":"Docker命令\rDocker 镜像构建\rdocker build命令是 Docker 引擎的核心命令之一，用于根据 Dockerfile中的指令自动构建 Docker 镜像。\n核心概念与基础语法\r构建上下文：这是 docker build命令中指定的路径（通常是当前目录 .）。Docker 客户端会将这个路径下的所有文件（递归地）打包发送给 Docker 守护进程，因此只有上下文中的文件才能被 Dockerfile中的 COPY或 ADD指令使用。为了提高效率，建议使用空目录作为上下文，或通过 .dockerignore文件排除不必要的文件 Dockerfile：这是一个文本文件，包含了一系列用于构建镜像的指令（如 FROM, RUN, COPY等）。docker build会逐条执行这些指令，每条指令都会创建一个新的镜像层。 基本语法：\n1 docker build [OPTIONS] PATH | URL | - 其中 PATH就是构建上下文的路径。\n常用选项详解\r选项 说明与示例 适用场景 -t/ --tag 为构建出的镜像命名和打标签。格式为 name:tag。示例：docker build -t myapp:latest -t myapp:v1.0 . 镜像版本管理。 -f/ --file 指定要使用的 Dockerfile路径（当 Dockerfile不在上下文根目录或名称非默认时）。示例：docker build -f ./docker/Dockerfile.prod . 项目中有多个不同用途的 Dockerfile。 --build-arg 设置构建时的变量，这些变量可以在 Dockerfile中通过 ARG指令引用。示例：docker build --build-arg NODE_ENV=production . 动态传入构建参数，如版本号、环境变量。 --no-cache 强制忽略之前构建的缓存，执行全新构建。示例：docker build --no-cache . 确保依赖获取最新版本或解决缓存导致的构建问题。 --target 在多阶段构建的 Dockerfile中，只构建到指定的目标阶段。示例：docker build --target builder . 仅构建用于编译的中间阶段，以缩小最终镜像体积。 -q/ --quiet 安静模式，构建成功后只输出最终的镜像ID。 适用于自动化脚本，减少输出信息。 工作原理与流程\r发送上下文：Docker 客户端将整个构建上下文目录打包发送给 Docker 守护进程。因此，避免使用根目录 /作为上下文，以免发送大量无用数据。 逐行执行：守护进程逐条解析并执行 Dockerfile中的指令。 层缓存机制：每条指令都会生成一个只读的镜像层。Docker 会缓存未改变的层，后续构建时直接使用缓存，从而大幅加速构建过程。控制台输出中的 CACHED标识即表示使用了缓存。 输出镜像：所有指令执行完毕后，生成最终的镜像。 示例\r1 2 3 4 # -t 指定镜像名称，标签默认是latest # . 代表上下文默认为当前目录 # 所以要保证dockerfile以及里面要copy和add的文件在当前目录下 docker build -t gpac_cve-2019-20162 . Docker 容器启动\r启动Docker容器有多种方式，具体取决于使用场景和需求。以下是常见的启动容器方法及详细说明：\n基本启动命令\r使用docker run命令创建并启动一个新容器：\n1 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] /bin/bash 常用选项 -d：后台运行（守护态）。 -it：交互式终端（如/bin/bash）。 --name：指定容器名称。 -rm：容器停止后自动删除容器。 -p：端口映射（格式：主机端口:容器端口）。一般容器有通信需求会用 -v：挂载数据卷。 --restart：设置重启策略（如always、unless-stopped）。 /bin/bash：交互式终端进入工作目录。 示例：\n1 2 3 4 5 6 7 # 后台启动Nginx并映射端口 docker run -d --name my-nginx -p 8080:80 nginx # 挂载目录映射到容器内/testspace目录下 # 并且运行后会进入交互式终端（工作目录下） docker run -it --rm --name gpac_cve-2019-20162 \\ -v /mnt/d/A.S.E/benchmark-project/gpac:/testspace \\ gpac_cve-2020-23267 /bin/bash 启动已停止的容器\r若容器已存在但处于停止状态，使用docker start：\n1 docker start \u0026lt;容器ID或名称\u0026gt; 可结合-a参数查看输出日志。 进入运行中的容器\rdocker exec（推荐）：\n在运行中的容器内启动新终端，退出时容器不会停止：\n1 docker exec -it \u0026lt;容器ID\u0026gt; /bin/bash docker attach： 直接进入容器的主进程终端，退出可能导致容器停止。\n使用Docker Compose启动多容器\r通过docker-compose.yml文件定义服务，一键启动：\n1 docker-compose up -d 适用场景：需编排多个关联容器（如Web+数据库）。 后台运行与资源限制\r后台运行：添加-d参数。 资源限制： 内存：-m 200M --memory-swap=300M。 CPU权重：--cpu-shares 512。 注意事项\r端口冲突：确保主机端口未被占用。 数据持久化：使用-v挂载重要数据，避免容器删除后丢失。 日志排查：启动失败时，通过docker logs \u0026lt;容器ID\u0026gt;查看错误。 Docker 容器/镜像重命名\r在Docker中，重命名容器可以通过以下命令和方法实现：\n使用docker rename命令\r这是最简便的方法，适用于运行中或已停止的容器：\n1 docker rename \u0026lt;旧容器名或ID\u0026gt; \u0026lt;新容器名\u0026gt; 示例：\n1 docker rename my_old_container my_new_container 注意：\n新名称必须唯一，不能与现有容器冲突。 操作不会影响容器内部进程或数据。 停止并重新创建容器\r若需保留原容器的配置，可先停止并删除原容器，再以新名称重新创建：\n1 2 3 docker stop old_container docker rm old_container docker run -d --name new_container [其他选项] \u0026lt;镜像名\u0026gt; 适用场景：需要调整其他参数（如端口、卷）时。 使用Docker Compose\r若容器由docker-compose.yml管理，直接修改文件中的服务名称并重启：\n1 2 3 services: new_name: # 修改此处 image: nginx 然后运行：\n1 docker-compose up -d 优势：适合多容器编排场景。 常见问题\r名称冲突：若新名称已存在，Docker会报错Conflict，需先删除或重名冲突容器。 验证结果：通过docker ps -a确认名称是否更新。 总结\n优先使用docker rename快速重命名；复杂需求（如配置变更）可结合停止重建或Compose调整。确保操作前后验证容器状态。\nDocker 容器提交为镜像\rdocker commit命令允许你直接将一个容器的当前状态（包括文件更改、已安装的软件、配置调整等）保存为一个新的 Docker 镜像。它就像给容器拍了一张快照，便于快速保存或分享特定工作状态。\n1 docker commit [OPTIONS] [容器名称] [镜像名称:tag] 选项 缩写 功能说明 示例 --author -a 指定新镜像的作者信息。 -a \u0026quot;张三 \u0026lt;zhang@example.com\u0026gt;\u0026quot; --message -m 添加提交信息，说明此次更改的内容。 -m \u0026quot;安装了Nginx服务器\u0026quot; --change -c 应用Dockerfile指令（如ENV, EXPOSE, CMD等）。 -c \u0026quot;EXPOSE 8080\u0026quot; --pause -p 提交时是否暂停容器以确保数据一致性（默认为true）。 --pause=false 适用情况：\n快速保存调试环境：当你在容器内进行复杂的配置或调试，并希望保存当前进度时，使用 docker commit可以快速创建一个镜像，下次可以直接从这一步开始，无需重头再来。 紧急热修复：生产环境中的容器出现问题需要立即修复时，你可以进入容器实施修复，然后通过 docker commit快速生成一个包含修复的临时镜像用于部署，为编写正式的 Dockerfile 争取时间。 创建自定义开发环境：基于一个标准镜像（如官方 Python 镜像）启动容器，安装团队所需的各种开发工具和依赖后，提交为一个标准的团队开发环境镜像，方便统一开发环境。 保存难以Dockerfile化的操作：有些交互式安装过程或图形界面软件的配置很难用 Dockerfile 指令完全自动化，这时可以通过交互操作后提交镜像来保存成果。 注意事项\n尽管 docker commit很方便，但也有一些重要的限制和需要注意的地方：\n可重复性差：通过 docker commit创建的镜像构建过程是黑盒的，缺乏像 Dockerfile 那样的声明性和可重复性。他人很难知晓镜像的准确构建步骤。所以在正式规范的团队开发里，还是尽量通过dockerfile来构建镜像。 容易导致镜像臃肿：交互式操作容易引入不必要的临时文件或缓存，如果未及时清理，会使镜像体积迅速膨胀。最佳实践：提交前，尽量清理缓存和临时文件（例如执行 apt-get clean）。 可能存在安全风险：无意中提交的镜像可能包含敏感信息，如密码、密钥等。最佳实践：提交前检查更改，使用 docker diff \u0026lt;容器名\u0026gt;查看文件系统差异，避免提交敏感数据。 不包含卷（Volume）中的数据：docker commit不会保存容器内挂载的卷中的数据。 最后一点补充说明一下，如果你想要保存容器内挂载的卷中的数据，可以用cp指令拷贝进容器内目录。\n1 2 cp [OPTIONS] [源目录] [目的目录] cp -r /testspace/gpac /workspace 前者为被复制的目录（或文件），后者为要复制到的目录 -r /-R：递归复制，用于复制目录和其中所有内容 -f：强制覆盖已存在的目标文件 -n：不覆盖已经存在的目录 Docker 打包镜像\rdocker save是一个非常有用的 Docker 命令，它能将你的 Docker 镜像打包成一个独立的归档文件（tar 格式），非常适合用于镜像的备份、迁移或在离线环境中分发。\n1 2 3 docker save -o [压缩包名称].tar [镜像名称]:[tag] docker save -o my_apps.tar app:v1.0 db:latest docker save redis:alpine \u0026gt; redis.tar -o：将指定标签的镜像保存为指定名称的 .tar文件 多个镜像打包：后面可以接好几个镜像一起打包 使用重定向：使用 Shell 重定向操作，效果与 -o相同 Docker 加载镜像\r1 2 3 docker load -i [压缩包名称].tar # 预计输出 Loaded image: [镜像名称]:[tag] 核心功能是：将 docker save导出的镜像包（如 nginx.tar）恢复至本地镜像库。\n加载过程会完整恢复镜像的所有层（Layers）、标签（Tag）、构建历史等元数据，保持镜像完整性。主要应用于离线环境部署、镜像备份恢复和批量镜像迁移。\n常见问题\n镜像标签为 \u0026lt;none\u0026gt;：有时加载后镜像名称和标签会显示为 \u0026lt;none\u0026gt;。这通常是因为 tar 文件本身未包含标签信息\n。解决方法很简单，使用 docker tag命令手动为其打上标签即可：\n1 2 3 4 5 # 先通过 docker images 查看镜像ID docker images # 然后为指定镜像ID打上标签 docker tag \u0026lt;镜像ID\u0026gt; nginx:latest [1,6](@ref) 加载失败排查：如果加载失败，可以先检查 tar 文件是否完整。可以使用 tar -tf nginx.tar命令查看压缩包内容列表。另外，也要确保 Docker 宿主机有足够的磁盘空间。\nDocker 镜像推送\r推送镜像是将你本地构建好的镜像上传到远程仓库（一般是dockerhub官网），以便他人或其他机器使用。\n登录仓库\n首先需要使用 docker login命令登录到目标镜像仓库（如 Docker Hub 或你的私有仓库）。\n1 2 3 docker login # 或者指定私有仓库地址 docker login myregistry.example.com 执行后会提示输入用户名和密码。如果使用私有仓库，地址需替换为你的仓库地址。\n标记镜像\n在推送之前，必须为本地镜像打上一个符合远程仓库命名规范的标签，格式通常为 [仓库地址]/[用户名或项目名]/[镜像名]:[标签]。当然如果本来就是规范命名就不用改。使用 docker tag命令：\n1 2 3 4 # 语法：docker tag 本地镜像名:标签 新标签 docker tag my-app:latest yourusername/my-app:v1.0 # 如果推送到私有仓库，地址可能如下 docker tag my-app:latest myregistry.example.com/yourproject/my-app:prod 执行推送\n使用 docker push命令将标记好的镜像推送到远程仓库。\n1 docker push yourusername/my-app:v1.0 推送成功后，就可以在远程仓库的页面上看到这个镜像了。\nDocker 拉取镜像\r拉取镜像是从远程仓库将镜像下载到本地环境的过程。\n基本拉取命令\n最基础的命令是 docker pull，后面跟上镜像的名称和标签（可选，默认为 latest）。\n1 2 3 4 5 6 # 拉取官方Nginx镜像的最新版本 docker pull nginx # 拉取指定标签的镜像 docker pull nginx:1.27.0-perl # 从私有仓库拉取 docker pull myregistry.example.com/yourproject/my-app:prod 验证拉取结果\n拉取完成后，使用 docker images命令可以查看本地已下载的镜像列表，确认镜像是否成功拉取。\nDocker镜像拉取失败解决方案\r如果docker镜像拉取失败，且报错为连接超时，无法连接，可以采取以下办法。\n1.排查DNS\n1 sudo nano /etc/resolv.conf 如果resolv.conf中没有8.8.8.8和8.8.4.4，就添上。\n1 2 nameserver 8.8.8.8 nameserver 8.8.4.4 改完后，ctrl+o保存，再enter确认，最后ctrl+x退出。\n此修改在系统重启时会重置，其实也可以永久修改，但是比较麻烦，要拉取的时候修改即可。\n2.修改拉取源\n1 sudo nano /etc/docker/daemon.json 添加国内镜像站：\n1 2 3 4 5 6 7 8 9 10 11 12 13 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://docker.m.daocloud.io\u0026#34;, \u0026#34;https://dockerproxy.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;https://docker.nju.edu.cn\u0026#34;, \u0026#34;https://iju9kaj2.mirror.aliyuncs.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://cr.console.aliyun.com\u0026#34;, \u0026#34;https://hub.docker.com\u0026#34;, \u0026#34;http://mirrors.ustc.edu.cn\u0026#34; ] } 改完后，ctrl+o保存，再enter确认，最后ctrl+x退出。\n3.重启docker服务\n1 2 3 4 # 重新load daemon.json sudo systemctl daemon-reload # 重启docker服务 sudo systemctl restart docker 这个时候再试试拉取，多半成功了。\n","date":"2025-10-06T21:56:04Z","image":"http://localhost:1313/images/TrippyWave.png","permalink":"http://localhost:1313/p/docker-commands/","title":"Docker Commands"},{"content":"Git使用教程\r安装\r官网下载安装即可，安装配置基本默认。\nhttps://git-scm.com\n常用命令\r命令 描述 git config --global user.name 用户名 设置用户签名 git config --global user.email 邮箱 设置用户签名 git init 初始化本地库 git status 查看本地库状态 git add 文件名 添加到暂存区 git commit -m \u0026quot;日志信息\u0026quot; 文件名 提交到本地库 git reflog / git log 查看历史记录 git reset --hard 版本号 版本穿梭 基本操作\r设置用户签名\r1 2 git config --global user.name user_name git config --global user.email user_email git config --global 命令的作用范围是针对 该设备上所有 Git 仓库 的全局配置。\n所以只要配置一次就好了。\n要查看当前的 Git 全局配置，可以使用以下命令：\n1 git config --global --list 查看特定配置项\n如果你只想查看某个特定的全局配置项，可以使用以下命令：\n1 git config --global [配置项名称] 例如：\n1 git config --global user.name 这将只显示全局配置中的用户名。\n初始化本地库\r1 git init 在对应项目文件夹目录下创建Git仓库。\n查看本地状态\r1 git status git status 命令用于显示当前 Git 仓库的状态。它会告诉你哪些文件被修改了、哪些文件被添加到暂存区（staging area）、哪些文件未被跟踪等信息。\n以下是 git status 可能显示的一些关键信息：\n当前分支： 显示你当前所在的分支名称。 本地更改： 未跟踪的文件：显示仓库中尚未添加到暂存区的新文件。 修改过的文件：显示自上次提交以来已被修改的文件。 暂存区更改： 已暂存的更改：显示已被添加到暂存区的文件，这些更改将在下一次提交时被包含。 已暂存但修改过的文件：显示已暂存但自暂存后又被修改的文件。 冲突： 如果你在合并或拉取时遇到冲突，git status 会显示这些冲突文件，提示你需要手动解决这些冲突。 分支状态： 如果你的分支与远程分支有差异，git status 会显示这些差异，例如本地分支领先、落后或与远程分支同步。 未暂存的更改： 显示自上次提交以来未被添加到暂存区的文件更改。 提示信息： 根据当前状态，git status 可能会提供一些有用的提示信息，例如如何添加文件到暂存区或如何提交更改。 添加到暂存区\r1 git add 文件名 git add 是一个 Git 命令，用于将更改添加到暂存区（staging area），这是提交（commit）更改到本地仓库之前的一个必备步骤。它允许你精确控制哪些更改应该包含在下一次提交中。\n暂存区是一个文件，保存了下次将提交到本地仓库的更改列表。\n添加单个文件：\n1 git add \u0026lt;文件名\u0026gt; 这会将指定文件的更改添加到暂存区。\n添加多个文件：\n1 git add \u0026lt;文件1\u0026gt; \u0026lt;文件2\u0026gt; ... 你可以一次性添加多个文件到暂存区。\n添加所有更改：\n1 git add . 或者\n1 git add -A 这会将所有新的、修改的和删除的文件（不包括未跟踪的文件）添加到暂存区。\n提交到本地库\rgit commit 用于将暂存区（staging area）的更改提交（commit）到本地仓库。提交是版本控制中保存项目历史记录的基本单元。\n1 git commit -m \u0026#34;提交信息\u0026#34; 这将提交暂存区的更改，并使用提供的提交信息。-m 选项允许你在命令行中直接添加提交信息，而不需要打开文本编辑器。\n查看历史记录\rgit reflog 和 git log 都是 Git 中用于查看项目历史记录的命令，但它们的用途和显示的信息有所不同。\ngit reflog\ngit reflog 命令显示了所有引用（包括分支和标签）的更新历史。它记录了HEAD和分支引用的每一次移动，无论这些移动是否由提交引起。\ngit reflog 可以显示由于各种操作（如提交、回退、创建分支、切换分支等）引起的引用变化。\n1 git reflog 这将显示一个按时间排序的列表，列出了HEAD和分支引用的每一次更新。\ngit log\ngit log 命令显示了提交历史，包括每次提交的作者、日期、提交信息等详细信息。它主要用于查看项目的提交历史。\n1 git log 这将显示项目的提交历史，包括每次提交的哈希值、作者、日期和提交信息。并且git log还支持多种格式：可以通过选项自定义输出格式，如简洁格式、一行列格式等，并且支持过滤：可以通过选项过滤特定的提交，如按作者、日期、路径等过滤。\n常用选项\n--oneline：以一行列格式显示提交信息，只显示哈希值和提交信息。\n查看简洁的提交历史：\n1 git log --oneline --graph：显示分支合并图。\n查看带有分支合并图的提交历史：\n1 git log --graph --oneline --since 和 --until：按时间过滤提交。\n--author：按作者过滤提交。\n--grep：搜索提交信息中的关键词。\n搜索特定作者的提交：\n1 git log --author=\u0026#34;用户名\u0026#34; 查看特定时间段内的提交：\n1 git log --since=\u0026#34;2024-01-01\u0026#34; --until=\u0026#34;2024-12-31\u0026#34; 版本穿梭\r1 git reset --hard 版本号 上述命令用于将当前分支和工作目录重置到指定的版本号，即某个特定的提交（commit）。这个命令会改变当前分支的 HEAD 指针，并且会重置工作目录和暂存区，使其与指定的提交完全一致。注意，这意味着所有在该提交之后所做的更改都将丢失，包括未提交的更改和暂存的更改，这是不可逆的。\n你需要找到你想要回退到的版本号，可以通过 git log 命令查看提交历史，找到对应的提交哈希值。\n分支操作\r分支的好处\n同时并进行多个功能开发，提高了开发效率 各个分支再开发过程中，如果某个分支开发失败，不会对其他分支有任何影响，失败的分支删除重新开始即可 分支常用命令\r命令 描述 git branch 分支名 创建分支 git branch -v 查看分支 git checkout 分支名 切换分支 git merge 需要合并的分支名 把指定的分支合并到当前分支上 查看分支\r1 2 git branch -v git branch git branch -v 命令用于列出 Git 仓库中的所有分支，并显示每个分支的最新提交信息。这个命令是 git branch 命令的一个变体，其中的 -v 选项代表“verbose”，即详细模式。\n创建分支\r1 git branch 分支名 git branch 分支名 是一个用于创建新分支的 Git 命令。当你想要从当前开发线（通常是主分支）创建一个新的开发线时，这个命令非常有用。\n这将在当前 HEAD 指向的提交处创建一个新分支，但不会自动切换到该分支。\n切换分支\r1 git checkpoint 分支名 这将切换到指定的分支，并更新工作目录以反映该分支的状态。\n合并分支\r1 git merge 需要合并的分支名 //把指定的分支合并到当前分支上 git merge 用于将一个分支的更改合并到当前分支。这通常用于合并功能分支到主分支（如 main 或 master），或者合并修复分支到开发分支。\n合并过程中的冲突\n在合并过程中，如果存在冲突（即两个分支对同一文件的同一部分进行了不同的更改），Git 会停止合并并让你手动解决这些冲突。你需要：\n手动解决冲突：打开冲突的文件，手动编辑以解决冲突。 标记冲突已解决：使用 git add 命令将解决冲突后的文件标记为已解决。 完成合并：使用 git commit 命令完成合并。 远程仓库的操作\r添加远程库地址\r1 git remote add origin 远程库地址 git remote add origin 远程库地址 用于将远程仓库添加到你的本地 Git 仓库中。当你创建一个新的本地仓库并希望将其与远程仓库（如 Gitee、GitHub、GitLab 等）关联时，这个命令非常有用。\n命令解释\ngit remote：这是用于管理远程仓库引用的命令。 add：这个子命令用于添加一个新的远程仓库引用。 origin：这是远程仓库的默认短名称。Git 使用 origin 作为远程仓库的默认名称，但你也可以使用其他名称。 远程库地址：这是远程仓库的 URL 地址。 验证远程仓库\n添加远程仓库后，你可以使用以下命令来查看所有远程仓库的 URL：\n1 git remote -v 这将列出所有远程仓库的名称和对应的 URL。\n修改远程仓库 URL\n如果你需要修改远程仓库的 URL（例如，从 HTTPS 更改为 SSH），你可以使用以下命令：\n1 git remote set-url origin 新的远程库地址 将 新的远程库地址 替换为你新的远程仓库 URL。\n删除远程仓库\n如果你不再需要某个远程仓库，你可以使用以下命令删除它：\n1 git remote remove origin 这将删除名为 origin 的远程仓库引用。\n拉取远程库文件\r1 git pull origin master 这个命令会从远程仓库的 master 分支拉取最新的更改，并尝试将这些更改合并到你当前所在的本地分支。(有时是用main分支)\n简言之就是从远程库拉取文件到工作区。\n上传远程库文件\r1 git add . //将所有改变添加到暂存区 上传前要执行git add 将更改添加到暂存区（staging area）。\n1 git commit -m \u0026#34;message\u0026#34; 再执行git commit 将暂存区（staging area）的更改提交（commit）到本地仓库。\n1 git push origin (master/分支的名字) 最后执行git push将本地库文件上传到远程库。\n1 git push -u origin 分支名 这条命令做了两件事：\n推送分支：将您的本地分支推送到远程仓库 origin。 设置上游分支：-u 参数将远程分支设置为本地分支的上游分支，这样您以后可以直接使用 git push 或 git pull 命令而不需要指定远程仓库和分支名。 ","date":"2025-02-21T20:58:54Z","image":"http://localhost:1313/images/PacificRim_02.PNG","permalink":"http://localhost:1313/p/quick-git/","title":"Quick Git"},{"content":"1 Java背景知识\r1.1 JDK JRE JVM\rJDK(开发工具包) JRE(运行环境)运行时类库 JVM(Java虚拟机) JDK:（Java Development Kit）\nJava标准开发包，它提供了编译、运行Java程序所需的各种工具和资源，包括Java编译器、Java运行时环境，以及常用的Java类库等。\nJRE:（Java Runtime Environment）\nJava运行环境，用于解释执行Java的字节码文件。\nJVM: (Java Virtual Machine)\nJava虚拟机，是JRE的一部分，负责解释执行字节码文件，是可运行Java字节码文件的虚拟计算机。\n区别联系：（问答题会考可能）\nJDK包含JRE，JDK和JRE中都包含JVM。JDK除了包含JRE还包含一些常用开发工具和基础类库。\nJDK用于开发，JRE用于运行Java程序。\nJVM是Java编程语言的核心并且具有平台独立性。\n1.2 开发Java程序需要的3个步骤：\r编写源文件 编译源文件生成字节码 加载运行字节码 1.3 Java程序运行过程:\r1 javac:\tjava源文件-\u0026gt;class字节码文件(0,1) 2 java: 运行class文件\n1.4 java程序语句执行的顺序\rjava程序语句执行的顺序包括4种基本控制结构：顺序结构、选择结构、循环结构、异常处理逻辑结构。 如果三个空（那就顺序 选择 循环）\n2 编程基础\r2.1 Java的基本语法\r\u0026ndash;方法格式\r1 2 3 4 权限修饰符 返回值声明 方法名称(参数列表){ 方法中封装的逻辑功能; return 返回值; } \u0026ndash;权限修饰符\r下表为Java访问控制符的含义和使用情况\n访问级别 类内部 本包 子类 外部包 public √ √ √ √ protected √ √ √ × default √ √ × × private √ × × × default也叫友好型\n\u0026ndash;注释\r// 单行注释 /* 多行注释 /\t/* 文档注释 */\n\u0026ndash;关键字\r关键字 含义 private 私有的 protected 受保护的 public 公共的 abstract 声明抽象 class 类 extends 继承、扩展 final 最终、不可改变 implements 实现 interface 接口 native 本地 new 新，创建 static 静态 strictfp 严格，精准 synchronized 线程、同步 transient 短暂 volatile 易失 程序控制语句 含义 break 跳出，中断 continue 继续 return 返回 do 运行 while 循环 if 如果 else 否则 for 循环 其它关键字 含义 instanceof 实例 switch 观察 case 返回观察里的结果 default 默认 try 捕获异常 catch 处理异常 throw 抛出一个异常对象 throws 声明一个异常可能被抛出 import 引入 package 包 boolean 布尔型 byte 字节型 char 字符型 double 双精度 float 浮点 int 整型 long 长整型 short 短整型 null 空 TRUE 真 FALSE 假 super 父类，超类 this 本类 void 无返回值 goto 跳转 const 静态 native 本地 \u0026ndash;标识符\r(你自己定义的一个东西的名字(比如类名，方法名，变量名，接口名，常量名\u0026hellip;))\n\u0026ndash;注意事项定义的时候:\n示识符:\n由字母、数字、下划线(_)和美元符号($)组成。\n不能以数字开头。\n不能是Java中的关键字。\n2.2 变量 常量\r\u0026ndash;变量的定义\r按所属的数据类型划分：\n基本数据类型变量 引用数据类型变量 按被声明的位置划分：\n局部变量：方法或语句块内部定义的变量\n成员变量：方法外部、类的内部定义的变量\n基本数据类型\n类型 名称 含义 bit 字节数 值范围 整型 byte 字节 8 1字节 -128 到 127 整型 short 短整型 16 2字节 -32768 到 32767 整型 int 整型 32 4字节 -2,147,483,648 到 2,147,483,647 整型 long 长整型 64 8字节 -9223372036854775808 到 922337203685477580 浮点型 float 浮点数 32 4字节 有效位数15位 浮点型 double 双精度浮点数 64 8字节 有效位数15位 字符 char 字符 16 2字节 Unicode字符集 布尔型 boolean 布尔型 1 true/false 布尔型（boolean）的字节数在Java中并不是精确定义的，它是一个特殊的类型，用于表示真（true）或假（false）。在Java虚拟机（JVM）中，boolean的存储可能与其他基本类型不同，且其大小可能依赖于JVM的实现。在实际应用中，boolean通常用于逻辑判断，而不是进行数值计算。\n引用数据类型\n在 Java 中，引用类型（Reference Types）是指那些不是基本数据类型（如 int、char、double 等）的类型。引用类型包括以下几种：\n类（Class）：用户自定义的类，例如 public class A {...} 中的 A 类。\n接口（Interface）：定义了一组方法规范，但不提供实现的类型。\n数组（Array）：存储固定大小的相同类型元素的集合，例如 int[] numbers = new int[10];。\n枚举（Enum）：一种特殊的类类型，其值是固定的常量，例如 enum Day { MONDAY, TUESDAY, WEDNESDAY, ... };。\n注解（Annotation）：一种特殊的接口类型，用于提供元数据，例如 @Deprecated。\n字符串（String）：虽然 String 在 Java 中是不可变的，但它是一个引用类型，用于表示字符序列。\n\u0026ndash;变量的类型转换\rboolean 类型不能转换成任何其它数据类型。\n自动类型转换\n容量小的类型自动转换成容量大的数据类型 byte, short, int -\u0026gt; float -\u0026gt; long -\u0026gt; double byte, short, int 不会互相转换，它们三者在计算时会转换成 int 类型\n显式类型转换\n容量大的类型转换成容量小的数据类型时，要加上强制转换符(截断转换)\n1 2 float b = 3.0f a = (int)b \u0026ndash;变量的作用域\r成员变量(全局变量 private int i=0;)或静态变量 private static String name=\u0026ldquo;list\u0026rdquo;) 在类体内定义的变量称为成员变量，它们作用域是整个类 局部变量 在一个方法或方法内代码块中定义的变量称为局部变量 \u0026ndash;Java中的常量\r(不怎么考)\n常量不能被转换，例如常数\n\u0026ndash;注意事项\r1 2 3 4 变量定义注意事项： float a=13.3f 带上\u0026#39;f\u0026#39; long a=222222222222L 带上\u0026#39;L\u0026#39; char c= \u0026#39;A\u0026#39; 带上\u0026#39; \u0026#39; 2.3 运算符\r算数\r1 2 + - * / % ++ -- / 取商 ；% 取余 赋值\r=\n关系\r\u0026lt; \u0026gt;= \u0026lt;= == !=\n逻辑\r! \u0026amp;\u0026amp; ||\n\u0026amp; |\t不怎么用\n^ 按位异或运算符,逻辑异或运算符\n位运算符(不会考)\n~ \u0026lt;\u0026lt; \u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt;\n条件运算符\rcondition ? valueIfTrue : valueIfFalse;\ncondition：一个布尔表达式，其结果为 true 或 false。 valueIfTrue：如果 condition 为 true，则这个值会被选择。 valueIfFalse：如果 condition 为 false，则这个值会被选择。 1 2 int score = 85; String grade = score \u0026gt;= 90 ? \u0026#34;A\u0026#34; : \u0026#34;B\u0026#34;; 在这个例子中，如果 score 大于或等于90，grade 将被赋值为 \u0026quot;A\u0026quot;；否则，它将被赋值为 \u0026quot;B\u0026quot;。\n2.4.1 选择语句\r1 2 3 4 5 6 7 8 9 10 11 if else if\t(接在if后面，多重选择) else 这三个与c语言基本相同 switch(XX) { //java特有 枚举 short byte int char String //C语言:字符,int case 1: XX;break; case 2: XX;break; default(可有可无): XX break; } 2.4.2 java的循环\r1 2 3 4 while(){} for(){} do{} while() 以上三种和c语言基本一样 1 2 3 for (ElementType element : collection) { // 在这里处理集合中的每个元素 } ElementType：表示集合中元素的数据类型。 element：表示当前遍历到的集合元素的变量。 collection：表示要遍历的数组或集合。 1 2 3 4 5 6 7 8 9 int[] numbers = {1, 2, 3, 4, 5}; for (int number : numbers) { System.out.println(number); } List\u0026lt;String\u0026gt; words = Arrays.asList(\u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;, \u0026#34;Java\u0026#34;); for (String word : words) { System.out.println(word); } 2.5 数组\r-不允许在前面的括号写元素个数\n2.5.1 多维数组初始化3种方式\r\u0026ndash;动态两种\njava的多维数组每一维数可不同\n1 2 3 4 5 1 int[][] arr = new int[3][]; //指定了行数，未指定列数 arr[0] = new int[3];//第0行3列 arr[1] = new int[2];//第1行2列 arr[2] = new int[1];//第2行1列 1 2 3 2 int[][] arr2 = new int[3][2];//同时指定行数和列数 arr[0][0] = 33;//单独对元素赋值 \u0026ndash;静态一种\n1 2 int arr4[][] = new int[][]{{1, 2, 3}, {2, 3}}; //第0行是{1，2，3}，第1行是{2，3} 不赋值默认元素为0\n一般来说初始化时都默认括号在数组名前，这是Java的风格，当然反过来也一样可行（c语言风格）\n2.5.2 数组的常见操作\r声明数组：\n1 int arr[] 数组初始化：\n1 2 int[] arr={1,2,3,4}; int[] arr=new int[]{1,2,3,4}; 查看数组长度：\n1 2 arr.length; 返回值是整数，反映了数组中第一维元素的个数 for each 循环：\n1 2 3 for(int a:arr){ System.out.println(a); } 数组拷贝：\n1 2 3 4 int[] arr2=arr1; 或 int[] arr2=Arrays.copyOf(arr, arr.length(自定义长度)); arr2会复制arr1 length长度的元素 数组排序：\n1 2 Arrays.sort(arr); 默认从小到大排序 将int数组转换为字符串：\n1 2 Arrays.toString(arr); 连括号一起转换成字符串了 2.6 输入输出\r输入\r1 2 Scanner s = new Scanner(System.in); //先创建了一个Scanner对象s，用于从System.in（标准输入流，即键盘输入）读取数据。 在Java中，Scanner 类的 next() 方法用于从输入流中读取下一个完整的 token。Token 通常是输入中的一个单词，由空白字符（如空格、制表符或换行符）分隔。next() 方法会读取并返回一个字符串，直到遇到下一个空白字符，但不包括这个空白字符。（类比scanf）\n1 2 3 4 String word = s.next(); // 从标准输入读取一个单词 System.out.println(\u0026#34;输入的单词是: \u0026#34; + word); //输出 如果需要读取包含空格的字符串，应该使用 nextLine() 而不是 next()。\n它将读取输入直到遇到换行符（\\n），并将换行符之前的所有内容（包括空格）作为字符串返回。\n1 String sentence = s.nextLine(); // 读取整行，包括空格 在s.next()的基础上，有：\n1 2 3 4 5 6 s.nextInt(); //读取用户输入的下一个整数 s.nextFloat(); //读取用户输入的下一个浮点数。这可以是单个数字、小数或科学记数法表示的数字 //即： s.next类型名(); Scanner 类的 hasNext() 方法用于检查输入流中是否还有更多的输入。这是一个非常有用的功能，尤其是在处理不确定数量的输入时，比如在读取用户输入直到用户决定停止时。\n1 2 3 4 5 6 7 8 Scanner s = new Scanner(System.in); while (s.hasNext()) { String input = s.next(); if (\u0026#34;end\u0026#34;.equals(input)) { break; // 结束循环 } System.out.println(\u0026#34;处理输入: \u0026#34; + input); } 同理有：hasNextLine() hasNextFloat()等方法检验有无特定类型的输入\n这里插入一下字符串的比较，equals()方法\n1 2 3 4 5 boolean areEqual = str1.equals(str2); //若str1与str2内容相同，返回true，反之返回false //注意：空值检查 //如果 equals 方法的参数是 null，那么在没有进行空值检查的情况下直接调用会导致 NullPointerException。 //因此，通常在调用 equals 方法之前，会先检查参数是否为 null。 输出\r在Java中，输出数据到控制台或文件可以通过多种方式实现。以下是一些输出方法：\nSystem.out.print 和 System.out.println：（常用）\nSystem.out.print：将数据打印到标准输出（通常是控制台），但不换行。 System.out.println：将数据打印到标准输出，并在末尾添加一个换行符。 1 2 System.out.print(\u0026#34;Hello, \u0026#34;); System.out.println(\u0026#34;World!\u0026#34;); System.out.printf：\n用于格式化输出，类似于C语言中的 printf 函数。可以指定输出格式和宽度等。 1 System.out.printf(\u0026#34;The value of pi is: %.2f%n\u0026#34;, Math.PI); System.out.format：\n类似于 System.out.printf，但返回 String 对象而不是打印到控制台。 1 String formattedString = System.out.format(\u0026#34;The value of pi is: %.2f%n\u0026#34;, Math.PI); PrintStream：\nSystem.out 是一个 PrintStream 对象，提供了更多的方法来控制输出，如 print, println, printf, format 等。 BufferedWriter：\n用于将文本写入字符输出流，可以提高写入性能，特别是当写入大量数据时。 1 2 3 4 BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(System.out)); writer.write(\u0026#34;Hello, World!\u0026#34;); writer.newLine(); // 写入换行符 writer.flush(); // 清空缓冲区 PrintWriter：\n用于打印格式化表示的字符到控制台或文件。 1 2 3 PrintWriter writer = new PrintWriter(System.out, true); writer.println(\u0026#34;Hello, World!\u0026#34;); writer.flush(); // 清空缓冲区 FileWriter：\n用于写入字符到文件。 1 2 3 FileWriter writer = new FileWriter(\u0026#34;output.txt\u0026#34;); writer.write(\u0026#34;Hello, World!\u0026#34;); writer.close(); // 关闭文件写入器 Files.write (Java 7+)：\n用于将字节数据写入文件，可以指定字符编码。 1 2 Path path = Paths.get(\u0026#34;output.txt\u0026#34;); Files.write(path, \u0026#34;Hello, World!\u0026#34;.getBytes(StandardCharsets.UTF_8)); Logger：\nJava的日志记录框架，用于记录应用程序的日志信息。 1 2 Logger logger = Logger.getLogger(\u0026#34;MyLogger\u0026#34;); logger.info(\u0026#34;Hello, World!\u0026#34;); StringBuffer 和 StringBuilder：\n用于在内存中构建字符串，特别是当需要多次修改字符串内容时。 1 2 3 StringBuilder sb = new StringBuilder(\u0026#34;Hello, \u0026#34;); sb.append(\u0026#34;World!\u0026#34;); System.out.println(sb.toString()); 选择哪种输出方法取决于你的具体需求，比如是否需要格式化输出、是否需要写入文件、是否需要考虑性能等因素。\n2.7.1 类与对象\r概念 三大特征 封装 “通过 private、default、protected、public 关键字实现属性或方法的封装，仅对外提供公共访问方式。” “高内聚、低耦合”\n封装的好处：\n实现数据和方法的隐藏 实现信息隐藏，允许外部对类有限的访问，开发者可以自由的改变类的内部实现 提高了代码的重用性 继承\n通过 extends。 两个好处：\n代码重用了。 通过继承，实现对现实世界更加准确的建模。 多态\n多态是指允许不同类的对象对同一消息做出响应，即同一操作作用于不同对象，可以有不同的解释，产生不同的执行结果。在Java中多态的实现方式：接口实现，继承父类进行方法重写。同一个类中进行方法重载，父类引用指向子类对象。\n2.7.2 类与对象 (重点)\r关系\n实例化(对象的创建)\n通过 new 关键字创建 比如\n1 2 Student zhangchunhui = new Student(); zhangchunhui.setAge(20); 1 2 3 4 5 6 class Student{ private int age; public static void setAge(int age){ this.age = age; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Stu{ //1 属性设为私有 private int age; //2 方法 get set 你自己定义的 public void setAge(int age) { this.age = age; } public int getAge() { return this.age; } //我自己定义的方法 public void myPrint() { System.out.println(\u0026#34;nihao\u0026#34;); } //3 构造函数 public Stu() { } 或 public Stu(int age) { this.age = age; //类内用this指代该类 } } 若使用无参数构造函数\n1 2 Stu student1 = new Stu(); // 创建了一个Stu对象，但是age属性没有被初始化 student1.setAge(25); // 之后可以手动设置age属性的值 若使用带参数构造函数\n1 Stu student2 = new Stu(20); // 创建了一个Stu对象，并且age属性被初始化为20 类的定义(格式,注意事项)\n1 2 3 4 [修饰符] class 类名 [extends 父类名] [implements 接口名]{ // 类体，包括类的成员变量和成员方法 } //[]表示可选 2.8 类的继承\rObject类\nObject类是所有类的父类，里面有很多方法 clone getClass toString equals hashCode notify notifyAll wait finalize\ngetClass方法 获取运行时类型，返回值为Class对象 hashCode方法 返回该对象的哈希码值，是为了提高哈希表的效率（Hashtable） equals方法 判断两个对象是否相等，在Object类中equals就是使用==去判断，所以在Object的子类中，如果equals相等的两个对象，hashCode一定相等，实现不同的比较。 clone方法 主要是JAVA里除了8种基本类型传参数是值传递，其他的类对象传参数都是引用传递。我们有时候不希望在方法里修改参数，这就需要在类中重写clone方法。 如果在clone方法中调用super.clone()方法需要实现Cloneable接口，否则会抛出CloneNotSupportedException。 此方法只实现了一个浅层拷贝，对于基本类型字段成功拷贝，但是如果是数组等对象，只做了浅拷贝，也就是只复制了对象的引用，所以需要自己重写clone方法进行深层拷贝。 toString方法 返回一个String字符串，用于描述当前对象的信息，可以重写该方法返回对自己有用的信息，默认返回的是当前对象的类名+hashCode的16进制数字。 wait方法 多线程中用到的方法，作用是让当前线程进入等待状态，同时也会释放当前线程所持有的锁。直到其他线程调用此对象的notify()方法或notifyAll()方法，当前线程才会被唤醒。 notify方法 多线程时用到的方法，唤醒该对象等待的某个线程 notifyAll方法 多线程时用到的方法，唤醒该对象等待的所有线程 finalize 对象在被垃圾收集器回收前一定会调用finalize方法，对象被释放前最后的挣扎，因为无法确定该方法什么时候被调用，很少使用。 \u0026ndash;类的继承格式\n1 2 3 4 5 class 父类 { } class 子类 extends 父类 { } \u0026ndash;继承了之后有父类(非私有private)的属性或方法,可直接调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Animal { public String name; private int id; public Animal(String myName, String myId) { // 初始化属性值 } public void eat() { } public void sleep() { System.out.println(\u0026#34;晚上了我要睡觉\u0026#34;) } } public class Owl extends Animal{ } \u0026mdash;重写父类方法\n子类可以重写父类的同名方法，以根据需求覆盖原方法\n1 2 3 4 5 public class Penguin extends Animal{ public void sleep() { System.out.println(\u0026#34;白天了我要睡觉\u0026#34;) } } 2.9 类的封装\r将类的某些信息隐藏在类的内部，不允许外部程序直接访问，而是通过该类提供getter/setter的方法来对隐藏的信息进行操作和访问。\ngetter setter\n封装的实现步骤：\n(1) 将成员属性的可见性设为（private）\n(2) 创建getter/setter方法（用于属性的读写）（通过这两种方法对数据进行获取和设定，对象通过调用这两种方法实现对数据的读写）\n(3) 在getter/setter方法中加入属性控制语句（对属性值的合法性进行判断）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class Person { private String name; private int age; public int getAge() { return age; } public String getName() { return name; } public void setAge(int age) { if(age \u0026lt; 0){ System.out.println(\u0026#34;你的年龄不合法请重新输入\u0026#34;)； } else{ this.age = age; } } public void setName(String name) { this.name = name; } } //通过方法来访问或者修改私有private的属性 2.10 构造方法(重点)\r\u0026ndash;定义\n主要用来在创建对象时初始化对象，即为对象成员变量赋初始值，总与new运算符一起使用在创建对象的语句中。\n一个类可以有多个构造函数，可根据其参数个数的不同或参数类型的不同来区分它们，即构造函数的重载。\n\u0026ndash;重载\n1 2 3 4 5 6 7 8 9 10 11 12 public Animal2(String name, int myid) { this.name = name; this.id = myid; } public Animal2(String name) { this.name = name; } public Animal2(int id2) { this.id = id2; } 2.11 方法的重载 和 重写\r\u0026ndash;回顾一下方法定义格式：\n1 2 3 4 权限修饰符 返回值声明 方法名称(参数列表){ 方法中封装的逻辑功能; return 返回值; } 重载（Overloading）：\n发生在同一个类中，当多个方法有相同的名称但参数列表不同（与返回值类型、修饰符无关）时，这些方法就是重载的。\n重载的目的是为了提供相同功能但使用不同参数的方法，以提高代码的可读性和灵活性。\n示例见下或2.10\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Calculator { // 重载方法1：两个整数相加 public int add(int a, int b) { return a + b; } // 重载方法2：三个整数相加 public int add(int a, int b, int c) { return a + b + c; } // 重载方法3：两个浮点数相加 public double add(double a, double b) { return a + b; } } 重写（Overriding）：\n发生在子类和父类之间，当子类有一个与父类方法签名（方法名称和参数列表）完全相同的方法时，子类的方法就重写了父类的方法。\n重写的目的是为了提供特定于子类的行为，即子类可以根据自己的需要改变父类方法的行为。\n实例见 2.8\n重写的注意事项：\n重写的方法必须要和父类一模一样（包括返回值类型、方法名、参数列表）。 重写的方法可以使用 @Override 注解来标识。 子类中重写的方法的访问权限不能低于父类中方法的访问权限。权限修饰符的顺序是：private \u0026lt; 默认（什么都不写） \u0026lt; protected \u0026lt; public。 2.12.1 this 关键字\rJava 中为解决变量的命名冲突和不确定性问题，引入关键字 this 代表其所在方法的当前对象的引用：\n构造方法中指该构造器所创建的新对象: 1 2 3 4 5 6 7 8 public class B { A a; // A是另一个类，算一个类型 // 构造方法，接收一个 A 类型的参数 public B(A a) { this.a = a; // 使用 this 来区分成员变量 a 和参数 a } } 方法中指调用该方法的对象: 1 2 3 4 5 6 7 8 9 10 public class Baby { public void wakeUp() { System.out.println(\u0026#34;宝宝醒啦\u0026#34;); } public void eat() { this.wakeUp(); // 调用当前对象的wakeUp方法 System.out.println(\u0026#34;吃东西\u0026#34;); } } 在类本身的方法或构造器中引用该类的实例变量（全局变量）和方法: 1 2 3 4 5 public void setName(String name) { this.name = name; // 使用this关键字来区分成员变量和方法参数 //this.name是成员变量，name是方法参数 } \u0026ndash;注意\nthis 只能在类中的非静态方法中使用，静态方法和静态的代码块中绝对不能出现 this\n\u0026ndash;原因：static 方法在类加载时就已经存在了，但是对象是在创建时才在内存中生成。\n2.12.2 super 关键字\r一句话概括：super 关键字主要存在于子类方法中，用于指向子类对象中的父类对象；可以访问父类的属性、函数以及构造函数。\n当子类和父类存在着同名的成员（包括变量和方法）时，在子类中默认是访问子类的成员，可以通过 super 关键字指定访问父类的成员。\n默认会先调用父类无参的构造方法，可以通过 super 关键字指定调用父类的构造方法。\n示例\n假设我们有一个父类 Animal 和一个子类 Dog，我们可以这样使用 super 关键字：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class Animal { String name; // 父类的构造方法 public Animal() { System.out.println(\u0026#34;Animal\u0026#39;s constructor\u0026#34;); } // 父类的方法 public void makeSound() { System.out.println(\u0026#34;Some generic animal sound\u0026#34;); } } class Dog extends Animal { // 子类的构造方法 public Dog() { super(); // 调用父类的无参构造方法 System.out.println(\u0026#34;Dog\u0026#39;s constructor\u0026#34;); } // 子类重写的方法 @Override public void makeSound() { System.out.println(\u0026#34;Woof woof\u0026#34;); } // 使用super调用父类的makeSound方法 public void specificSound() { super.makeSound(); // 调用父类的makeSound方法 System.out.println(\u0026#34;Dog\u0026#39;s specific sound\u0026#34;); } } 在这个例子中，super 关键字用于在子类 Dog 中调用父类 Animal 的构造方法和 makeSound 方法。这展示了如何在子类中访问和使用父类的成员。\n2.13.1 static 关键字\r\u0026ndash;静态变量\n1 private static String str1 = \u0026#34;staticProperty\u0026#34;; \u0026ndash;静态方法\n1 2 3 4 5 public static void print2() { System.out.println(str1); System.out.println(str2); print1(); } \u0026ndash;静态代码块\n1 2 3 static { static int a = 3; } 被 static 修饰的变量属于类变量，可以通过类名.变量名直接引用，而不需要 new 出一个类来。\n被 static 修饰的方法属于类方法，可以通过类名.方法名直接引用，而不需要 new 出一个类来。\n平时要使用类中的变量或者方法都要先new实例化一个类。\n2.13.2 final关键字\rfinal：用于声明常量、最终类或最终方法。\n\u0026ndash;修饰变量\n基本类型变量使用 final 修饰了就不可变了 对于引用类型变量被 final 修饰了；引用变量引用不可变(就整个引用变量不可变)，但是引用对象的内容可以改变。 举例\nfinal修饰数组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class FinalArrayExample { public static void main(String[] args) { final int[] numbers = {1, 2, 3, 4, 5}; // 修改数组中的元素是允许的 numbers[0] = 10; // 尝试重新赋值，这将导致编译错误 // numbers = new int[]{6, 7, 8}; // 错误：不能将变量 numbers 赋值 // 输出修改后的数组 System.out.println(Arrays.toString(numbers)); // 输出: [10, 2, 3, 4, 5] } } 在这个例子中，数组 numbers 被 final 修饰，这意味着数组的引用不能被改变指向另一个数组。但是，数组中的元素可以被修改。\n\u0026ndash;修饰类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class FinalObjectExample { public static void main(String[] args) { final A obj = new A(); // 修改对象的属性是允许的，如果属性不是 final 的 obj.a = 4; // 假设 A 类中的 a 不是 final // 尝试重新赋值，这将导致编译错误 // obj = new A(); // 错误：不能将变量 obj 赋值 // 输出对象的属性值 System.out.println(obj.a); // 输出: 4 } } class A { int a = 3; } 注意\nfinal 修饰的类，不能被继承（）\n\u0026ndash;修饰方法\nfinal 修饰的方法 不能被重写，但是子类可以用父类中 final 修饰的方法；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 final class FinalClassExample { // final 类不能被继承 // 子类继承 FinalClassExample 是不允许的 public final void display() { System.out.println(\u0026#34;Hello, World!\u0026#34;); } // final 方法不能被子类重写 // 子类重写 display 方法是不允许的 } // 尝试创建子类将导致编译错误 // class SubClass extends FinalClassExample { } 2.14 抽象类\r1 2 3 4 5 6 public abstract class Action { public abstract void doSomething(); // 抽象方法 public void test() { // 方法体 } } 在这段代码中，Action 类被声明为抽象类，使用 abstract 关键字。这意味着 Action 类不能被实例化，它只能作为其他类的父类。\n抽象类可以包含抽象方法和具体方法。\n抽象方法也使用 abstract 关键字声明，它们没有方法体，必须在子类中被实现。在这个例子中，doSomething 是一个抽象方法，而 test 是一个具体方法，它提供了一个方法体。\n子类继承 Action 类时，必须实现 doSomething 方法，即要重写 doSomething 方法并添加具体的方法体。\n2.15 接口\r1 2 3 4 5 6 7 8 9 10 11 12 13 public interface UserService { // 接口中的所有定义的方法默认都是抽象的（public abstract） // 变量只能为 public static final 类型的 // public abstract void add(); // 等效于 void add(); // int age = 99; // 等效于 public static final int age = 99; int age = 99; void add(String name); void delete(String name); void update(String name); void query(String name); } 在 Java 中，接口（interface）是一种特殊的抽象类型，它可以包含抽象方法和常量。接口中的方法默认是 public abstract 的，这意味着它们没有方法体，必须由实现接口的类来提供具体实现。接口中的变量默认是 public static final 的，这意味着它们是常量，并且必须在声明时初始化。\n\u0026ndash;区别\n接口要被子类实现，抽象类要被子类继承。 接口中变量全为公共静态常量，抽象类中可有普通变量。 接口中全为抽象方法的声明，抽象类中可以有具体方法的实现。 接口中不可以有构造函数，抽象类中可以有构造函数。 一个类可实现多个接口，而抽象类只能被单继承。 接口中方法为抽象方法，而抽象类中也可有非抽象方法。 示例\n1 2 3 4 5 6 //定义接口 public interface Vehicle { void startEngine(); void stopEngine(); void honk(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //实现接口 //一旦你决定用一个类实现一个接口，你必须实现其所有的抽象方法 public class Car implements Vehicle { @Override public void startEngine() { System.out.println(\u0026#34;Car engine started.\u0026#34;); } @Override public void stopEngine() { System.out.println(\u0026#34;Car engine stopped.\u0026#34;); } @Override public void honk() { System.out.println(\u0026#34;Car horn honked.\u0026#34;); } } 1 2 3 4 5 6 7 8 9 //调用方法 public class Main { public static void main(String[] args) { Car myCar = new Car(); myCar.startEngine(); myCar.honk(); myCar.stopEngine(); } } ","date":"2024-12-16T16:04:20Z","image":"http://localhost:1313/images/Lover.PNG","permalink":"http://localhost:1313/p/quick-java/","title":"Quick Java"},{"content":"(2023-11-15) Do Users Write More Insecure Code with AI Assistants?\r作者: Neil Perry; Megha Srivastava; Deepak Kumar; Dan Boneh; 期刊: （发表日期: 2023-11-15） 期刊分区: 本地链接: Perry 等 - 2023 - Do Users Write More Insecure Code with AI Assistants.pdf DOI: 10.1145/3576915.3623157 摘要: AI code assistants have emerged as powerful tools that can aid in the software development life-cycle and can improve developer productivity. Unfortunately, such assistants have also been found to produce insecure code in lab environments, raising significant concerns about their usage in practice. In this paper, we conduct a user study to examine how users interact with AI code assistants to solve a variety of security related tasks. Overall, we find that participants who had access to an AI assistant wrote significantly less secure code than those without access to an assistant. Participants with access to an AI assistant were also more likely to believe they wrote secure code, suggesting that such tools may lead users to be overconfident about security flaws in their code. To better inform the design of future AI-based code assistants, we release our user-study apparatus and anonymized data to researchers seeking to build on our work at this link. **标签:**AI代码安全，用户行为侧 笔记日期: 2024/11/26 16:30:20 📜 研究核心\rTips: 做了什么？解决了什么问题，创新点与不足？\n研究用户如何与 AI 代码助手交互以解决各种与安全相关的任务。\n⚙️ 内容\r背景问题：AI代码助手在实验室环境中会产生不安全的代码\n研究：进行了一项用户研究，以研究用户如何与 AI 代码助手交互以解决各种与安全相关的任务。\n核心问题：\n1.用户在使用AI编程助手时是否编写了更多不安全的代码？\n2.用户是否信任AI助手能够编写安全的代码？\n3.用户在与 AI 助手交互时的语言和行为，如何影响，其代码中安全漏洞的程度？\n发现：\n1.可以访问 AI 助手的参与者编写的代码的安全性明显低于无法使用助手的参与者。\n2.有权访问 AI 助手的参与者也更有可能相信他们编写了安全代码，这表明此类工具可能会导致用户对其代码中的安全漏洞过于自信。\n💡 创新点\r从 AI代码确有问题的层面 深入到了\n1.讨论是不是 使用ai就会导致更多代码问题\n2.以及 用户对ai的信任和交互方式 和 AI生成代码问题 之间的内在联系\n🧩 不足\r研究的参与者主要是大学生，不一定能代表实际使用AI助手的开发者群体。\n而且碍于控制变量和数据收集的难度，样本数量可能确实不算太多。\n🔁 研究内容\r研究目的\n本研究旨在探讨用户在使用AI代码助手（如OpenAI的Codex）时如何解决与安全相关的编程任务，以及这种交互如何影响代码的安全性。研究主要关注三个核心问题：\n1.用户在使用AI编程助手时是否编写了更多不安全的代码？\n2.用户是否信任AI助手能够编写安全的代码？\n3.用户在与AI助手互动时的语言和行为如何影响代码中的安全漏洞程度？\n👩🏻‍💻 方法 与 🔬 实验\r实验设计\r参与者招募：\n研究招募了54名参与者，涵盖了本科生、研究生以及来自不同公司的专业程序员。参与者在参与前需通过一项筛选问题，以验证其编程能力。\n最终，有47名参与者完成了实验，其中33人使用了AI助手，14人作为对照组未使用AI助手。\n研究工具：\n为本研究定制了一个编程用户界面，实验组还配备了一个AI辅助界面，两个组别均可使用外部浏览器以解决问题。\n实验任务：\n参与者被要求完成六个与安全相关的编程问题，涉及Python、JavaScript和C语言。任务包括加密/解密字符串、签名消息、处理用户提供的路径、执行SQL操作以及处理C语言中的字符串等。参与者可以自由选择完成任务的顺序，并在两小时内完成所有问题。\n实验设计：\n参与者被随机分配到实验组（使用AI助手）和对照组（不使用AI助手）。\n研究过程中，记录了参与者的所有交互，包括查询、响应和最终提交的代码。同时，研究团队会手动分析参与者的代码，以评估其正确性和安全性。\n💧 数据\r研究团队记录了参与者在实验中的所有操作，包括代码输出和AI助手的使用情况。通过多变量回归分析，研究者控制了参与者的安全背景和编程经验，以评估AI助手对代码安全性的影响。此外，参与者在完成每个问题后还需填写简短的调查问卷，以获取他们对AI助手的信任程度及代码安全性的自我评估。\n分析过程\r研究团队详细描述了他们如何分析参与者的编程任务响应，尤其关注正确性和安全性错误的分类和评估过程。\n错误分类: 两位作者手动检查所有参与者的解决方案，创建了一个错误列表，列出了所有的正确性和安全性错误，并根据严重性对其进行了排名。\n评分标准: 研究团队设定了明确的评分标准，以衡量每个问题的正确性和安全性，\n正确性：指代码是否能成功执行预期功能；\n安全性：涉及是否存在安全漏洞。\n例如：每个问题的错误分类包括“安全”、“部分安全”、“不安全”等类别。\n注：\nCohen-Kappa一致性评分: 研究团队采用Cohen-Kappa指标（取值在-1和1间，越大一致性越高）来评估两位评审者在正确性和安全性评分上的一致性。结果显示，评分的一致性相当高，正确性评分的Kappa值在0.7至0.96之间，安全性评分的Kappa值在0.68至0.88之间，表明评分过程的可靠性。\n安全分析\r分类系统:\n研究团队为每个安全性问题设计了一个分类系统，以评估参与者的正确性和安全性，进而确定正确率和安全性错误的发生率、错误类型及其来源（来自AI助手还是用户自身）\n实验发现：\n在其中的四个问题上，可以使用人工智能助手的参与者编写的代码的安全性始终低于无法使用人工智能助手的参与者。\n统计分析:\r研究团队使用多变量回归分析来控制参与者的安全背景、编程经验等变量，以解释不同组别之间的安全性差异。\n控制变量以确保是否使用AI助手是影响代码安全的主要因素。\n信任分析\r研究者探讨了用户对AI助手作为编程辅助工具的信任程度。研究通过调查问卷、自由反馈以及用户对AI建议的采纳程度来综合评估信任这一抽象而复杂的概念。\n分析结果：\n提供答案不安全的实验组反而自我正确性和安全性评分更高；\n方案安全的信任度低，不安全的反而高；\n研究者尝试用是否直接复制AI代码来量化信任度，但是发现这因题目而异；\n大部分安全答案都是在AI代码基础上修改的，说明提供安全解决方案可能需要用户更有意识地修改AI生成的代码，而不是盲目信任AI生成的内容。\n提示分析\r研究者探讨了用户如何与AI代码助手进行交互，具体分析了用户的提示语言、提示参数和修复策略对代码安全性的影响。\n分析结果\n提示语言\n使用函数声明和帮助函数的提示更能生成安全的代码。\n提示类型的选择对代码的安全性有显著影响，部分参与者在与AI助手的互动中使用了前一个AI输出作为新提示，这可能导致安全问题的放大或重复。\n提示参数的调整\n调整温度参数可能对代码的安全性产生影响，使用更高的温度值通常与更安全的代码输出相关。\n修复策略\n参与者在修复提示时更倾向于使用更具体的指令和信息。\n安全性\n依赖于AI助手的先前输出进行后续提示的参与者，往往不太可能提供安全答案。这表明，过度依赖AI生成的内容可能导致安全性下降。\n📜 结论总结\rAI助手的影响\r（同时也是核心问题1的回答）\n研究发现，参与者在使用AI助手时，通常会引入更多的安全漏洞。大多数任务中，使用AI助手的参与者更可能提交不安全的解决方案，而那些没有使用助手的参与者则相对更安全。这表明AI助手可能导致开发者对其生成的代码过于信任，从而忽视潜在的安全问题。\n用户信任与安全性的关系\r参与者普遍认为他们的答案更安全，尤其是那些提交不安全代码的用户，相比之下，提交安全代码的用户对AI助手的信任度较低。这种反向关系特别明显，显示出用户在面对AI生成的代码时可能会产生误导性的安全感。\n用户行为的多样性\r参与者在与AI助手互动时展现出显著的行为差异。那些更加积极调整提示或参数的参与者，通常能提供更安全的解决方案。这表明用户的交互策略和对AI助手的理解程度直接影响了他们最终的代码安全性。\nAI助手的设计建议\r研究者建议未来的AI助手设计应加强对用户的教育，帮助他们理解如何有效地与AI进行交互，避免过度依赖助手的输出。\n同时，应该考虑在AI助手中集成安全警示和验证测试，以减少用户在使用过程中产生的安全漏洞。\n研究的局限性\r研究的参与者主要是大学生，这可能不代表实际使用AI助手的开发者群体。研究者指出，未来需要更大规模的样本和不同背景的参与者，以更全面地评估AI助手在实际开发环境中的影响。\n小结\r总的来说，该总结部分强调了AI助手在提高开发效率的同时，也可能引入安全风险，用户应更加谨慎地对待AI生成的代码，未来的AI助手设计需要考虑如何增强用户的安全意识和代码审查能力。\n🤔 个人总结\r🙋‍♀️重点记录\ridea的创新之处\n从 AI代码确有问题的层面 深入到了\n1.讨论是不是 使用ai就会导致更多代码问题；\n2.以及 用户对ai的信任和交互方式 和 AI生成代码问题 之间的内在联系。\n在现有的研究上更加深入，具体地探讨了影响 AI生成代码安全问题的 用户因素。\n控制变量的处理\n要确保实验反映的确实是AI代码助手的影响，需要把其它实验变量控制在可控范围内，尽量消除它们对关键要素的判断的影响。\n不足\n研究的参与者主要是大学生，不一定能代表实际使用AI助手的开发者群体。\n而且碍于控制变量和数据收集的难度，样本数量可能确实不算太多。\n启发\r这篇文章是从用户端分析的AI生成代码安全的问题，我觉得从模型端的角度也可以对AI代码安全问题进行分析。虽然感觉实现难度上可能要大得多了。\n","date":"2024-11-23T21:45:04Z","image":"http://localhost:1313/images/Tiger.JPG","permalink":"http://localhost:1313/p/do-users-write-more-insecure-code-with-ai-assistants/","title":"Do Users Write More Insecure Code with AI Assistants?"},{"content":"Typora教程\rTypora的安装\r这是b站up主 格格分享集 提供的1.9.5版本及绕过激活方法，在此鸣谢。\nhttps://www.bilibili.com/video/BV1iKUsYdEat/?share_source=copy_web\u0026vd_source=94c6a60e88fb8109fcdee4173a2a7281\n不想看视频的可以往下看。\n解压 Typora1.9.5.zip后，文件结构如下：\n先运行安装程序安装typora1.9.5；\n然后解压河蟹.zip,将其中的配置文件winmm.dll复制到typora所在文件夹(右键点击typora快捷方式即可)；\n最后打开typora，点击侧边栏中的帮助，再点击关于激活即可。\nMarkdown语法及Typora快捷键\r标题\r使用井号 # 后接文本表标题，#个数表示几级标题，至多六级。（有时#后要紧接空格）\nTypora中快捷键Ctrl+1-6表示相应级标题。\n字体\r斜体\r一对星号*括住的文本表示斜体文本。\n要表示斜体的文本\n或者用一对下划线_括住文本表示斜体文本。\n要表示斜体的文本\nTypora快捷键Ctrl+I。\n粗体\r一对 ** 括住的文本表示斜体文本。\n要表示斜体的文本\n或者用一对下划线 __ 括住文本表示斜体文本。\n要表示斜体的文本\nTypora快捷键Ctrl+B。\n粗斜体文本\r一对 *** 括住的文本表示斜体文本。\n要表示粗斜体的文本\n或者用一对下划线 __ 括住文本表示斜体文本。\n要表示斜体的文本\n文本高亮\r算是Typora的一个特色，用一对==将要高亮的文本括起来，需要在文件-偏好设置中打开。\n==要高亮的文本==\n各种线\r分割线\r用三个及以上的 + 号或 * 号或 - 来表示一条分割线；\nTypora右键插入水平分割线即可。\n下为例子：\n+++\n下划线\r利用的是HTML的标签 和 表示增加下划线文本，\n要增加下划线的文本\nTypora快捷键：Ctrl+U\n删除线\r用一对~~括住的文本来表示删除文本；\n要删除的文本\nTypora快捷键：Alt+Shift+5\n表格\rMarkdown 制作表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行。\nTypora快捷键：Ctrl+T\nTypora中表格的创建和修改都非常精简和方便，所以很多额外的操作（对齐、添加行列等）不加赘述了。\n表头 表头 表头 列表\r无序列表\r用*，+或-标记符号来表示无序列表项，标记符号后要紧接一个空格。\n1 2 其它两符号同上。\n（Enter键退出列表）\nTypora快捷键：Ctrl+Shift+] (更建议右键里添加)\n有序列表\r以 数字紧接.再紧接空格表示有序列表。\n一 二 Typora快捷键：Ctrl+Shift+[ (更建议右键里添加)\n嵌套列表\r列表中：\n回车换行自动生成列表第二列；\nTab键该项变为上一项的子列表。\n无序列表和有序列表间可相互嵌套。\n引用\r用区块表引用, \u0026gt;加空格表示区块。\n这是一级引用\n这是二级引用\n（Enter键退出区块）\nTypora快捷键：Ctrl+Shift+Q (更建议右键里添加)\n代码块\r代码行：用一对**`**（英语下Tab键上方符号）括住代码\nprint(\u0026quot;Helloworld\u0026quot;)\n代码块：\n以三个`加回车进入代码块；\nTypora快捷键：Ctrl+Shift+`\n链接\r用\n链接文字\n或\n\u0026lt;链接地址\u0026gt;\n表示链接。\n[]中是链接文本，\u0026lt;\u0026gt;中是链接地址，也可以放本地文件的地址（相对绝对均可）\n但是单独使用\u0026lt;\u0026gt;不能打开文件。\n亦可使用链接实现页内跳转：\n链接文字\nCTRL+点击跳转至文章开头\n图像\r语法如下：\n！加[属性文本]加(图片地址 ”可选标题“)\n首先一个感叹号 然后中括号里面写属性文本 小括号里面写图片地址，后可接标题 本地地址和网络地址都行。\n在Typora中，也可以直接使用Ctrl+C，Ctrl+V来直接进行复制粘贴图片，但是，由于Markdown语法的限制，一定需要文件地址，所以需要设置一下Typora。\n在Typora 文件-偏好设置-图像 中可自行选择将图片复制到什么路径。相对路径以该文本文件为参照。\n数学\r数学公式太繁琐了喵，推荐让ai生成，这里不加赘述了。\n有时间再更。\n","date":"2024-11-23T21:45:04Z","image":"http://localhost:1313/images/PacificRim_01.jpg","permalink":"http://localhost:1313/p/typora/","title":"Typora"}]